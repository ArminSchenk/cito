---
title: "Example: (Multi-) Species distribution models with cito"
author: "Maximilian Pichler"
abstract: "This vignette shows working examples of how to fit (multi-) species distribution models with cito. Training neural networks is tricky compared to other ML algorithms that converge more easily (due to various reasons). The purpose of this vignette is to provide an example workflow and to point out common caveats when training a neural network"
date: "2024-03-05"
output:
 rmarkdown::html_vignette:
    toc: true
    toc_depth: 4
    html_document:
      toc: true
      theme: cerulean
vignette: >
  %\VignetteIndexEntry{Example: (Multi-) Species distribution models with cito}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---



## Species distribution model - African elephant

The goal is to build a SDM for the African elephant. A pre-processed dataset from [Angelov, 2020](https://zenodo.org/record/4048271) can be found in the EcoData package which is only available on github:


```r
if(!require(EcoData)) devtools::install_github(repo = "TheoreticalEcology/EcoData",
                         dependencies = FALSE, build_vignettes = FALSE)

library(EcoData)
df = EcoData::elephant$occurenceData
head(df)
#>       Presence       bio1       bio2       bio3       bio4        bio5       bio6       bio7       bio8       bio9       bio10       bio11      bio12      bio13       bio14
#> 3364         0 -0.4981747 -0.2738045  0.5368968 -0.5409999 -0.36843571  0.2947850 -0.5260099 -1.2253960  0.2494100 -0.64527314 -0.06267842  0.6285371  0.6807958 -0.29703736
#> 6268         0  0.6085908 -0.5568352  1.0340686 -1.2492050 -0.11835651  0.8221087 -0.8938475  0.4233787  0.7746249  0.09168503  0.94419518  1.1121516  0.5918442  0.01619202
#> 10285        0 -0.7973005  1.4648130 -1.0540532  2.0759423  0.07614953 -1.5860029  1.6284678  0.2768209 -1.5153122 -0.03648161 -1.44165748 -1.2351482 -1.3396742 -0.50585695
#> 2247         0  0.6385034  1.3435141 -0.1591439 -0.5107148  1.10425291 -0.1622288  0.8577603  0.4600181  0.5855475  0.54026827  0.68153250  0.5951165  0.8714061 -0.55806185
#> 9821         0  0.6684160 -0.6781341  0.6363311 -0.9906170  0.15950927  0.9099960 -0.8062671  0.3867393  0.8586593  0.31597665  0.94419518  1.1003561  0.5537222  0.59044589
#> 1351         0  0.9675418 -0.6781341 -0.3580126 -0.3748202  0.77081398  0.8748411 -0.3858812  0.3134604  1.0477367  0.98885151  0.94419518  0.7287986  1.1255533 -0.50585695
#>              bio15      bio16      bio17       bio18       bio19
#> 3364  -0.008455252  0.7124535 -0.2949994 -1.06812752  1.96201807
#> 6268  -0.884507980  0.5607328  0.3506918  1.22589281 -0.36205814
#> 10285  0.201797403 -1.3499999 -0.5616980 -0.42763181 -0.62895735
#> 2247   0.236839512  1.1012378 -0.5616980 -0.20541902 -0.58378979
#> 9821  -1.024676416  0.6413344  0.7437213  0.06254347 -0.05409751
#> 1351   0.236839512  1.2956300 -0.4494038 -0.90473576  2.47939193
```

Presence is our response variable and we have the 19 bioclim variables as features/predictors.

Let's split part of the data away so that we can use it at the end to evaluate our model:


```r
indices = sample.int(nrow(df), 300)
test = df[indices,]
df = df[-indices,]
```

### Adjusting optimization parameters - Convergence

We will first try a simple DNN with default values and the binomial likelihood. We use 30% of the data as validation holdout to check for overfitting:


```r
library(cito)
model = dnn(Presence~., data = df,
            batchsize = 100L,
            validation = 0.3, loss = "binomial",
            verbose = FALSE)
```

<img src="C/C-unnamed-chunk-4-1.png" style="display: block; margin: auto;" />

We see that the training and test losses were still decreasing which means we didn't train the model long enough. We could now either increase the number of epochs or increase the learning rate so that the model trains faster:


```r
model = dnn(Presence~., data = df,
            batchsize = 100L,
            lr = 0.05,
            validation = 0.3, loss = "binomial",
            verbose = FALSE)
```

<img src="C/C-unnamed-chunk-5-1.png" style="display: block; margin: auto;" />

Much better! But still now enough epochs. Also, let's see if we can further decrease the loss by using a wider and deeper neural network:


```r
model = dnn(Presence~., data = df,
            batchsize = 100L,
            hidden = c(100L, 100L, 100L),
            lr = 0.05,
            validation = 0.3, loss = "binomial",
            verbose = FALSE)
```

<img src="C/C-unnamed-chunk-6-1.png" style="display: block; margin: auto;" />

At the end of the training, the losses start to get jumpy, which can be a sign of potential overfitting. We can control that by adding a weak regularization (but we only want a L2 regularization, so we set alpha to 1.0):


```r
model = dnn(Presence~., data = df,
            batchsize = 100L,
            epochs = 150L,
            hidden = c(100L, 100L, 100L),
            lr = 0.05,
            lambda = 0.001,
            alpha = 1.0,
            validation = 0.3, loss = "binomial",
            verbose = FALSE)
```

<img src="C/C-unnamed-chunk-7-1.png" style="display: block; margin: auto;" />

We will turn on now advanced features that help with the convergence and to reduce overfitting:

-   learning rate scheduler - reduces learning rate during training

-   early stopping - stop training when validation loss starts to increase


```r
model = dnn(Presence~., data = df,
            batchsize = 100L,
            epochs = 150L,
            hidden = c(100L, 100L, 100L),
            lr = 0.05,
            lambda = 0.001,
            alpha = 1.0,
            validation = 0.3, loss = "binomial",
            verbose = FALSE,
            lr_scheduler = config_lr_scheduler("reduce_on_plateau", patience = 7), # reduce learning rate each 7 epochs if the validation loss didn't decrease,
            early_stopping = 14 # stop training when validation loss didn't decrease for 10 epochs
            )
```

<img src="C/C-unnamed-chunk-8-1.png" style="display: block; margin: auto;" />

Great! We found now a model architecture and training procedure that fits and trains well. Let's proceed to our final model

### Train final model with bootstrapping to obtain uncertainties

We haven't directly started with bootstrapping because it complicates the adjustment of the training procedure.

Uncertainties can be obtained by using bootstrapping. Be aware that this can be computational expensive:


```r
model_boot = dnn(Presence~., data = df,
                 batchsize = 100L,
                 epochs = 150L,
                 hidden = c(100L, 100L, 100L),
                 lr = 0.05,
                 lambda = 0.001,
                 alpha = 1.0,
                 validation = 0.3, loss = "binomial",
                 verbose = FALSE,
                 lr_scheduler = config_lr_scheduler("reduce_on_plateau", patience = 7), # reduce learning rate each 7 epochs if the validation loss didn't decrease,
                 early_stopping = 14, # stop training when validation loss didn't decrease for 10 epochs
                 bootstrap = 20L,
                 bootstrap_parallel = 5L
            )
```

### Predictions

We can use the model now for predictions:


```r
predictions = predict(model_boot, newdata = test, reduce = "none")
dim(predictions)
#> [1]  20 300   1
```

The predictions are 2/3 dimensional because of the bootstrapping. Calculate the AUC interval:


```r
hist(sapply(1:20, function(i) Metrics::auc(test$Presence, predictions[i,,])),
     xlim = c(0, 1), main = "AUC of ensemble model", xlab = "AUC")
```

<img src="C/C-unnamed-chunk-11-1.png" style="display: block; margin: auto;" />

We can now predict the habitat suitability of the elephant (Note that spatial dependencies are required):


```r
library(raster)
library(sp)
library(rsample)
library(latticeExtra)
library(sp)
library(ggplot2)
library(maptools)
customPredictFun = function(model, data) {
  return(apply(predict(model, data), 2:3, mean)[,1])
}

normalized_raster = EcoData::elephant$predictionData

predictions =
  raster::predict(normalized_raster,
                  model_boot,
                  fun = customPredictFun)
#> Error in apply(predict(model, data), 2:3, mean): 'MARGIN' does not match dim(X)

habitat_plot =
  spplot(predictions, colorkey = list(space = "left") )
#> Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'spplot' for signature '"array"'
habitat_plot
#> Error in eval(expr, envir, enclos): object 'habitat_plot' not found
```

Moreover, we can visualize the uncertainty of our model, instead of calculating the average occurrence probability, we calculate for each prediction the standard deviation and visualize it:


```r
customPredictFun_sd = function(model, data) {
  return(apply(predict(model, data), 2:3, sd)[,1])
}
predictions =
  raster::predict(normalized_raster,
                  model_boot,
                  fun = customPredictFun_sd)
#> Error in apply(predict(model, data), 2:3, sd): 'MARGIN' does not match dim(X)

uncertain_plot =
  spplot(predictions, colorkey = list(space = "left") )
#> Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'spplot' for signature '"array"'
uncertain_plot
#> Error in eval(expr, envir, enclos): object 'uncertain_plot' not found
```

### Inference

Neural networks are often called black-box models but the tools of explainable AI (xAI) allows us to understand them - and actually infer properties similar to what a linear regression model can provide (the calculation can take some time...):


```r
results = summary(model_boot)
results
#> Summary of Deep Neural Network Model
#> 
#> ── Feature Importance
#>          Importance Std.Err Z value Pr(>|z|)  
#> bio1 →        0.555   0.460    1.21    0.227  
#> bio2 →        0.508   0.325    1.56    0.119  
#> bio3 →        0.759   0.475    1.60    0.110  
#> bio4 →        0.786   0.545    1.44    0.149  
#> bio5 →        0.637   0.507    1.26    0.208  
#> bio6 →        0.514   0.451    1.14    0.255  
#> bio7 →        0.348   0.216    1.62    0.106  
#> bio8 →        0.571   0.323    1.77    0.076 .
#> bio9 →        1.114   1.060    1.05    0.293  
#> bio10 →       0.426   0.313    1.36    0.174  
#> bio11 →       0.421   0.368    1.15    0.252  
#> bio12 →       1.050   0.684    1.54    0.125  
#> bio13 →       0.469   0.400    1.17    0.241  
#> bio14 →       0.558   0.318    1.76    0.079 .
#> bio15 →       0.796   0.366    2.18    0.030 *
#> bio16 →       1.731   1.283    1.35    0.177  
#> bio17 →       0.252   0.122    2.07    0.038 *
#> bio18 →       0.993   0.546    1.82    0.069 .
#> bio19 →       0.363   0.263    1.38    0.167  
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> ── Average Conditional Effects
#>               ACE  Std.Err Z value Pr(>|z|)    
#> bio1 →    0.04299  0.02580    1.67  0.09564 .  
#> bio2 →   -0.04720  0.01540   -3.06  0.00218 ** 
#> bio3 →   -0.04280  0.02170   -1.97  0.04858 *  
#> bio4 →    0.03113  0.02753    1.13  0.25807    
#> bio5 →    0.04581  0.02900    1.58  0.11424    
#> bio6 →    0.03400  0.03982    0.85  0.39326    
#> bio7 →   -0.01218  0.01734   -0.70  0.48247    
#> bio8 →   -0.00952  0.02756   -0.35  0.72968    
#> bio9 →   -0.07652  0.03407   -2.25  0.02469 *  
#> bio10 →   0.00598  0.03173    0.19  0.85054    
#> bio11 →  -0.00848  0.03175   -0.27  0.78942    
#> bio12 →  -0.07520  0.03718   -2.02  0.04313 *  
#> bio13 →   0.03388  0.03139    1.08  0.28031    
#> bio14 →   0.09689  0.02855    3.39  0.00069 ***
#> bio15 →  -0.02667  0.02135   -1.25  0.21151    
#> bio16 →  -0.09338  0.02933   -3.18  0.00145 ** 
#> bio17 →   0.05404  0.02442    2.21  0.02689 *  
#> bio18 →   0.03148  0.01504    2.09  0.03639 *  
#> bio19 →  -0.02727  0.02754   -0.99  0.32213    
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> ── Standard Deviation of Conditional Effects
#>             ACE Std.Err Z value Pr(>|z|)    
#> bio1 →   0.1130  0.0329    3.43  0.00060 ***
#> bio2 →   0.1018  0.0285    3.57  0.00036 ***
#> bio3 →   0.1088  0.0383    2.84  0.00446 ** 
#> bio4 →   0.1089  0.0298    3.66  0.00026 ***
#> bio5 →   0.1095  0.0424    2.58  0.00988 ** 
#> bio6 →   0.0957  0.0401    2.39  0.01706 *  
#> bio7 →   0.0622  0.0193    3.22  0.00127 ** 
#> bio8 →   0.1073  0.0200    5.38  7.6e-08 ***
#> bio9 →   0.1214  0.0575    2.11  0.03461 *  
#> bio10 →  0.0880  0.0232    3.79  0.00015 ***
#> bio11 →  0.0931  0.0267    3.48  0.00049 ***
#> bio12 →  0.1334  0.0389    3.43  0.00061 ***
#> bio13 →  0.0917  0.0397    2.31  0.02084 *  
#> bio14 →  0.1540  0.0469    3.28  0.00102 ** 
#> bio15 →  0.0972  0.0207    4.69  2.7e-06 ***
#> bio16 →  0.1570  0.0481    3.27  0.00109 ** 
#> bio17 →  0.1037  0.0315    3.29  0.00100 ** 
#> bio18 →  0.1830  0.0449    4.07  4.6e-05 ***
#> bio19 →  0.0799  0.0258    3.09  0.00198 ** 
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Bioclim9, 12, 14, and 16 have large significant average conditional effects (\$\\approx\$ linear effects). We can visualize them using accumulated local effect plots:


```r
par(mfrow = c(1, 4))
ALE(model_boot, variable = "bio9")
```

<img src="C/C-unnamed-chunk-15-1.png" style="display: block; margin: auto;" />

```r
ALE(model_boot, variable = "bio12")
```

<img src="C/C-unnamed-chunk-15-2.png" style="display: block; margin: auto;" />

```r
ALE(model_boot, variable = "bio14")
```

<img src="C/C-unnamed-chunk-15-3.png" style="display: block; margin: auto;" />

```r
ALE(model_boot, variable = "bio16")
```

<img src="C/C-unnamed-chunk-15-4.png" style="display: block; margin: auto;" />

## Multi-species distribution model

Cito supports many different loss functions which we can use to build multi-species distribution models (MSDM). MSDM are multi-label, i.e. they model and predict simultaneously many responses. We will use eucalypts data from [Pollock et al., 2014](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12180). The dataset has occurrence of 12 species over 458 sites.


```r
load(url("https://github.com/TheoreticalEcology/s-jSDM/raw/master/sjSDM/data/eucalypts.rda"))
# Environment
head(eucalypts$env)
#>   Rockiness Sandiness VallyBotFlat PPTann Loaminess cvTemp      T0
#> 1        60         1            0    785         0    142 6124.01
#> 2        75         1            0    785         0    142 6124.01
#> 3        70         1            0    780         0    142 3252.96
#> 4        40         1            0    778         0    142 1636.63
#> 5        15         1            0    772         0    142 1352.08
#> 6        80         1            0    841         0    142 5018.48

# PA
head(eucalypts$PA)
#>      ALA ARE BAX CAM GON MEL OBL OVA WIL ALP VIM ARO.SAB
#> [1,]   0   0   0   0   0   0   0   0   1   1   0       0
#> [2,]   0   0   0   0   0   0   1   0   1   1   0       0
#> [3,]   0   0   1   0   0   0   0   0   1   1   0       0
#> [4,]   0   0   1   0   0   0   0   0   1   0   0       0
#> [5,]   0   0   1   0   0   0   1   0   0   0   0       0
#> [6,]   0   0   0   0   0   0   0   0   1   1   0       0
```

Bring data into a format that is usable by cito:


```r
df = cbind(eucalypts$PA, scale(eucalypts$env))
head(df)
#>      ALA ARE BAX CAM GON MEL OBL OVA WIL ALP VIM ARO.SAB  Rockiness Sandiness VallyBotFlat       PPTann  Loaminess    cvTemp         T0
#> [1,]   0   0   0   0   0   0   0   0   1   1   0       0  1.0315338 0.5716827   -0.5939667 -0.005981517 -0.2134535 -1.056073  0.5378148
#> [2,]   0   0   0   0   0   0   1   0   1   1   0       0  1.4558834 0.5716827   -0.5939667 -0.005981517 -0.2134535 -1.056073  0.5378148
#> [3,]   0   0   1   0   0   0   0   0   1   1   0       0  1.3144335 0.5716827   -0.5939667 -0.045456081 -0.2134535 -1.056073 -0.3404551
#> [4,]   0   0   1   0   0   0   0   0   1   0   0       0  0.4657344 0.5716827   -0.5939667 -0.061245907 -0.2134535 -1.056073 -0.8348993
#> [5,]   0   0   1   0   0   0   1   0   0   0   0       0 -0.2415148 0.5716827   -0.5939667 -0.108615385 -0.2134535 -1.056073 -0.9219447
#> [6,]   0   0   0   0   0   0   0   0   1   1   0       0  1.5973333 0.5716827   -0.5939667  0.436133605 -0.2134535 -1.056073  0.1996271
```

We will use the binomial likelihood - each species occurrence data will be modelled by a binomial likelihood. Build simple model:


```r
model = dnn(cbind(ALA, ARE, BAX, CAM, GON, MEL, OBL, OVA, WIL, ALP, VIM, ARO.SAB)~.,
            data = df,
            lr = 0.1,
            verbose = FALSE,
            loss = "binomial")
```

<img src="C/C-unnamed-chunk-18-1.png" style="display: block; margin: auto;" />

Plot model:


```r
plot(model)
```

<img src="C/C-unnamed-chunk-19-1.png" style="display: block; margin: auto;" />

Our NN has now 12 output nodes, one for each species.


```r
head(predict(model))
#>           [,1]      [,2]        [,3]      [,4]      [,5]      [,6]        [,7]      [,8]        [,9]      [,10]     [,11]     [,12]
#> [1,] -1.789873 -3.754081  0.34240779 -4.597900 -4.251222 -2.890321 -0.82101405 -4.179935 -0.80416811 -0.8944693 -3.595195 -3.095653
#> [2,] -1.548055 -3.517138  0.09588669 -4.913952 -3.942821 -3.110520 -1.16666865 -4.564185 -1.08635747 -0.1742114 -3.965924 -3.757052
#> [3,] -1.884867 -3.635351  0.09913537 -4.933583 -3.961093 -3.203473 -1.14224339 -4.613166 -1.11530805 -0.5742322 -4.045332 -3.625873
#> [4,] -2.544899 -4.399445  0.65598494 -4.395844 -4.849123 -2.886551 -0.48054117 -3.963417 -0.52106273 -2.2920618 -3.402213 -2.282501
#> [5,] -3.149618 -5.015063  1.03085506 -3.934410 -5.620312 -2.561637  0.06874193 -3.393110 -0.07596268 -3.8622015 -2.837154 -1.146416
#> [6,] -1.498866 -3.473027 -0.20058735 -5.327390 -3.818149 -3.475967 -1.55100596 -5.096377 -1.44351935  0.4397406 -4.493228 -4.503428
```

### Train model with bootstrapping


```r
model_boot = dnn(cbind(ALA, ARE, BAX, CAM, GON, MEL, OBL, OVA, WIL, ALP, VIM, ARO.SAB)~.,
                 data = df,
                 loss = "binomial",
                                  epochs = 200L,
                 hidden = c(50L, 50L),
                 batchsize = 50L,
                 lr = 0.1,
                 lambda = 0.001,
                 alpha = 1.0,
                 validation = 0.2,
                 verbose = FALSE,
                 lr_scheduler = config_lr_scheduler("reduce_on_plateau", patience = 7), # reduce learning rate each 7 epochs if the validation loss didn't decrease,
                 early_stopping = 14, # stop training when validation loss didn't decrease for 10 epochs
                 bootstrap = 20L,
                 bootstrap_parallel = 5L)
```

We haven't really adjusted the training procedure, so let's check the convergence first:


```r
analyze_training(model_boot)
```


### Inference


```r
results = summary(model_boot)
results
#> Summary of Deep Neural Network Model
#> 
#> ── Feature Importance
#>                        Importance Std.Err Z value Pr(>|z|)    
#> Rockiness → ALA           0.12210 0.04218    2.89  0.00380 ** 
#> Sandiness → ALA           0.01043 0.00679    1.54  0.12445    
#> VallyBotFlat → ALA        0.07903 0.02774    2.85  0.00439 ** 
#> PPTann → ALA              0.04954 0.01876    2.64  0.00828 ** 
#> Loaminess → ALA           0.01590 0.00817    1.94  0.05179 .  
#> cvTemp → ALA              0.07097 0.02587    2.74  0.00608 ** 
#> T0 → ALA                  0.02463 0.02000    1.23  0.21811    
#>                                                               
#> Rockiness → ARE           0.09887 0.05537    1.79  0.07416 .  
#> Sandiness → ARE           0.02578 0.01982    1.30  0.19328    
#> VallyBotFlat → ARE        0.07796 0.04485    1.74  0.08218 .  
#> PPTann → ARE              0.11210 0.05186    2.16  0.03066 *  
#> Loaminess → ARE           0.03703 0.02396    1.55  0.12212    
#> cvTemp → ARE              1.18976 0.41596    2.86  0.00423 ** 
#> T0 → ARE                  0.05877 0.03234    1.82  0.06916 .  
#>                                                               
#> Rockiness → BAX           0.10627 0.04850    2.19  0.02845 *  
#> Sandiness → BAX           0.09101 0.03866    2.35  0.01855 *  
#> VallyBotFlat → BAX        0.22940 0.09698    2.37  0.01801 *  
#> PPTann → BAX              0.05193 0.02741    1.89  0.05811 .  
#> Loaminess → BAX           0.00936 0.00652    1.44  0.15095    
#> cvTemp → BAX              0.17226 0.07107    2.42  0.01536 *  
#> T0 → BAX                  0.01656 0.01089    1.52  0.12851    
#>                                                               
#> Rockiness → CAM           0.04580 0.04128    1.11  0.26723    
#> Sandiness → CAM           0.22821 0.05174    4.41  1.0e-05 ***
#> VallyBotFlat → CAM        0.41840 0.21033    1.99  0.04667 *  
#> PPTann → CAM              0.06238 0.03214    1.94  0.05226 .  
#> Loaminess → CAM           0.03121 0.02548    1.22  0.22063    
#> cvTemp → CAM              0.05732 0.01971    2.91  0.00363 ** 
#> T0 → CAM                  0.01534 0.01438    1.07  0.28604    
#>                                                               
#> Rockiness → GON           0.34516 0.13958    2.47  0.01340 *  
#> Sandiness → GON           0.02589 0.01900    1.36  0.17303    
#> VallyBotFlat → GON        0.12257 0.04583    2.67  0.00748 ** 
#> PPTann → GON              0.25898 0.11776    2.20  0.02786 *  
#> Loaminess → GON           0.05682 0.05499    1.03  0.30148    
#> cvTemp → GON              2.24820 1.13641    1.98  0.04789 *  
#> T0 → GON                  0.07410 0.03384    2.19  0.02857 *  
#>                                                               
#> Rockiness → MEL           0.10442 0.05503    1.90  0.05776 .  
#> Sandiness → MEL           0.01634 0.01341    1.22  0.22296    
#> VallyBotFlat → MEL        0.03516 0.01921    1.83  0.06723 .  
#> PPTann → MEL              0.07239 0.02253    3.21  0.00132 ** 
#> Loaminess → MEL           0.02673 0.00894    2.99  0.00279 ** 
#> cvTemp → MEL              0.06166 0.02585    2.39  0.01705 *  
#> T0 → MEL                  0.00808 0.01440    0.56  0.57495    
#>                                                               
#> Rockiness → OBL           0.09884 0.03967    2.49  0.01271 *  
#> Sandiness → OBL           0.03275 0.01454    2.25  0.02432 *  
#> VallyBotFlat → OBL        0.07512 0.03715    2.02  0.04315 *  
#> PPTann → OBL              0.04173 0.01706    2.45  0.01443 *  
#> Loaminess → OBL           0.03967 0.03264    1.22  0.22417    
#> cvTemp → OBL              0.20270 0.09347    2.17  0.03012 *  
#> T0 → OBL                  0.01366 0.00807    1.69  0.09043 .  
#>                                                               
#> Rockiness → OVA           0.07784 0.02957    2.63  0.00848 ** 
#> Sandiness → OVA           0.16015 0.04237    3.78  0.00016 ***
#> VallyBotFlat → OVA        0.16872 0.07301    2.31  0.02083 *  
#> PPTann → OVA              0.05007 0.02107    2.38  0.01746 *  
#> Loaminess → OVA           0.03253 0.02639    1.23  0.21778    
#> cvTemp → OVA              0.03498 0.01924    1.82  0.06898 .  
#> T0 → OVA                  0.01567 0.00812    1.93  0.05354 .  
#>                                                               
#> Rockiness → WIL           0.03650 0.03077    1.19  0.23543    
#> Sandiness → WIL           0.03562 0.02691    1.32  0.18572    
#> VallyBotFlat → WIL        0.08666 0.03562    2.43  0.01497 *  
#> PPTann → WIL              0.05886 0.02452    2.40  0.01639 *  
#> Loaminess → WIL           0.03437 0.02929    1.17  0.24070    
#> cvTemp → WIL              0.59898 0.18061    3.32  0.00091 ***
#> T0 → WIL                  0.01757 0.00936    1.88  0.06040 .  
#>                                                               
#> Rockiness → ALP           1.51632 0.58609    2.59  0.00968 ** 
#> Sandiness → ALP           0.05678 0.03427    1.66  0.09749 .  
#> VallyBotFlat → ALP        0.14332 0.10672    1.34  0.17930    
#> PPTann → ALP              0.68321 0.32452    2.11  0.03527 *  
#> Loaminess → ALP           0.01890 0.02087    0.91  0.36514    
#> cvTemp → ALP              0.11532 0.08698    1.33  0.18494    
#> T0 → ALP                  0.04807 0.02380    2.02  0.04340 *  
#>                                                               
#> Rockiness → VIM           0.07706 0.02640    2.92  0.00351 ** 
#> Sandiness → VIM           0.08625 0.03370    2.56  0.01048 *  
#> VallyBotFlat → VIM        0.04626 0.02904    1.59  0.11120    
#> PPTann → VIM              0.04896 0.01859    2.63  0.00845 ** 
#> Loaminess → VIM           0.03420 0.01510    2.27  0.02348 *  
#> cvTemp → VIM              0.04089 0.01263    3.24  0.00121 ** 
#> T0 → VIM                  0.02100 0.01216    1.73  0.08419 .  
#>                                                               
#> Rockiness → ARO.SAB       0.27155 0.09716    2.79  0.00519 ** 
#> Sandiness → ARO.SAB       0.03110 0.02188    1.42  0.15519    
#> VallyBotFlat → ARO.SAB    0.19323 0.10244    1.89  0.05925 .  
#> PPTann → ARO.SAB          0.13336 0.03374    3.95  7.7e-05 ***
#> Loaminess → ARO.SAB       0.01033 0.00964    1.07  0.28414    
#> cvTemp → ARO.SAB          0.24699 0.12032    2.05  0.04010 *  
#> T0 → ARO.SAB              0.01119 0.01014    1.10  0.26972    
#>                                                               
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> ── Average Conditional Effects
#>                              ACE   Std.Err Z value Pr(>|z|)    
#> Rockiness → ALA         0.032118  0.007738    4.15  3.3e-05 ***
#> Sandiness → ALA        -0.006514  0.005956   -1.09  0.27402    
#> VallyBotFlat → ALA     -0.014412  0.006908   -2.09  0.03696 *  
#> PPTann → ALA            0.014711  0.009970    1.48  0.14008    
#> Loaminess → ALA         0.002504  0.006519    0.38  0.70090    
#> cvTemp → ALA            0.021084  0.009143    2.31  0.02111 *  
#> T0 → ALA                0.011582  0.006688    1.73  0.08332 .  
#>                                                                
#> Rockiness → ARE         0.022071  0.010239    2.16  0.03112 *  
#> Sandiness → ARE        -0.006314  0.006238   -1.01  0.31147    
#> VallyBotFlat → ARE     -0.006222  0.009454   -0.66  0.51045    
#> PPTann → ARE           -0.006220  0.008917   -0.70  0.48543    
#> Loaminess → ARE        -0.004228  0.008404   -0.50  0.61490    
#> cvTemp → ARE            0.061778  0.013130    4.71  2.5e-06 ***
#> T0 → ARE                0.002527  0.006444    0.39  0.69497    
#>                                                                
#> Rockiness → BAX        -0.041620  0.021248   -1.96  0.05014 .  
#> Sandiness → BAX         0.057334  0.013558    4.23  2.3e-05 ***
#> VallyBotFlat → BAX     -0.097302  0.024544   -3.96  7.4e-05 ***
#> PPTann → BAX            0.002840  0.015879    0.18  0.85806    
#> Loaminess → BAX         0.002976  0.018595    0.16  0.87286    
#> cvTemp → BAX           -0.105248  0.021714   -4.85  1.3e-06 ***
#> T0 → BAX               -0.003586  0.022459   -0.16  0.87313    
#>                                                                
#> Rockiness → CAM        -0.003888  0.010022   -0.39  0.69803    
#> Sandiness → CAM        -0.029018  0.005661   -5.13  3.0e-07 ***
#> VallyBotFlat → CAM      0.041992  0.010780    3.90  9.8e-05 ***
#> PPTann → CAM           -0.011960  0.007723   -1.55  0.12150    
#> Loaminess → CAM         0.001489  0.008198    0.18  0.85592    
#> cvTemp → CAM            0.011102  0.009432    1.18  0.23918    
#> T0 → CAM                0.002146  0.004597    0.47  0.64062    
#>                                                                
#> Rockiness → GON         0.029111  0.010210    2.85  0.00436 ** 
#> Sandiness → GON        -0.006863  0.006012   -1.14  0.25367    
#> VallyBotFlat → GON     -0.006314  0.007972   -0.79  0.42830    
#> PPTann → GON           -0.010237  0.007151   -1.43  0.15226    
#> Loaminess → GON        -0.004863  0.009151   -0.53  0.59511    
#> cvTemp → GON            0.064492  0.012163    5.30  1.1e-07 ***
#> T0 → GON               -0.001894  0.006260   -0.30  0.76225    
#>                                                                
#> Rockiness → MEL        -0.017226  0.013963   -1.23  0.21731    
#> Sandiness → MEL        -0.010009  0.005088   -1.97  0.04918 *  
#> VallyBotFlat → MEL      0.015454  0.007862    1.97  0.04935 *  
#> PPTann → MEL           -0.016714  0.007851   -2.13  0.03325 *  
#> Loaminess → MEL        -0.000741  0.008563   -0.09  0.93109    
#> cvTemp → MEL            0.014418  0.011990    1.20  0.22914    
#> T0 → MEL                0.009153  0.006887    1.33  0.18384    
#>                                                                
#> Rockiness → OBL        -0.056380  0.022418   -2.51  0.01190 *  
#> Sandiness → OBL        -0.015077  0.014645   -1.03  0.30326    
#> VallyBotFlat → OBL     -0.020269  0.017078   -1.19  0.23527    
#> PPTann → OBL           -0.023796  0.014790   -1.61  0.10763    
#> Loaminess → OBL         0.043786  0.019499    2.25  0.02473 *  
#> cvTemp → OBL           -0.115451  0.029947   -3.86  0.00012 ***
#> T0 → OBL               -0.000397  0.019484   -0.02  0.98375    
#>                                                                
#> Rockiness → OVA        -0.007268  0.007507   -0.97  0.33300    
#> Sandiness → OVA        -0.025309  0.005043   -5.02  5.2e-07 ***
#> VallyBotFlat → OVA      0.028477  0.004992    5.70  1.2e-08 ***
#> PPTann → OVA           -0.010053  0.005538   -1.82  0.06945 .  
#> Loaminess → OVA         0.002244  0.006636    0.34  0.73527    
#> cvTemp → OVA            0.008543  0.008184    1.04  0.29652    
#> T0 → OVA                0.006965  0.004211    1.65  0.09807 .  
#>                                                                
#> Rockiness → WIL        -0.010575  0.018971   -0.56  0.57723    
#> Sandiness → WIL         0.006244  0.020646    0.30  0.76233    
#> VallyBotFlat → WIL     -0.021394  0.018216   -1.17  0.24020    
#> PPTann → WIL           -0.010014  0.018095   -0.55  0.57999    
#> Loaminess → WIL         0.035297  0.015673    2.25  0.02432 *  
#> cvTemp → WIL           -0.131155  0.025835   -5.08  3.8e-07 ***
#> T0 → WIL               -0.002772  0.016279   -0.17  0.86478    
#>                                                                
#> Rockiness → ALP         0.065619  0.012074    5.43  5.5e-08 ***
#> Sandiness → ALP         0.005546  0.007049    0.79  0.43142    
#> VallyBotFlat → ALP     -0.015620  0.013689   -1.14  0.25387    
#> PPTann → ALP            0.051932  0.007651    6.79  1.1e-11 ***
#> Loaminess → ALP         0.006649  0.014172    0.47  0.63894    
#> cvTemp → ALP           -0.012765  0.011877   -1.07  0.28250    
#> T0 → ALP                0.001665  0.008606    0.19  0.84660    
#>                                                                
#> Rockiness → VIM        -0.013623  0.008217   -1.66  0.09735 .  
#> Sandiness → VIM        -0.023838  0.005323   -4.48  7.5e-06 ***
#> VallyBotFlat → VIM      0.023549  0.007555    3.12  0.00183 ** 
#> PPTann → VIM           -0.012451  0.006556   -1.90  0.05754 .  
#> Loaminess → VIM         0.002340  0.005995    0.39  0.69623    
#> cvTemp → VIM           -0.004593  0.009521   -0.48  0.62954    
#> T0 → VIM                0.007164  0.003645    1.97  0.04937 *  
#>                                                                
#> Rockiness → ARO.SAB    -0.089142  0.026762   -3.33  0.00087 ***
#> Sandiness → ARO.SAB    -0.021444  0.013936   -1.54  0.12387    
#> VallyBotFlat → ARO.SAB  0.079349  0.019111    4.15  3.3e-05 ***
#> PPTann → ARO.SAB       -0.059847  0.018562   -3.22  0.00126 ** 
#> Loaminess → ARO.SAB     0.014639  0.018046    0.81  0.41726    
#> cvTemp → ARO.SAB       -0.096509  0.025933   -3.72  0.00020 ***
#> T0 → ARO.SAB           -0.001463  0.011699   -0.13  0.90049    
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#> 
#> ── Standard Deviation of Conditional Effects
#>                            ACE Std.Err Z value Pr(>|z|)    
#> Rockiness → ALA        0.02917 0.00727    4.01  6.0e-05 ***
#> Sandiness → ALA        0.01653 0.00407    4.06  4.9e-05 ***
#> VallyBotFlat → ALA     0.01651 0.00445    3.71  0.00021 ***
#> PPTann → ALA           0.02028 0.00478    4.24  2.3e-05 ***
#> Loaminess → ALA        0.00914 0.00199    4.59  4.5e-06 ***
#> cvTemp → ALA           0.02661 0.00669    3.98  7.0e-05 ***
#> T0 → ALA               0.01430 0.00372    3.85  0.00012 ***
#>                                                            
#> Rockiness → ARE        0.04658 0.00836    5.57  2.5e-08 ***
#> Sandiness → ARE        0.02332 0.00716    3.25  0.00114 ** 
#> VallyBotFlat → ARE     0.02889 0.00905    3.19  0.00141 ** 
#> PPTann → ARE           0.03108 0.00682    4.56  5.2e-06 ***
#> Loaminess → ARE        0.01668 0.00579    2.88  0.00396 ** 
#> cvTemp → ARE           0.06880 0.01751    3.93  8.5e-05 ***
#> T0 → ARE               0.01798 0.00448    4.02  5.9e-05 ***
#>                                                            
#> Rockiness → BAX        0.05709 0.00975    5.85  4.8e-09 ***
#> Sandiness → BAX        0.04153 0.00790    5.26  1.5e-07 ***
#> VallyBotFlat → BAX     0.06429 0.01363    4.72  2.4e-06 ***
#> PPTann → BAX           0.04870 0.01011    4.82  1.5e-06 ***
#> Loaminess → BAX        0.02171 0.00690    3.15  0.00166 ** 
#> cvTemp → BAX           0.06199 0.01377    4.50  6.8e-06 ***
#> T0 → BAX               0.02655 0.00796    3.34  0.00085 ***
#>                                                            
#> Rockiness → CAM        0.02027 0.00446    4.55  5.4e-06 ***
#> Sandiness → CAM        0.03624 0.00673    5.39  7.2e-08 ***
#> VallyBotFlat → CAM     0.04599 0.01255    3.66  0.00025 ***
#> PPTann → CAM           0.02032 0.00747    2.72  0.00655 ** 
#> Loaminess → CAM        0.01735 0.00645    2.69  0.00710 ** 
#> cvTemp → CAM           0.03195 0.00797    4.01  6.0e-05 ***
#> T0 → CAM               0.01864 0.00339    5.49  4.0e-08 ***
#>                                                            
#> Rockiness → GON        0.05887 0.01130    5.21  1.9e-07 ***
#> Sandiness → GON        0.02442 0.00714    3.42  0.00062 ***
#> VallyBotFlat → GON     0.03034 0.00830    3.66  0.00026 ***
#> PPTann → GON           0.03350 0.00749    4.48  7.6e-06 ***
#> Loaminess → GON        0.01876 0.00661    2.84  0.00451 ** 
#> cvTemp → GON           0.08383 0.01580    5.30  1.1e-07 ***
#> T0 → GON               0.01941 0.00484    4.01  6.1e-05 ***
#>                                                            
#> Rockiness → MEL        0.02318 0.01160    2.00  0.04567 *  
#> Sandiness → MEL        0.02444 0.00554    4.41  1.0e-05 ***
#> VallyBotFlat → MEL     0.02790 0.00766    3.64  0.00027 ***
#> PPTann → MEL           0.02119 0.00788    2.69  0.00714 ** 
#> Loaminess → MEL        0.01105 0.00434    2.55  0.01090 *  
#> cvTemp → MEL           0.02543 0.00786    3.24  0.00121 ** 
#> T0 → MEL               0.01386 0.00344    4.03  5.7e-05 ***
#>                                                            
#> Rockiness → OBL        0.04647 0.01165    3.99  6.7e-05 ***
#> Sandiness → OBL        0.03897 0.00794    4.91  9.1e-07 ***
#> VallyBotFlat → OBL     0.04979 0.01206    4.13  3.7e-05 ***
#> PPTann → OBL           0.04049 0.00908    4.46  8.2e-06 ***
#> Loaminess → OBL        0.03074 0.01068    2.88  0.00399 ** 
#> cvTemp → OBL           0.06944 0.02107    3.30  0.00098 ***
#> T0 → OBL               0.02338 0.00725    3.23  0.00126 ** 
#>                                                            
#> Rockiness → OVA        0.01762 0.00340    5.18  2.2e-07 ***
#> Sandiness → OVA        0.02711 0.00594    4.57  5.0e-06 ***
#> VallyBotFlat → OVA     0.02898 0.00539    5.37  7.7e-08 ***
#> PPTann → OVA           0.01671 0.00341    4.90  9.7e-07 ***
#> Loaminess → OVA        0.01332 0.00446    2.99  0.00282 ** 
#> cvTemp → OVA           0.02523 0.00615    4.10  4.2e-05 ***
#> T0 → OVA               0.01677 0.00337    4.97  6.6e-07 ***
#>                                                            
#> Rockiness → WIL        0.04609 0.01323    3.48  0.00049 ***
#> Sandiness → WIL        0.03584 0.00792    4.53  6.0e-06 ***
#> VallyBotFlat → WIL     0.04712 0.01011    4.66  3.1e-06 ***
#> PPTann → WIL           0.04405 0.01044    4.22  2.4e-05 ***
#> Loaminess → WIL        0.03244 0.01097    2.96  0.00310 ** 
#> cvTemp → WIL           0.10473 0.02393    4.38  1.2e-05 ***
#> T0 → WIL               0.02801 0.00782    3.58  0.00034 ***
#>                                                            
#> Rockiness → ALP        0.08837 0.01808    4.89  1.0e-06 ***
#> Sandiness → ALP        0.01999 0.00499    4.01  6.2e-05 ***
#> VallyBotFlat → ALP     0.02839 0.01517    1.87  0.06122 .  
#> PPTann → ALP           0.07454 0.01114    6.69  2.2e-11 ***
#> Loaminess → ALP        0.02423 0.01112    2.18  0.02932 *  
#> cvTemp → ALP           0.05214 0.00852    6.12  9.2e-10 ***
#> T0 → ALP               0.02669 0.00735    3.63  0.00028 ***
#>                                                            
#> Rockiness → VIM        0.01860 0.00525    3.55  0.00039 ***
#> Sandiness → VIM        0.02614 0.00557    4.69  2.7e-06 ***
#> VallyBotFlat → VIM     0.02901 0.00648    4.48  7.6e-06 ***
#> PPTann → VIM           0.01816 0.00416    4.37  1.3e-05 ***
#> Loaminess → VIM        0.01217 0.00363    3.35  0.00081 ***
#> cvTemp → VIM           0.02277 0.00558    4.08  4.4e-05 ***
#> T0 → VIM               0.01625 0.00345    4.71  2.4e-06 ***
#>                                                            
#> Rockiness → ARO.SAB    0.07510 0.02235    3.36  0.00078 ***
#> Sandiness → ARO.SAB    0.05144 0.01341    3.84  0.00012 ***
#> VallyBotFlat → ARO.SAB 0.07588 0.02134    3.56  0.00038 ***
#> PPTann → ARO.SAB       0.05944 0.01272    4.67  3.0e-06 ***
#> Loaminess → ARO.SAB    0.02771 0.01064    2.60  0.00920 ** 
#> cvTemp → ARO.SAB       0.08358 0.02281    3.66  0.00025 ***
#> T0 → ARO.SAB           0.02786 0.00739    3.77  0.00016 ***
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

cvTemp is significant for many species. Visualization of the effect:


```r
ale_plots = ALE(model_boot, variable = "cvTemp", plot = FALSE)
do.call(gridExtra::grid.arrange, ale_plots)
```

<img src="C/C-unnamed-chunk-24-1.png" style="display: block; margin: auto;" />


## Advanced: Joint species distribution model

In recent years, joint species distribution models (JSDM) have emerged as a new class of models capable of jointly modeling species. JSDM account for co-occurrences between species that cannot be explained by the environment alone with biotic associations [Pollock et al., 2014](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12180). Technically, biotic associations are coded by a covariance matrix that absorbs the species co-occurrences "left over" in the residuals. Two common models for JSDMs are the latent variable model [Warton et al., 2015](https://doi.org/10.1016/j.tree.2015.09.007) and the multivariate probit model (MVP) ([Pollock et al., 2014](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12180)).

In 'cito' we provide an experimental likelihood for the multivariate probit model which is based on a Monte-Carlo approximation ([Chen et al., 2018](https://proceedings.mlr.press/v80/chen18o.html)). However, 'cito' is not a JSDM-focused package which means that many interesting features of JSDMs such as community assembly analyses are not available in 'cito'. If you want to perform an in-depth analysis with JSDM such as to reveal the internal metacommunity structure we recommend, for example, the [sjSDM package](https://cran.r-project.org/web/packages/sjSDM/index.html):


```r
jsdm = dnn(cbind(ALA, ARE, BAX, CAM, GON, MEL, OBL, OVA, WIL, ALP, VIM, ARO.SAB)~.,
            data = df,
            lr = 0.1,
            epochs = 200L,
            verbose = FALSE,
            loss = "mvp")
```

<img src="C/C-unnamed-chunk-25-1.png" style="display: block; margin: auto;" />

Building the covariance matrix which corresponds to the biotic associations:

```r
L = jsdm$parameter$paramter
biotic_association = cov2cor(L%*%t(L) + diag(1, 12))
fields::image.plot(biotic_association)
```

<img src="C/C-unnamed-chunk-26-1.png" style="display: block; margin: auto;" />

For more information about community analyses with JSDMs see the [vignette of the sjSDM package](https://cran.r-project.org/web/packages/sjSDM/vignettes/sjSDM_Introduction.html)

