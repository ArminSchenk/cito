[{"path":"/E-CNN_and_MMN.html","id":"data-preparation-of-complex-data","dir":"","previous_headings":"","what":"Data Preparation of complex data","title":"NA","text":"Cito, workflow preparing complex data Convolutional Neural Networks (CNNs) Multimodal Neural Networks (MMNs) . difference MMNs can process multiple data types simultaneously (see ‘MMN’ section ). dive details, let’s clarify represent different types complex data R using multidimensional arrays: Black/white image: [height,width][height, width] height/width number pixels Colored images: [3,height,width][3, height, width] 3 channels three colors LiDAR point clouds: [x,y,z][x, y, z] Environmental time series (can also represented “image”): [time_steps,n_covariates][\\text{time_steps}, \\text{n_covariates}] Note: Cito currently supports three-dimensional inputs (excluding sample dimension). Four-dimensional arrays, temporal RGB sequences [3,height,width,timesteps][3, height, width, time_steps], yet supported. Please contact us need support 4D inputs.","code":""},{"path":"/E-CNN_and_MMN.html","id":"the-format-of-the-inputs-we-expect-in-cito","dir":"","previous_headings":"Data Preparation of complex data","what":"The format of the inputs we expect in cito","title":"NA","text":"cnn() mmn() functions expect X argument single array, first dimension indexing samples. subsequent dimensions correspond data structure sample. Specifically: Grayscale images: [n_samples,height,width][\\text{n_samples}, height, width] RGB images: [n_samples,3,height,width][\\text{n_samples}, 3, height, width] LiDAR point clouds: [n_samples,x,y,z][\\text{n_samples}, x, y, z] Time series data: [n_samples,timesteps,ncovariates][\\text{n_samples}, time_steps, n_covariates] crucial order samples X matches order observations response (target) vector (matrix multiple response) y. Ultimately, requirement cito multidimensional arrays inputs. Please note several ways can build ; following workflow just one example.","code":""},{"path":"/E-CNN_and_MMN.html","id":"id_1-preparing-your-data-on-disk","dir":"","previous_headings":"Data Preparation of complex data","what":"1. Preparing your data on disk","title":"NA","text":"Although images can saved different formats, recommend using formats R function R package available allow load images R. Grayscale RGB images saved .png .jpeg. Time series data can technically interpreted grayscale images therefore also saved .png .jpeg. However, LiDAR point clouds /remote sensing data ‘channels’ (ofc, channels ) grayscale RGB images therefore saved .png .jpeg. Classical formats saving data .tiff (GeoTiff) .nc (netCDF). recommend saving image individually hard drive using naming strategy allows observation ID inferred image name. example:","code":"project/ ├── data/ │   ├── RGBimages/ │   │   ├── 001-img.jpeg │   │   ├── 002-img.jpeg │   │   ├── 003-img.jpeg │   │   ├── 004-img.jpeg │   │   └── ... │   ├── LiDAR/ │   │   ├── 001-LiDAR.tiff │   │   ├── 002-LiDAR.tiff │   │   ├── 003-LiDAR.tiff │   │   ├── 004-LiDAR.tiff │   │   └── ... │   └── Response/ │       └── Y.csv └── code/     ├── 01-MMN.R     └── 02-CNN.R"},{"path":"/E-CNN_and_MMN.html","id":"id_2-load-images-into-r","dir":"","previous_headings":"Data Preparation of complex data","what":"2. Load images into R","title":"NA","text":"can run/train cito, must load images R, transform arrays, concatenate individual images one input type one array. Reading .jpeg files: Can done either using imager package via .array(imager::load.image(\"path--img.jpeg\"))) using torchvision package (dependency cito) via torchvision::base_loader(\"path--img.jpeg\") Reading .png files: Can done using torchvision package (dependency cito) via torchvision::base_loader(\"path--img.jpeg\") Reading .tiff files: tiff::readTIFF(\"path--img.tiff\") Reading .tiff (GeoTIFF) files: .array(raster::brick(\"path--img.tiff\"))","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/articles/A-Introduction_to_cito.html","id":"setup---installing-torch","dir":"Articles","previous_headings":"","what":"Setup - Installing torch","title":"Introduction to cito","text":"using ‘cito’ make sure current version ‘torch’ installed running. problems installing Torch, check installation help torch developer.","code":"if(!require(torch)) install.packages(\"torch\") library(torch) if(!torch_is_installed()) install_torch()  library (cito)"},{"path":[]},{"path":"/articles/A-Introduction_to_cito.html","id":"internal-data-representation","dir":"Articles","previous_headings":"Details about the internal implementation of ‘cito’","what":"Internal Data Representation","title":"Introduction to cito","text":"Tabular data typically supplied cito data.frame usual encoding via data argument. Categorical data processed internally using model.matrix functions R ‘stats’ package. Categorical features automatically one-hot encoded (reference level). data split feature matrix (variables) response matrix. training neural networks based stochastic gradient descent, involves sampling random batches data optimization step. optimize sampling subsetting data, ‘torch’ provides optimized data loader objects create data iterators (objects iterate data set corresponding epoch). feature response matrices passed ‘torch’ data loaders reside CPU (avoid memory overflows GPU, available).","code":""},{"path":"/articles/A-Introduction_to_cito.html","id":"construction-of-the-neural-networks","dir":"Articles","previous_headings":"Details about the internal implementation of ‘cito’","what":"Construction of the neural networks","title":"Introduction to cito","text":"Neural networks (NN) built using ‘nn_sequential’ object ‘torch’ package. nn_sequential’ expects list layers returns fully functional neural network object. also initializes weights layers. list layers built based user input, particular hidden argument number size hidden layers, activation argument corresponding activation layers.","code":""},{"path":"/articles/A-Introduction_to_cito.html","id":"training-and-evaluation","dir":"Articles","previous_headings":"Details about the internal implementation of ‘cito’","what":"Training and Evaluation","title":"Introduction to cito","text":"NN structure data prepared, actual training starts (baseline loss also calculated training starts). training consists two loops. outer loop number epochs (one epoch means data used update weights). inner loop stochastic gradient descent, .e. n = 100 observations batch size = 20, takes 5 batches data traverse dataset . step inner loop, optimizer reset, batch data returned data iterator (initialized epoch data loader), split feature response tensors, pushed GPU (one available), feature matrix passed NN prediction, average loss computed based response tensor predictions, average loss backpropagated, weights updated optimizer based back-propagated errors. inner loop repeated dataset used , completing epoch. process repeated n epochs. validation turned , epoch model evaluated validation holdout (separated data beginning).","code":""},{"path":"/articles/A-Introduction_to_cito.html","id":"transferability","dir":"Articles","previous_headings":"Details about the internal implementation of ‘cito’","what":"Transferability","title":"Introduction to cito","text":"make model portable (e.g. save reload model), weights stored R matrices final object ‘dnn’ function. necessary ‘torch’ objects just pointers corresponding data structures. Naively, storing pointers pointless, R session ends, memory freed pointers meaningless.","code":""},{"path":[]},{"path":"/articles/A-Introduction_to_cito.html","id":"loss-functions-likelihoods","dir":"Articles","previous_headings":"Introduction to models and model structures","what":"Loss functions / Likelihoods","title":"Introduction to cito","text":"Cito can handle many different response types. Common loss functions ML also likelihoods statistical models supported: Moreover, non multilabel losses (except softmax cross-entropy) can modeled multilabel using cbind syntax dnn(cbind(Sepal.Length, Sepal.Width)~., …, loss = \"mse\") likelihoods (Gaussian, Binomial, Poisson) can also passed stats equivalents: dnn(Sepal.Length~., ..., loss = stats::gaussian)","code":""},{"path":"/articles/A-Introduction_to_cito.html","id":"data","dir":"Articles","previous_headings":"Introduction to models and model structures","what":"Data","title":"Introduction to cito","text":"vignette, work irirs dataset build regression model.","code":"data <- datasets::iris head(data) #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          5.1         3.5          1.4         0.2  setosa #> 2          4.9         3.0          1.4         0.2  setosa #> 3          4.7         3.2          1.3         0.2  setosa #> 4          4.6         3.1          1.5         0.2  setosa #> 5          5.0         3.6          1.4         0.2  setosa #> 6          5.4         3.9          1.7         0.4  setosa  #scale dataset data <- data.frame(scale(data[,-5]),Species = data[,5])"},{"path":"/articles/A-Introduction_to_cito.html","id":"fitting-a-simple-model","dir":"Articles","previous_headings":"Introduction to models and model structures","what":"Fitting a simple model","title":"Introduction to cito","text":"‘cito’, neural networks specified fitted dnn() function. Models can also trained GPU setting device = \"cuda\"(installed CUDA dependencies). suggested working large data sets networks. can plot network structure give visual feedback created object. e aware may take time large networks.  neural network 5 input nodes (3 continuoues features, Sepal.Width, Petal.Length, Petal.Width contrasts Species variable (n_classes - 1)) 1 output node response (Sepal.Length).","code":"library(cito)  #fitting a regression model to predict Sepal.Length nn.fit <- dnn(Sepal.Length~. , data = data, epochs = 12, loss = \"mse\", verbose=FALSE) plot(nn.fit)"},{"path":"/articles/A-Introduction_to_cito.html","id":"baseline-loss","dir":"Articles","previous_headings":"Introduction to models and model structures","what":"Baseline loss","title":"Introduction to cito","text":"start training calculate baseline loss intercept model. allows us control training goal beat baseline loss. don’t, need adjust optimization parameters (epochs lr (learning rate)): vs  See vignette(\"B-Training_neural_networks\") details adjust optimization procedure increase probability convergence.","code":"nn.fit <- dnn(Sepal.Length~. , data = data, epochs = 50, lr = 0.6, loss = \"mse\", verbose = FALSE) # lr too high nn.fit <- dnn(Sepal.Length~. , data = data, epochs = 50, lr = 0.01, loss = \"mse\", verbose = FALSE)"},{"path":"/articles/A-Introduction_to_cito.html","id":"adding-a-validation-set-to-the-training-process","dir":"Articles","previous_headings":"Introduction to models and model structures","what":"Adding a validation set to the training process","title":"Introduction to cito","text":"order see model might suffer overfitting addition validation set can useful. dnn() can put validation = 0.x define percentage used training validation epoch. training, loss plot show two losses behave (see vignette(\"B-Training_neural_networks\") details training NN guaranteeing convergence). Weights oft last epoch lowest validation loss saved: default use weights last epoch. can also tell model use weights lowest validation loss:","code":"#20% of data set is used as validation set nn.fit <- dnn(Sepal.Length~., data = data, epochs = 32,               loss= \"mse\", validation = 0.2) length(nn.fit$weights) #> [1] 2 nn.fit$use_model_epoch = 1 # Default, use last epoch nn.fit$use_model_epoch = 2 # Use weights from epoch with lowest validation loss"},{"path":"/articles/A-Introduction_to_cito.html","id":"methods","dir":"Articles","previous_headings":"Introduction to models and model structures","what":"Methods","title":"Introduction to cito","text":"cito supports many well-known methods statistical packages:","code":"predict(nn.fit) coef(nn.fit) print(nn.fit)"},{"path":"/articles/A-Introduction_to_cito.html","id":"explainable-ai---understanding-your-model","dir":"Articles","previous_headings":"","what":"Explainable AI - Understanding your model","title":"Introduction to cito","text":"xAI can produce outputs similar known outputs statistical models: summary() returns feature importance, ACE SDCE:","code":"# Calculate and return feature importance summary(nn.fit) #> Summary of Deep Neural Network Model #>  #> Feature Importance: #>       variable importance_1 #> 1  Sepal.Width     2.266942 #> 2 Petal.Length    19.364085 #> 3  Petal.Width     1.816410 #> 4      Species     1.101089 #>  #> Average Conditional Effects: #>              Response_1 #> Sepal.Width   0.3135183 #> Petal.Length  1.1674297 #> Petal.Width  -0.3144642 #>  #> Standard Deviation of Conditional Effects: #>              Response_1 #> Sepal.Width  0.05861976 #> Petal.Length 0.11233247 #> Petal.Width  0.05357466 #returns weights of neural network coef(nn.fit)"},{"path":"/articles/A-Introduction_to_cito.html","id":"uncertaintiesp-values","dir":"Articles","previous_headings":"Explainable AI - Understanding your model","what":"Uncertainties/p-Values","title":"Introduction to cito","text":"can use bootstrapping obtain uncertainties xAI metrics (also predictions). retrain model enabled bootstrapping: find Petal.Length Sepal.Width significant (categorical features supported yet average conditional effects). Let’s compare output statistical outputs: Feature importance anova report Petal.Length important feature. Visualization effects:   differences statistical model NN - expected NN can fit data flexible. time differences large confidence intervals (e.g. effect Petal.Width)","code":"df = data df[,2:4] = scale(df[,2:4]) # scaling can help the NN to convergence faster nn.fit <- dnn(Sepal.Length~., data = df,               epochs = 100,               verbose = FALSE,               loss= \"mse\",               bootstrap = 30L               ) summary(nn.fit) #> Summary of Deep Neural Network Model #>  #> ── Feature Importance #>                 Importance Std.Err Z value Pr(>|z|)     #> Sepal.Width →         1.58    0.44    3.59  0.00033 *** #> Petal.Length →       39.56    9.40    4.21  2.6e-05 *** #> Petal.Width →         1.62    1.37    1.19  0.23477     #> Species →             2.02    1.66    1.22  0.22359     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> ── Average Conditional Effects #>                     ACE Std.Err Z value Pr(>|z|)     #> Sepal.Width →    0.2834  0.0494    5.73  9.8e-09 *** #> Petal.Length →   1.5751  0.1557   10.11  < 2e-16 *** #> Petal.Width →   -0.2994  0.1557   -1.92    0.054 .   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> ── Standard Deviation of Conditional Effects #>                    ACE Std.Err Z value Pr(>|z|)     #> Sepal.Width →   0.1105  0.0250    4.42  9.9e-06 *** #> Petal.Length →  0.2062  0.0383    5.38  7.3e-08 *** #> Petal.Width →   0.0743  0.0209    3.55  0.00039 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 anova(lm(Sepal.Length~., data = df)) #> Analysis of Variance Table #>  #> Response: Sepal.Length #>               Df  Sum Sq Mean Sq  F value    Pr(>F)     #> Sepal.Width    1   2.060   2.060  15.0011 0.0001625 *** #> Petal.Length   1 123.127 123.127 896.8059 < 2.2e-16 *** #> Petal.Width    1   2.747   2.747  20.0055 1.556e-05 *** #> Species        2   1.296   0.648   4.7212 0.0103288 *   #> Residuals    144  19.770   0.137                        #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 PDP(nn.fit) library(effects) plot(allEffects(lm(Sepal.Length~., data = df)))"},{"path":"/articles/A-Introduction_to_cito.html","id":"architecture","dir":"Articles","previous_headings":"","what":"Architecture","title":"Introduction to cito","text":"architecture NN usually refers width depth hidden layers (layers input output layer) activation functions. can increase complexity NN adding layers /making wider:   definitive guide choosing right architecture right task. However, general rules/recommendations: general, wider, deeper neural networks can improve generalization - double-edged sword also increases risk overfitting. , increase width depth network, also add regularization (e.g., increasing lambda parameter, corresponds regularization strength). Furthermore, Pichler & Hartig, 2023, investigated effects hyperparameters prediction performance function data size. example, found selu activation function outperforms relu small data sizes (<100 observations). recommend starting moderate sizes (like defaults), model doesn’t generalize/converge, try larger networks along regularization helps minimize risk overfitting (see vignette(\"B-Training_neural_networks\") ).","code":"# \"simple NN\" - low complexity nn.fit <- dnn(Sepal.Length~., data = data, epochs = 100,               loss= \"mse\", validation = 0.2,               hidden = c(5L), verbose=FALSE) # \"large NN\" - high complexity nn.fit <- dnn(Sepal.Length~., data = data, epochs = 100,               loss= \"mse\", validation = 0.2,               hidden = c(100L, 100), verbose=FALSE)"},{"path":"/articles/A-Introduction_to_cito.html","id":"activation-functions","dir":"Articles","previous_headings":"Architecture","what":"Activation functions","title":"Introduction to cito","text":"default, layers fitted SeLU activation function. relu(x)=max(0,x) relu(x) = max (0,x) can also adjust activation function layer individually build exactly network want. case provide vector length hidden layers. activation function output layer chosen loss argument provided. Note: default activation function adequate tasks. don’t recommend tuning .","code":"#selu as activation function for all layers: nn.fit <- dnn(Sepal.Length~., data = data, hidden = c(10,10,10,10), activation= \"relu\") #layer specific activation functions: nn.fit <- dnn(Sepal.Length~., data = data,               hidden = c(10,10,10,10), activation= c(\"relu\",\"selu\",\"tanh\",\"sigmoid\"))"},{"path":[]},{"path":[]},{"path":"/articles/A-Introduction_to_cito.html","id":"elastic-net-regularization","dir":"Articles","previous_headings":"Tuning hyperparameters > Regularization","what":"Elastic net regularization","title":"Introduction to cito","text":"elastic net used, ‘cito’ produce sparse, generalized neural network. L1/L2 loss can controlled arguments alpha lambda. loss=λ*[(1−α)*|weights|+α|weights|2]  loss = \\lambda * [ (1 - \\alpha) * |weights| + \\alpha |weights|^2 ]","code":"#elastic net penalty in all layers: nn.fit <- dnn(Species~., data = data, alpha = 0.5, lambda = 0.01, verbose=FALSE, loss = \"softmax\")"},{"path":"/articles/A-Introduction_to_cito.html","id":"dropout-regularization","dir":"Articles","previous_headings":"Tuning hyperparameters > Regularization","what":"Dropout Regularization","title":"Introduction to cito","text":"Dropout regularization proposed Srivastava et al. can controlled similar elastic net regularization. approach, percentage different nodes gets left epoch.","code":"#dropout of 35% on all layers: nn.fit <- dnn(Species~., data = data, loss = \"softmax\", dropout = 0.35, verbose=FALSE)"},{"path":[]},{"path":"/articles/A-Introduction_to_cito.html","id":"learning-rate-scheduler","dir":"Articles","previous_headings":"Tuning hyperparameters","what":"Learning rate scheduler","title":"Introduction to cito","text":"Learning rate scheduler allow start high learning rate decrease training process. leads overall faster training. can choose different types schedulers. Namely, lambda, multiplicative, one_cycle step. function config_lr_scheduler() helps setup scheduler. See ?config_lr_scheduler() information","code":"# Step Learning rate scheduler that reduces learning rate every 16 steps by a factor of 0.5 scheduler <- config_lr_scheduler(type = \"step\",                                  step_size = 16,                                  gamma = 0.5)  nn.fit <- dnn(Sepal.Length~., data = data,lr = 0.01, lr_scheduler= scheduler, verbose = FALSE)"},{"path":"/articles/A-Introduction_to_cito.html","id":"optimizer","dir":"Articles","previous_headings":"Tuning hyperparameters","what":"Optimizer","title":"Introduction to cito","text":"Optimizer responsible fitting neural network. optimizer tries minimize loss function. default stochastic gradient descent used. Custom optimizers can used config_optimizer(). See ?config_optimizer() information.","code":"# adam optimizer with learning rate 0.002, betas to 0.95, 0.999 and eps to 1.5e-08 opt <- config_optimizer(   type = \"sgd\")  nn.fit <- dnn(Species~., data = data,  optimizer = opt, lr=0.002, verbose=FALSE, loss = \"softmax\")"},{"path":"/articles/A-Introduction_to_cito.html","id":"early-stopping","dir":"Articles","previous_headings":"Tuning hyperparameters","what":"Early Stopping","title":"Introduction to cito","text":"Adding early stopping criteria helps save time stopping training process early, validation loss current epoch bigger validation loss n epochs early. n can defined early_stopping argument. required set validation > 0.","code":"# Stops training if validation loss at current epoch is bigger than that 15 epochs earlier nn.fit <- dnn(Sepal.Length~., data = data, epochs = 1000,               validation = 0.2, early_stopping = 15, verbose=FALSE)"},{"path":"/articles/A-Introduction_to_cito.html","id":"automatic-hyperparameter-tuning-experimental","dir":"Articles","previous_headings":"","what":"Automatic hyperparameter tuning (experimental)","title":"Introduction to cito","text":"started support automatic hyperparameter tuning Cross Validation. tuning strategy random search, .e. potential hyperparameter values sampled uniform distributions, boundaries can specified user. can mark hyperparameters tuned cito setting values tune(), example dnn (..., lr = tune(). tune() function creates range random values given hyperparameter. can also change maximum minimum range values. following table lists hyperparameters can currently tuned: hyperparameters tuned random search (.e., random values hyperparameters within specified range) cross-validation. exact tuning regime can specified [config_tuning]. Note hyperparameter tuning can expensive. implemented option parallelize hyperparameter tuning, including parallelization one GPUs (hyperparameter evaluation parallelized, CV). can especially useful small models. example, 4 GPUs, 20 CPU cores, 20 steps (random samples random search), run dnn(..., device=\"cuda\",lr = tune(), batchsize=tune(), tuning=config_tuning(parallel=20, NGPU=4), distribute 20 model fits across 4 GPUs, GPU process 5 models (parallel). Tune learning rate one important hyperparameters: tuning, final model trained best set hyperparameters returned.","code":"nn.fit_tuned = dnn(Species~.,                    data = iris,                    lr = tune(0.0001, 0.1),                    loss = \"softmax\",                    tuning = config_tuning(steps = 3L, CV = 3L)) #> Starting hyperparameter tuning... #> Fitting final model..."},{"path":"/articles/A-Introduction_to_cito.html","id":"continue-training-process","dir":"Articles","previous_headings":"","what":"Continue training process","title":"Introduction to cito","text":"can continue training process existing model continue_training(). also allows change training parameters, example learning rate. can analyze training process analyze_training().","code":"# simple example, simply adding another 12 epochs to the training process nn.fit <- continue_training(nn.fit, epochs = 12, verbose=FALSE) head(predict(nn.fit)) #>            [,1] #> [1,] -1.0259458 #> [2,] -1.4077228 #> [3,] -1.3449415 #> [4,] -1.2816025 #> [5,] -0.9411238 #> [6,] -0.5879976 # picking the model with the smalles validation loss # with changed parameters, in this case a smaller learning rate and a smaller batchsize nn.fit <- continue_training(nn.fit,                             epochs = 32,                             changed_params = list(lr = 0.001, batchsize = 16),                             verbose = FALSE)"},{"path":"/articles/A-Introduction_to_cito.html","id":"the-best-of-both-worlds---combining-statistical-models-and-deep-learning","dir":"Articles","previous_headings":"","what":"The best of both worlds - combining statistical models and deep learning","title":"Introduction to cito","text":"addition common loss functions, also provide option using actual likelihoods - , assume DNN approximates underlying data generating model. important consequence - also ensure effects extracted xAI correct - check model assumptions, whether residuals distributed expect given likelihood/probability distribution. Example: Simulate negative binomial distribution fit poisson-DNN Fit model poisson likelihood:  can use DHARMa package check residuals. DHARMa support cito directly, can use general interface residual checks. first need simulate model:   Overdispersion (biased effect estimates inflated error rates consequence overdispersion) ! One solution (one implemented cito) switch negative binomial distribution fits variable dispersion parameter:  custom implementation negative binomial distribution (similar “nbinom1” glmmTMB (nbinom converges poisson dispersion parameters approaches infinity)) provide simulate function:   Better! still perfect, challenge maximum likelihood estimation negative binomial distribution get theta estimate (disperson parameter) unbiased. remaining pattern can probably explained fact overdispersion perfectly estimated. However, still better Poisson distribution, get switching negative binomial? p-values xAI metrics may strongly affected statistical model estimating standard errors (thus p-values) MLE surface. bootstrap independent likelihood. However, negative binomial distribution better weights overdispersed values, can expect model make accurate predictions.","code":"X = matrix(runif(500*3,-1,1), 500, 3) Y = rnbinom(500, mu = exp(2.5*X[,1]), size = 0.3) df = data.frame(Y = Y, X) m1 = dnn(Y~., data = df, loss = \"poisson\", lr = 0.005, epochs = 300L, verbose = FALSE) library(DHARMa) pred = predict(m1, type = \"response\") sims = sapply(1:100, function(i) rpois(length(pred), pred))  res = createDHARMa(sims, Y, pred[,1], integerResponse = TRUE) plot(res) testOverdispersion(res) #> testOverdispersion is deprecated, switch your code to using the testDispersion function #>  #>  DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated #>  #> data:  simulationOutput #> dispersion = 15.45, p-value < 2.2e-16 #> alternative hypothesis: two.sided m2 = dnn(Y~., data = df, loss = \"nbinom\", lr = 0.005, epochs = 300L, verbose = FALSE, lambda = 0.0, alpha = 1.0) # Dispersion parameter: m2$loss$parameter_link() #> [1] 0.5323167 pred = predict(m2, type = \"response\") sims = sapply(1:100, function(i) m2$loss$simulate(pred))  res = createDHARMa(sims, Y, pred[,1], integerResponse = TRUE) plot(res, rank = FALSE) testOverdispersion(res) #> testOverdispersion is deprecated, switch your code to using the testDispersion function #>  #>  DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated #>  #> data:  simulationOutput #> dispersion = 1.1972, p-value = 0.5 #> alternative hypothesis: two.sided"},{"path":"/articles/B-Training_neural_networks.html","id":"possible-issues","dir":"Articles","previous_headings":"","what":"Possible issues","title":"Training neural networks","text":"Convergence issues, (often learning rate), training loss baseline loss:  looks like , go adjusting learning rate section Overfitting, difference training testing/holdout/new data error high, validation loss first decreases increases :  loos like , go overfitting section","code":""},{"path":"/articles/B-Training_neural_networks.html","id":"lr","dir":"Articles","previous_headings":"","what":"Convergence issues","title":"Training neural networks","text":"Ensuring convergence can tricky training neural networks. training sensitive combination learning rate (much weights updated optimization step), batch size (random subset data used optimization step), number epochs (number optimization steps).","code":""},{"path":"/articles/B-Training_neural_networks.html","id":"epochs","dir":"Articles","previous_headings":"Convergence issues","what":"Epochs","title":"Training neural networks","text":"Give neural network enough time learn. epochs high enough training loss “stabilizes”:  10 epochs loss still decreasing, train model longer (increase epochs):  , takes around 190-200 epochs loss doesn’t decrease anymore. “speed” learning depends also learning rate. Higher rates means larger steps direction local minima loss function:  Now takes 100 epochs, also see training loss becomes wobbly. Larger learning rates increase probability local minima skipped optimizer problems hit minima. Note: learning rate high, high, loss get “jumpy”, risk optimizer jumping local minima increases (see next section).","code":"m = dnn(Species~., data = iris, epochs = 10L, loss = \"softmax\", verbose=FALSE) m = dnn(Species~., data = iris, epochs = 200L, loss = \"softmax\", verbose=FALSE) m = dnn(Species~., data = iris, epochs = 200L, loss = \"softmax\", lr = 0.05, verbose=FALSE)"},{"path":"/articles/B-Training_neural_networks.html","id":"learning-rate","dir":"Articles","previous_headings":"Convergence issues","what":"Learning rate","title":"Training neural networks","text":"Typically, learning rate decreased size neural networks (depth network width hidden layers). provide baseline loss (intercept model) can give hints appropriate learning rate.  training loss model doesn’t fall baseline loss, learning rate either high low. happens, try higher lower learning rates. common strategy try (manually) different learning rates see learning rate right scale.","code":"nn.fit_good<- dnn(Species~., data = datasets::iris, lr = 0.09, epochs = 20L, loss = \"softmax\", verbose = FALSE, plot = FALSE) nn.fit_high<- dnn(Species~., data = datasets::iris, lr = 2.09, epochs = 20L, loss = \"softmax\", verbose = FALSE, plot = FALSE) nn.fit_low<- dnn(Species~., data = datasets::iris, lr = 0.00000001, epochs = 20L, loss = \"softmax\", verbose = FALSE, plot = FALSE)  par(mfrow = c(1, 3), mar = c(4, 3, 2, 2)) cito:::visualize.training(nn.fit_good$losses,main=\"Training loss\", epoch = 20, new = TRUE, baseline = nn.fit_good$base_loss) cito:::visualize.training(nn.fit_high$losses,main=\"Training loss\", epoch = 20, new = TRUE, baseline = nn.fit_good$base_loss) cito:::visualize.training(nn.fit_low$losses,main=\"Training loss\", epoch = 20, new = TRUE, baseline = nn.fit_good$base_loss)"},{"path":"/articles/B-Training_neural_networks.html","id":"solution-learning-rate-scheduler","dir":"Articles","previous_headings":"Convergence issues","what":"Solution: learning rate scheduler","title":"Training neural networks","text":"common strategy deal learning rate problem start high learning rate, loss decrease, learning rate reduced according specific plan. favor “reduce learning rate plateau” scheduler. loss plateau isn’t resolved certain number epochs (patience), learning rate reduced (lrnew=factor*lroldlr_{new} = factor * lr_{old}):  end training, learning rate 0.025 Note: learning rate scheduler powerful approach improve likeliness convergence, help much high learning rates!  Although learning rate ended 0.01562, loss never outperformed baseline loss. optimizer jumped right beginning completely unrealistic solution space parameters NN, recover.","code":"nn.fit_high<- dnn(Species~., data = datasets::iris,                   lr = 0.2,                   epochs = 60L,                   loss = \"softmax\",                   lr_scheduler = config_lr_scheduler(\"reduce_on_plateau\", patience = 5, factor = 0.5),                   verbose = TRUE,                   plot = TRUE) #> Loss at epoch 1: 0.868813, lr: 0.20000 #> Loss at epoch 2: 0.607227, lr: 0.20000 #> Loss at epoch 3: 1.129801, lr: 0.20000 #> Loss at epoch 4: 0.498109, lr: 0.20000 #> Loss at epoch 5: 0.427480, lr: 0.20000 #> Loss at epoch 6: 0.505962, lr: 0.20000 #> Loss at epoch 7: 0.423542, lr: 0.20000 #> Loss at epoch 8: 0.398008, lr: 0.20000 #> Loss at epoch 9: 0.415886, lr: 0.20000 #> Loss at epoch 10: 0.310365, lr: 0.20000 #> Loss at epoch 11: 0.364727, lr: 0.20000 #> Loss at epoch 12: 0.405762, lr: 0.20000 #> Loss at epoch 13: 0.371685, lr: 0.20000 #> Loss at epoch 14: 0.606758, lr: 0.20000 #> Loss at epoch 15: 0.494564, lr: 0.20000 #> Loss at epoch 16: 0.386717, lr: 0.10000 #> Loss at epoch 17: 0.247253, lr: 0.10000 #> Loss at epoch 18: 0.196016, lr: 0.10000 #> Loss at epoch 19: 0.216442, lr: 0.10000 #> Loss at epoch 20: 0.229231, lr: 0.10000 #> Loss at epoch 21: 0.147426, lr: 0.10000 #> Loss at epoch 22: 0.168880, lr: 0.10000 #> Loss at epoch 23: 0.290900, lr: 0.10000 #> Loss at epoch 24: 0.279733, lr: 0.10000 #> Loss at epoch 25: 0.181382, lr: 0.10000 #> Loss at epoch 26: 0.274826, lr: 0.10000 #> Loss at epoch 27: 0.122269, lr: 0.10000 #> Loss at epoch 28: 0.278979, lr: 0.10000 #> Loss at epoch 29: 0.145546, lr: 0.10000 #> Loss at epoch 30: 0.232280, lr: 0.10000 #> Loss at epoch 31: 0.360600, lr: 0.10000 #> Loss at epoch 32: 0.133818, lr: 0.10000 #> Loss at epoch 33: 0.133925, lr: 0.05000 #> Loss at epoch 34: 0.117416, lr: 0.05000 #> Loss at epoch 35: 0.097019, lr: 0.05000 #> Loss at epoch 36: 0.095766, lr: 0.05000 #> Loss at epoch 37: 0.085271, lr: 0.05000 #> Loss at epoch 38: 0.081865, lr: 0.05000 #> Loss at epoch 39: 0.087199, lr: 0.05000 #> Loss at epoch 40: 0.086238, lr: 0.05000 #> Loss at epoch 41: 0.115600, lr: 0.05000 #> Loss at epoch 42: 0.101273, lr: 0.05000 #> Loss at epoch 43: 0.081162, lr: 0.05000 #> Loss at epoch 44: 0.093478, lr: 0.05000 #> Loss at epoch 45: 0.078520, lr: 0.05000 #> Loss at epoch 46: 0.112726, lr: 0.05000 #> Loss at epoch 47: 0.112692, lr: 0.05000 #> Loss at epoch 48: 0.093684, lr: 0.05000 #> Loss at epoch 49: 0.100669, lr: 0.05000 #> Loss at epoch 50: 0.081393, lr: 0.05000 #> Loss at epoch 51: 0.110707, lr: 0.02500 #> Loss at epoch 52: 0.079502, lr: 0.02500 #> Loss at epoch 53: 0.074759, lr: 0.02500 #> Loss at epoch 54: 0.071895, lr: 0.02500 #> Loss at epoch 55: 0.071452, lr: 0.02500 #> Loss at epoch 56: 0.072424, lr: 0.02500 #> Loss at epoch 57: 0.073547, lr: 0.02500 #> Loss at epoch 58: 0.073571, lr: 0.02500 #> Loss at epoch 59: 0.075333, lr: 0.02500 #> Loss at epoch 60: 0.071900, lr: 0.02500 nn.fit_high<- dnn(Species~., data = datasets::iris,                   lr = 2,                   epochs = 60L,                   loss = \"softmax\",                   lr_scheduler = config_lr_scheduler(\"reduce_on_plateau\", patience = 5, factor = 0.5),                   verbose = TRUE,                   plot = TRUE) #> Loss at epoch 1: 782.251417, lr: 2.00000 #> Loss at epoch 2: 3298.952477, lr: 2.00000 #> Loss at epoch 3: 258.680795, lr: 2.00000 #> Loss at epoch 4: 90.482500, lr: 2.00000 #> Loss at epoch 5: 25.033280, lr: 2.00000 #> Loss at epoch 6: 14.902886, lr: 2.00000 #> Loss at epoch 7: 14.502181, lr: 2.00000 #> Loss at epoch 8: 11.076120, lr: 2.00000 #> Loss at epoch 9: 12.562866, lr: 2.00000 #> Loss at epoch 10: 11.093193, lr: 2.00000 #> Loss at epoch 11: 9.510224, lr: 2.00000 #> Loss at epoch 12: 12.989465, lr: 2.00000 #> Loss at epoch 13: 13.282229, lr: 2.00000 #> Loss at epoch 14: 9.262714, lr: 2.00000 #> Loss at epoch 15: 9.705650, lr: 2.00000 #> Loss at epoch 16: 14.090702, lr: 2.00000 #> Loss at epoch 17: 12.523569, lr: 2.00000 #> Loss at epoch 18: 12.015066, lr: 2.00000 #> Loss at epoch 19: 14.319363, lr: 2.00000 #> Loss at epoch 20: 9.328203, lr: 1.00000 #> Loss at epoch 21: 7.450138, lr: 1.00000 #> Loss at epoch 22: 5.726156, lr: 1.00000 #> Loss at epoch 23: 5.152872, lr: 1.00000 #> Loss at epoch 24: 6.538125, lr: 1.00000 #> Loss at epoch 25: 4.690747, lr: 1.00000 #> Loss at epoch 26: 4.736277, lr: 1.00000 #> Loss at epoch 27: 6.920749, lr: 1.00000 #> Loss at epoch 28: 6.986071, lr: 1.00000 #> Loss at epoch 29: 4.831617, lr: 1.00000 #> Cancel training because loss is still above baseline, please hyperparameters. See vignette('B-Training_neural_networks') for help."},{"path":"/articles/B-Training_neural_networks.html","id":"overfitting","dir":"Articles","previous_headings":"","what":"Overfitting","title":"Training neural networks","text":"Overfitting means model fits training data well, generalizes poorly new observations. can use validation argument detect overfitting. validation loss starts increase certain point, often means models starting overfit training data:  Solutions: Re-train epochs = point model started overfit Early stopping, stop training model starts overfit, can specified using ⁠early_stopping=…⁠ argument Use regularization (dropout elastic-net, see next section)","code":"library(EcoData) # can be install from github using devtools::install_github(repo = \"TheoreticalEcology/EcoData\", dependencies = FALSE, build_vignettes = FALSE) df = elephant$occurenceData m = dnn(Presence~., data = df, lr = 0.03, epochs = 600L, loss = \"binomial\", validation = 0.2,  hidden = c(350L, 350L, 350L), activation = \"relu\", batchsize = 150L, verbose = FALSE, plot = TRUE)"},{"path":"/articles/B-Training_neural_networks.html","id":"early-stopping-and-regularization","dir":"Articles","previous_headings":"Overfitting","what":"Early stopping and regularization","title":"Training neural networks","text":"Early stopping = stop training validation loss improved x epochs (validation split, training loss used). lambda = 0.001 regularization strength alpha = 0.2 means 20% L1 80% L2 weighting.  training aborted!","code":"m = dnn(Presence~., data = df, lr = 0.03, epochs = 600L, loss = \"binomial\", validation = 0.2,  hidden = c(350L, 350L, 350L), activation = \"relu\", batchsize = 150L, verbose = FALSE, plot = TRUE, early_stopping = 10, lambda = 0.001, alpha = 0.2)"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"species-distribution-model---african-elephant","dir":"Articles","previous_headings":"","what":"Species distribution model - African elephant","title":"Example: (Multi-) Species distribution models with cito","text":"goal build SDM African elephant. pre-processed dataset Angelov, 2020 can found EcoData package available github: Presence response variable 19 bioclim variables features/predictors. Let’s split part data away can use end evaluate model:","code":"set.seed(1337) if(!require(EcoData)) devtools::install_github(repo = \"TheoreticalEcology/EcoData\",                          dependencies = FALSE, build_vignettes = FALSE) #> Loading required package: EcoData  library(EcoData) df = EcoData::elephant$occurenceData head(df) #>       Presence       bio1       bio2       bio3       bio4        bio5       bio6       bio7       bio8       bio9       bio10       bio11      bio12 #> 3364         0 -0.4981747 -0.2738045  0.5368968 -0.5409999 -0.36843571  0.2947850 -0.5260099 -1.2253960  0.2494100 -0.64527314 -0.06267842  0.6285371 #> 6268         0  0.6085908 -0.5568352  1.0340686 -1.2492050 -0.11835651  0.8221087 -0.8938475  0.4233787  0.7746249  0.09168503  0.94419518  1.1121516 #> 10285        0 -0.7973005  1.4648130 -1.0540532  2.0759423  0.07614953 -1.5860029  1.6284678  0.2768209 -1.5153122 -0.03648161 -1.44165748 -1.2351482 #> 2247         0  0.6385034  1.3435141 -0.1591439 -0.5107148  1.10425291 -0.1622288  0.8577603  0.4600181  0.5855475  0.54026827  0.68153250  0.5951165 #> 9821         0  0.6684160 -0.6781341  0.6363311 -0.9906170  0.15950927  0.9099960 -0.8062671  0.3867393  0.8586593  0.31597665  0.94419518  1.1003561 #> 1351         0  0.9675418 -0.6781341 -0.3580126 -0.3748202  0.77081398  0.8748411 -0.3858812  0.3134604  1.0477367  0.98885151  0.94419518  0.7287986 #>            bio13       bio14        bio15      bio16      bio17       bio18       bio19 #> 3364   0.6807958 -0.29703736 -0.008455252  0.7124535 -0.2949994 -1.06812752  1.96201807 #> 6268   0.5918442  0.01619202 -0.884507980  0.5607328  0.3506918  1.22589281 -0.36205814 #> 10285 -1.3396742 -0.50585695  0.201797403 -1.3499999 -0.5616980 -0.42763181 -0.62895735 #> 2247   0.8714061 -0.55806185  0.236839512  1.1012378 -0.5616980 -0.20541902 -0.58378979 #> 9821   0.5537222  0.59044589 -1.024676416  0.6413344  0.7437213  0.06254347 -0.05409751 #> 1351   1.1255533 -0.50585695  0.236839512  1.2956300 -0.4494038 -0.90473576  2.47939193 indices = sample.int(nrow(df), 300) test = df[indices,] df = df[-indices,]"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"adjusting-optimization-parameters---convergence","dir":"Articles","previous_headings":"Species distribution model - African elephant","what":"Adjusting optimization parameters - Convergence","title":"Example: (Multi-) Species distribution models with cito","text":"first try simple DNN default values binomial likelihood. use 30% data validation holdout check overfitting:  see training test losses still decreasing means didn’t train model long enough. now either increase number epochs increase learning rate model trains faster:  Much better! still now enough epochs. Also, let’s see can decrease loss using wider deeper neural network:  end training, losses start get jumpy, can sign potential overfitting. can control adding weak regularization (want L2 regularization, set alpha 1.0):  turn now advanced features help convergence reduce overfitting: learning rate scheduler - reduces learning rate training early stopping - stop training validation loss starts increase  Great! found now model architecture training procedure fits trains well. Let’s proceed final model","code":"library(cito) model = dnn(Presence~., data = df,             batchsize = 100L,             validation = 0.3, loss = \"binomial\",             verbose = FALSE) model = dnn(Presence~., data = df,             batchsize = 100L,             lr = 0.05,             validation = 0.3, loss = \"binomial\",             verbose = FALSE) model = dnn(Presence~., data = df,             batchsize = 100L,             hidden = c(100L, 100L, 100L),             lr = 0.05,             validation = 0.3, loss = \"binomial\",             verbose = FALSE) model = dnn(Presence~., data = df,             batchsize = 100L,             epochs = 150L,             hidden = c(100L, 100L, 100L),             lr = 0.05,             lambda = 0.001,             alpha = 1.0,             validation = 0.3, loss = \"binomial\",             verbose = FALSE) model = dnn(Presence~., data = df,             batchsize = 100L,             epochs = 150L,             hidden = c(100L, 100L, 100L),             lr = 0.05,             lambda = 0.001,             alpha = 1.0,             validation = 0.3, loss = \"binomial\",             verbose = FALSE,             lr_scheduler = config_lr_scheduler(\"reduce_on_plateau\", patience = 7), # reduce learning rate each 7 epochs if the validation loss didn't decrease,             early_stopping = 14 # stop training when validation loss didn't decrease for 10 epochs             )"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"train-final-model-with-bootstrapping-to-obtain-uncertainties","dir":"Articles","previous_headings":"Species distribution model - African elephant","what":"Train final model with bootstrapping to obtain uncertainties","title":"Example: (Multi-) Species distribution models with cito","text":"haven’t directly started bootstrapping complicates adjustment training procedure. Uncertainties can obtained using bootstrapping. aware can computational expensive:","code":"model_boot = dnn(Presence~., data = df,                  batchsize = 100L,                  epochs = 150L,                  hidden = c(100L, 100L, 100L),                  lr = 0.05,                  lambda = 0.001,                  alpha = 1.0,                  validation = 0.3, loss = \"binomial\",                  verbose = FALSE,                  lr_scheduler = config_lr_scheduler(\"reduce_on_plateau\", patience = 7), # reduce learning rate each 7 epochs if the validation loss didn't decrease,                  early_stopping = 14, # stop training when validation loss didn't decrease for 10 epochs                  bootstrap = 20L,                  bootstrap_parallel = 5L             )"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"predictions","dir":"Articles","previous_headings":"Species distribution model - African elephant","what":"Predictions","title":"Example: (Multi-) Species distribution models with cito","text":"can use model now predictions: predictions 2/3 dimensional bootstrapping. Calculate AUC interval:  can now predict habitat suitability elephant (Note spatial dependencies required):  Moreover, can visualize uncertainty model, instead calculating average occurrence probability, calculate prediction standard deviation visualize :","code":"predictions = predict(model_boot, newdata = test, reduce = \"none\") dim(predictions) #> [1]  20 300   1 hist(sapply(1:20, function(i) Metrics::auc(test$Presence, predictions[i,,])),      xlim = c(0, 1), main = \"AUC of ensemble model\", xlab = \"AUC\") library(raster) #> Loading required package: sp library(sp) library(rsample) library(latticeExtra) #> Loading required package: lattice #>  #> Attaching package: 'lattice' #> The following object is masked from 'package:EcoData': #>  #>     melanoma library(sp) library(ggplot2) #> Need help getting started? Try the R Graphics Cookbook: https://r-graphics.org #>  #> Attaching package: 'ggplot2' #> The following object is masked from 'package:latticeExtra': #>  #>     layer library(maptools) #> Please note that 'maptools' will be retired during October 2023, #> plan transition at your earliest convenience (see #> https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs #> for guidance);some functionality will be moved to 'sp'. #>  Checking rgeos availability: FALSE customPredictFun = function(model, data) {   return(apply(predict(model, data, reduce = \"none\"), 2:3, mean)[,1]) }  normalized_raster = EcoData::elephant$predictionData  predictions =   raster::predict(normalized_raster,                   model_boot,                   fun = customPredictFun)  habitat_plot =   spplot(predictions, colorkey = list(space = \"left\") ) habitat_plot customPredictFun_sd = function(model, data) {   return(apply(predict(model, data, reduce=\"none\"), 2:3, sd)[,1]) } predictions =   raster::predict(normalized_raster,                   model_boot,                   fun = customPredictFun_sd)  uncertain_plot =   spplot(predictions, colorkey = list(space = \"left\") ) uncertain_plot"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"inference","dir":"Articles","previous_headings":"Species distribution model - African elephant","what":"Inference","title":"Example: (Multi-) Species distribution models with cito","text":"Neural networks often called black-box models tools explainable AI (xAI) allows us understand - actually infer properties similar linear regression model can provide (calculation can take time…): Bioclim9, 12, 14, 16 large significant average conditional effects ($\\approx$ linear effects). can visualize using accumulated local effect plots:","code":"results = summary(model_boot) results #> Summary of Deep Neural Network Model #>  #> ── Feature Importance #>          Importance Std.Err Z value Pr(>|z|)     #> bio1 →       0.5671  0.2955    1.92  0.05493 .   #> bio2 →       0.3368  0.2757    1.22  0.22188     #> bio3 →       0.1971  0.1093    1.80  0.07128 .   #> bio4 →       0.2896  0.1992    1.45  0.14594     #> bio5 →       0.6996  0.3356    2.09  0.03707 *   #> bio6 →       0.5888  0.4589    1.28  0.19940     #> bio7 →       0.1762  0.1117    1.58  0.11486     #> bio8 →       0.3758  0.1940    1.94  0.05270 .   #> bio9 →       2.5090  1.4337    1.75  0.08012 .   #> bio10 →      0.3349  0.2130    1.57  0.11585     #> bio11 →      0.2795  0.2177    1.28  0.19921     #> bio12 →      1.9087  0.6461    2.95  0.00314 **  #> bio13 →      0.3197  0.1760    1.82  0.06924 .   #> bio14 →      0.4169  0.2696    1.55  0.12200     #> bio15 →      0.8942  0.2640    3.39  0.00071 *** #> bio16 →      0.3672  0.3013    1.22  0.22299     #> bio17 →      0.1733  0.1445    1.20  0.23038     #> bio18 →      0.2410  0.1145    2.10  0.03536 *   #> bio19 →      0.0645  0.0355    1.82  0.06914 .   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> ── Average Conditional Effects #>               ACE  Std.Err Z value Pr(>|z|)     #> bio1 →    0.09733  0.03226    3.02  0.00256 **  #> bio2 →   -0.05851  0.03811   -1.54  0.12465     #> bio3 →   -0.00413  0.03759   -0.11  0.91261     #> bio4 →    0.03089  0.03336    0.93  0.35445     #> bio5 →    0.11839  0.03709    3.19  0.00141 **  #> bio6 →    0.09144  0.04549    2.01  0.04443 *   #> bio7 →    0.00310  0.03884    0.08  0.93644     #> bio8 →   -0.04861  0.03167   -1.54  0.12475     #> bio9 →   -0.18590  0.05309   -3.50  0.00046 *** #> bio10 →  -0.03716  0.04174   -0.89  0.37333     #> bio11 →   0.02729  0.04083    0.67  0.50397     #> bio12 →  -0.19637  0.03947   -4.97  6.5e-07 *** #> bio13 →   0.07646  0.03118    2.45  0.01420 *   #> bio14 →   0.09271  0.04582    2.02  0.04302 *   #> bio15 →  -0.09483  0.02640   -3.59  0.00033 *** #> bio16 →  -0.05575  0.04044   -1.38  0.16803     #> bio17 →   0.03714  0.04335    0.86  0.39166     #> bio18 →   0.02949  0.01743    1.69  0.09069 .   #> bio19 →   0.00413  0.02446    0.17  0.86604     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> ── Standard Deviation of Conditional Effects #>             ACE Std.Err Z value Pr(>|z|)     #> bio1 →   0.1238  0.0321    3.86  0.00012 *** #> bio2 →   0.0827  0.0331    2.50  0.01243 *   #> bio3 →   0.0548  0.0230    2.38  0.01734 *   #> bio4 →   0.0717  0.0258    2.77  0.00553 **  #> bio5 →   0.1366  0.0359    3.81  0.00014 *** #> bio6 →   0.1116  0.0438    2.55  0.01081 *   #> bio7 →   0.0565  0.0206    2.74  0.00618 **  #> bio8 →   0.0946  0.0224    4.22  2.5e-05 *** #> bio9 →   0.2123  0.0601    3.53  0.00041 *** #> bio10 →  0.0792  0.0235    3.37  0.00076 *** #> bio11 →  0.0859  0.0205    4.18  2.9e-05 *** #> bio12 →  0.2167  0.0356    6.08  1.2e-09 *** #> bio13 →  0.0877  0.0267    3.28  0.00102 **  #> bio14 →  0.1134  0.0380    2.98  0.00285 **  #> bio15 →  0.1093  0.0189    5.79  7.0e-09 *** #> bio16 →  0.0808  0.0343    2.35  0.01856 *   #> bio17 →  0.0671  0.0291    2.30  0.02123 *   #> bio18 →  0.0949  0.0265    3.59  0.00033 *** #> bio19 →  0.0380  0.0152    2.50  0.01257 *   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 par(mfrow = c(1, 4)) ALE(model_boot, variable = \"bio9\") ALE(model_boot, variable = \"bio12\") ALE(model_boot, variable = \"bio14\") ALE(model_boot, variable = \"bio16\")"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"multi-species-distribution-model","dir":"Articles","previous_headings":"","what":"Multi-species distribution model","title":"Example: (Multi-) Species distribution models with cito","text":"Cito supports many different loss functions can use build multi-species distribution models (MSDM). MSDM multi-label, .e. model predict simultaneously many responses. use eucalypts data Pollock et al., 2014. dataset occurrence 12 species 458 sites. Bring data format usable cito: use binomial likelihood - species occurrence data modelled binomial likelihood. Build simple model:  Plot model:  NN now 12 output nodes, one species.","code":"load(url(\"https://github.com/TheoreticalEcology/s-jSDM/raw/master/sjSDM/data/eucalypts.rda\")) # Environment head(eucalypts$env) #>   Rockiness Sandiness VallyBotFlat PPTann Loaminess cvTemp      T0 #> 1        60         1            0    785         0    142 6124.01 #> 2        75         1            0    785         0    142 6124.01 #> 3        70         1            0    780         0    142 3252.96 #> 4        40         1            0    778         0    142 1636.63 #> 5        15         1            0    772         0    142 1352.08 #> 6        80         1            0    841         0    142 5018.48  # PA head(eucalypts$PA) #>      ALA ARE BAX CAM GON MEL OBL OVA WIL ALP VIM ARO.SAB #> [1,]   0   0   0   0   0   0   0   0   1   1   0       0 #> [2,]   0   0   0   0   0   0   1   0   1   1   0       0 #> [3,]   0   0   1   0   0   0   0   0   1   1   0       0 #> [4,]   0   0   1   0   0   0   0   0   1   0   0       0 #> [5,]   0   0   1   0   0   0   1   0   0   0   0       0 #> [6,]   0   0   0   0   0   0   0   0   1   1   0       0 df = cbind(eucalypts$PA, scale(eucalypts$env)) head(df) #>      ALA ARE BAX CAM GON MEL OBL OVA WIL ALP VIM ARO.SAB  Rockiness Sandiness VallyBotFlat       PPTann  Loaminess    cvTemp         T0 #> [1,]   0   0   0   0   0   0   0   0   1   1   0       0  1.0315338 0.5716827   -0.5939667 -0.005981517 -0.2134535 -1.056073  0.5378148 #> [2,]   0   0   0   0   0   0   1   0   1   1   0       0  1.4558834 0.5716827   -0.5939667 -0.005981517 -0.2134535 -1.056073  0.5378148 #> [3,]   0   0   1   0   0   0   0   0   1   1   0       0  1.3144335 0.5716827   -0.5939667 -0.045456081 -0.2134535 -1.056073 -0.3404551 #> [4,]   0   0   1   0   0   0   0   0   1   0   0       0  0.4657344 0.5716827   -0.5939667 -0.061245907 -0.2134535 -1.056073 -0.8348993 #> [5,]   0   0   1   0   0   0   1   0   0   0   0       0 -0.2415148 0.5716827   -0.5939667 -0.108615385 -0.2134535 -1.056073 -0.9219447 #> [6,]   0   0   0   0   0   0   0   0   1   1   0       0  1.5973333 0.5716827   -0.5939667  0.436133605 -0.2134535 -1.056073  0.1996271 model = dnn(cbind(ALA, ARE, BAX, CAM, GON, MEL, OBL, OVA, WIL, ALP, VIM, ARO.SAB)~.,             data = df,             lr = 0.1,             verbose = FALSE,             loss = \"binomial\") plot(model) head(predict(model)) #>           [,1]      [,2]        [,3]      [,4]      [,5]      [,6]         [,7]      [,8]        [,9]      [,10]     [,11]     [,12] #> [1,] -1.836887 -4.988176  0.32807234 -5.222610 -5.308745 -4.067790 -0.867894590 -4.736314 -0.61683136 -1.0782812 -3.910664 -3.400055 #> [2,] -1.657390 -4.839282  0.08797990 -5.386761 -4.938032 -4.516629 -1.182702303 -4.994690 -0.84761620 -0.3660365 -4.247718 -4.020841 #> [3,] -2.085413 -5.099712  0.15239546 -5.287928 -5.096430 -4.624372 -1.044999719 -4.999919 -0.66758049 -0.6565972 -4.395789 -3.780074 #> [4,] -2.725661 -5.414782  0.62847829 -4.861598 -5.769506 -3.869004 -0.428146392 -4.516877 -0.22675626 -2.3427727 -3.797922 -2.450565 #> [5,] -3.021702 -5.423952  1.02425063 -4.336437 -6.150292 -2.892931 -0.006421283 -3.893203  0.08195837 -3.6905608 -3.047264 -1.228144 #> [6,] -1.672060 -4.829151 -0.08096267 -5.475241 -4.819751 -5.006217 -1.395022869 -5.176019 -0.99880135  0.4147617 -4.579223 -4.475727"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"train-model-with-bootstrapping","dir":"Articles","previous_headings":"Multi-species distribution model","what":"Train model with bootstrapping","title":"Example: (Multi-) Species distribution models with cito","text":"haven’t really adjusted training procedure, let’s check convergence first:","code":"model_boot = dnn(cbind(ALA, ARE, BAX, CAM, GON, MEL, OBL, OVA, WIL, ALP, VIM, ARO.SAB)~.,                  data = df,                  loss = \"binomial\",                                   epochs = 200L,                  hidden = c(50L, 50L),                  batchsize = 50L,                  lr = 0.1,                  lambda = 0.001,                  alpha = 1.0,                  validation = 0.2,                  verbose = FALSE,                  lr_scheduler = config_lr_scheduler(\"reduce_on_plateau\", patience = 7), # reduce learning rate each 7 epochs if the validation loss didn't decrease,                  early_stopping = 14, # stop training when validation loss didn't decrease for 10 epochs                  bootstrap = 20L,                  bootstrap_parallel = 5L) analyze_training(model_boot)"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"inference-1","dir":"Articles","previous_headings":"Multi-species distribution model","what":"Inference","title":"Example: (Multi-) Species distribution models with cito","text":"cvTemp significant many species. Visualization effect:","code":"results = summary(model_boot) results #> Summary of Deep Neural Network Model #>  #> ── Feature Importance #>                        Importance Std.Err Z value Pr(>|z|)     #> Rockiness → ALA           0.05591 0.03510    1.59  0.11123     #> Sandiness → ALA           0.01819 0.02898    0.63  0.53031     #> VallyBotFlat → ALA        0.07302 0.04190    1.74  0.08140 .   #> PPTann → ALA              0.01665 0.02027    0.82  0.41153     #> Loaminess → ALA           0.01670 0.01386    1.20  0.22830     #> cvTemp → ALA              0.03050 0.02471    1.23  0.21724     #> T0 → ALA                  0.05909 0.03446    1.71  0.08643 .   #>                                                                #> Rockiness → ARE           0.03587 0.02774    1.29  0.19595     #> Sandiness → ARE           0.04953 0.05938    0.83  0.40421     #> VallyBotFlat → ARE        0.06833 0.04268    1.60  0.10935     #> PPTann → ARE              0.03399 0.03270    1.04  0.29861     #> Loaminess → ARE           0.03420 0.01897    1.80  0.07134 .   #> cvTemp → ARE              1.25189 0.46022    2.72  0.00652 **  #> T0 → ARE                  0.03928 0.03372    1.16  0.24413     #>                                                                #> Rockiness → BAX           0.09881 0.05129    1.93  0.05403 .   #> Sandiness → BAX           0.09485 0.03736    2.54  0.01113 *   #> VallyBotFlat → BAX        0.17888 0.05286    3.38  0.00071 *** #> PPTann → BAX              0.01467 0.01240    1.18  0.23667     #> Loaminess → BAX           0.00538 0.00588    0.92  0.35944     #> cvTemp → BAX              0.18118 0.06824    2.66  0.00793 **  #> T0 → BAX                  0.00563 0.00475    1.18  0.23606     #>                                                                #> Rockiness → CAM           0.06633 0.03476    1.91  0.05635 .   #> Sandiness → CAM           0.25162 0.10085    2.50  0.01259 *   #> VallyBotFlat → CAM        0.36023 0.14501    2.48  0.01298 *   #> PPTann → CAM              0.02242 0.02065    1.09  0.27754     #> Loaminess → CAM           0.02145 0.02064    1.04  0.29849     #> cvTemp → CAM              0.00418 0.00657    0.64  0.52476     #> T0 → CAM                  0.01695 0.01211    1.40  0.16144     #>                                                                #> Rockiness → GON           0.23601 0.12185    1.94  0.05276 .   #> Sandiness → GON           0.02487 0.04504    0.55  0.58078     #> VallyBotFlat → GON        0.10855 0.05694    1.91  0.05660 .   #> PPTann → GON              0.15407 0.11052    1.39  0.16330     #> Loaminess → GON           0.05577 0.03523    1.58  0.11346     #> cvTemp → GON              2.14793 0.74598    2.88  0.00399 **  #> T0 → GON                  0.02103 0.02102    1.00  0.31709     #>                                                                #> Rockiness → MEL           0.17740 0.07674    2.31  0.02079 *   #> Sandiness → MEL           0.02014 0.01699    1.19  0.23577     #> VallyBotFlat → MEL        0.01139 0.01082    1.05  0.29247     #> PPTann → MEL              0.04085 0.02205    1.85  0.06398 .   #> Loaminess → MEL           0.02822 0.01559    1.81  0.07029 .   #> cvTemp → MEL              0.02804 0.02145    1.31  0.19109     #> T0 → MEL                  0.03865 0.04112    0.94  0.34727     #>                                                                #> Rockiness → OBL           0.11460 0.06456    1.78  0.07586 .   #> Sandiness → OBL           0.02254 0.01224    1.84  0.06553 .   #> VallyBotFlat → OBL        0.09752 0.04155    2.35  0.01891 *   #> PPTann → OBL              0.01894 0.01465    1.29  0.19605     #> Loaminess → OBL           0.06726 0.04543    1.48  0.13879     #> cvTemp → OBL              0.22548 0.08677    2.60  0.00936 **  #> T0 → OBL                  0.00581 0.00586    0.99  0.32135     #>                                                                #> Rockiness → OVA           0.11048 0.03845    2.87  0.00406 **  #> Sandiness → OVA           0.16389 0.09224    1.78  0.07561 .   #> VallyBotFlat → OVA        0.11062 0.05946    1.86  0.06283 .   #> PPTann → OVA              0.01255 0.01587    0.79  0.42927     #> Loaminess → OVA           0.03811 0.01947    1.96  0.05027 .   #> cvTemp → OVA              0.00684 0.01811    0.38  0.70577     #> T0 → OVA                  0.00574 0.00688    0.83  0.40387     #>                                                                #> Rockiness → WIL           0.03170 0.02511    1.26  0.20670     #> Sandiness → WIL           0.02764 0.01915    1.44  0.14895     #> VallyBotFlat → WIL        0.05395 0.02662    2.03  0.04267 *   #> PPTann → WIL              0.02771 0.01524    1.82  0.06902 .   #> Loaminess → WIL           0.04921 0.03098    1.59  0.11220     #> cvTemp → WIL              0.64483 0.17280    3.73  0.00019 *** #> T0 → WIL                  0.00978 0.00968    1.01  0.31246     #>                                                                #> Rockiness → ALP           1.33898 0.45270    2.96  0.00310 **  #> Sandiness → ALP           0.02993 0.02998    1.00  0.31820     #> VallyBotFlat → ALP        0.07775 0.06459    1.20  0.22870     #> PPTann → ALP              0.83178 0.25272    3.29  0.00100 *** #> Loaminess → ALP           0.03192 0.03546    0.90  0.36808     #> cvTemp → ALP              0.11859 0.06806    1.74  0.08144 .   #> T0 → ALP                  0.02064 0.01572    1.31  0.18925     #>                                                                #> Rockiness → VIM           0.11096 0.03613    3.07  0.00214 **  #> Sandiness → VIM           0.11823 0.05786    2.04  0.04102 *   #> VallyBotFlat → VIM        0.03927 0.03977    0.99  0.32345     #> PPTann → VIM              0.01356 0.01253    1.08  0.27921     #> Loaminess → VIM           0.05022 0.01879    2.67  0.00751 **  #> cvTemp → VIM              0.01314 0.01189    1.11  0.26914     #> T0 → VIM                  0.01542 0.01302    1.18  0.23648     #>                                                                #> Rockiness → ARO.SAB       0.30750 0.07678    4.01  6.2e-05 *** #> Sandiness → ARO.SAB       0.02214 0.01923    1.15  0.24977     #> VallyBotFlat → ARO.SAB    0.16434 0.07468    2.20  0.02776 *   #> PPTann → ARO.SAB          0.07733 0.04191    1.85  0.06501 .   #> Loaminess → ARO.SAB       0.00689 0.00914    0.75  0.45086     #> cvTemp → ARO.SAB          0.23335 0.08098    2.88  0.00396 **  #> T0 → ARO.SAB              0.01032 0.00978    1.06  0.29141     #>                                                                #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> ── Average Conditional Effects #>                              ACE   Std.Err Z value Pr(>|z|)     #> Rockiness → ALA         0.022009  0.011727    1.88  0.06055 .   #> Sandiness → ALA         0.000475  0.015970    0.03  0.97628     #> VallyBotFlat → ALA     -0.040763  0.016232   -2.51  0.01203 *   #> PPTann → ALA            0.010853  0.010901    1.00  0.31945     #> Loaminess → ALA        -0.023536  0.012049   -1.95  0.05078 .   #> cvTemp → ALA            0.022284  0.012757    1.75  0.08068 .   #> T0 → ALA                0.024279  0.009628    2.52  0.01167 *   #>                                                                 #> Rockiness → ARE         0.004097  0.014343    0.29  0.77515     #> Sandiness → ARE         0.016287  0.010944    1.49  0.13669     #> VallyBotFlat → ARE     -0.027409  0.011461   -2.39  0.01678 *   #> PPTann → ARE           -0.006271  0.009138   -0.69  0.49252     #> Loaminess → ARE        -0.027573  0.012705   -2.17  0.02999 *   #> cvTemp → ARE            0.088176  0.018124    4.87  1.1e-06 *** #> T0 → ARE                0.011037  0.011154    0.99  0.32241     #>                                                                 #> Rockiness → BAX        -0.087220  0.029893   -2.92  0.00353 **  #> Sandiness → BAX         0.089410  0.019960    4.48  7.5e-06 *** #> VallyBotFlat → BAX     -0.126835  0.019717   -6.43  1.3e-10 *** #> PPTann → BAX           -0.017420  0.022320   -0.78  0.43510     #> Loaminess → BAX        -0.009810  0.018394   -0.53  0.59380     #> cvTemp → BAX           -0.123235  0.023233   -5.30  1.1e-07 *** #> T0 → BAX                0.003709  0.016590    0.22  0.82308     #>                                                                 #> Rockiness → CAM        -0.033868  0.010889   -3.11  0.00187 **  #> Sandiness → CAM        -0.039071  0.010464   -3.73  0.00019 *** #> VallyBotFlat → CAM      0.042429  0.008675    4.89  1.0e-06 *** #> PPTann → CAM           -0.018928  0.010994   -1.72  0.08512 .   #> Loaminess → CAM        -0.016836  0.007736   -2.18  0.02953 *   #> cvTemp → CAM            0.000116  0.006826    0.02  0.98640     #> T0 → CAM               -0.004428  0.008660   -0.51  0.60915     #>                                                                 #> Rockiness → GON         0.026573  0.008300    3.20  0.00137 **  #> Sandiness → GON         0.006518  0.009327    0.70  0.48466     #> VallyBotFlat → GON     -0.024043  0.010133   -2.37  0.01765 *   #> PPTann → GON           -0.015254  0.009903   -1.54  0.12346     #> Loaminess → GON        -0.024562  0.009682   -2.54  0.01118 *   #> cvTemp → GON            0.080506  0.014910    5.40  6.7e-08 *** #> T0 → GON                0.003805  0.008977    0.42  0.67169     #>                                                                 #> Rockiness → MEL        -0.079029  0.027386   -2.89  0.00390 **  #> Sandiness → MEL         0.017185  0.015587    1.10  0.27023     #> VallyBotFlat → MEL      0.001956  0.014723    0.13  0.89432     #> PPTann → MEL           -0.037932  0.013843   -2.74  0.00614 **  #> Loaminess → MEL        -0.035711  0.012857   -2.78  0.00548 **  #> cvTemp → MEL            0.022832  0.010397    2.20  0.02809 *   #> T0 → MEL                0.020194  0.013265    1.52  0.12792     #>                                                                 #> Rockiness → OBL        -0.094420  0.029524   -3.20  0.00138 **  #> Sandiness → OBL        -0.026955  0.014240   -1.89  0.05838 .   #> VallyBotFlat → OBL     -0.077027  0.024505   -3.14  0.00167 **  #> PPTann → OBL           -0.034164  0.021544   -1.59  0.11278     #> Loaminess → OBL         0.057495  0.027004    2.13  0.03324 *   #> cvTemp → OBL           -0.128407  0.018304   -7.02  2.3e-12 *** #> T0 → OBL                0.003082  0.018364    0.17  0.86670     #>                                                                 #> Rockiness → OVA        -0.042656  0.011541   -3.70  0.00022 *** #> Sandiness → OVA        -0.031969  0.011213   -2.85  0.00436 **  #> VallyBotFlat → OVA      0.024976  0.008358    2.99  0.00280 **  #> PPTann → OVA           -0.015456  0.012192   -1.27  0.20488     #> Loaminess → OVA        -0.023076  0.007738   -2.98  0.00286 **  #> cvTemp → OVA            0.005134  0.010920    0.47  0.63826     #> T0 → OVA                0.005040  0.005497    0.92  0.35923     #>                                                                 #> Rockiness → WIL        -0.039157  0.017691   -2.21  0.02687 *   #> Sandiness → WIL         0.030581  0.013444    2.27  0.02293 *   #> VallyBotFlat → WIL     -0.048129  0.016968   -2.84  0.00456 **  #> PPTann → WIL           -0.029462  0.013224   -2.23  0.02588 *   #> Loaminess → WIL         0.027987  0.010349    2.70  0.00684 **  #> cvTemp → WIL           -0.144880  0.018816   -7.70  1.4e-14 *** #> T0 → WIL               -0.009177  0.011576   -0.79  0.42788     #>                                                                 #> Rockiness → ALP         0.067017  0.011881    5.64  1.7e-08 *** #> Sandiness → ALP         0.011443  0.009825    1.16  0.24411     #> VallyBotFlat → ALP     -0.026809  0.015801   -1.70  0.08975 .   #> PPTann → ALP            0.053667  0.008062    6.66  2.8e-11 *** #> Loaminess → ALP        -0.012781  0.013272   -0.96  0.33554     #> cvTemp → ALP           -0.020158  0.008833   -2.28  0.02249 *   #> T0 → ALP                0.002295  0.008227    0.28  0.78033     #>                                                                 #> Rockiness → VIM        -0.056519  0.016041   -3.52  0.00043 *** #> Sandiness → VIM        -0.033793  0.011963   -2.82  0.00473 **  #> VallyBotFlat → VIM      0.014227  0.013794    1.03  0.30235     #> PPTann → VIM           -0.021759  0.012002   -1.81  0.06982 .   #> Loaminess → VIM        -0.030142  0.008741   -3.45  0.00056 *** #> cvTemp → VIM           -0.013018  0.009845   -1.32  0.18609     #> T0 → VIM                0.010468  0.007531    1.39  0.16453     #>                                                                 #> Rockiness → ARO.SAB    -0.151047  0.021186   -7.13  1.0e-12 *** #> Sandiness → ARO.SAB     0.011755  0.020452    0.57  0.56544     #> VallyBotFlat → ARO.SAB  0.070048  0.017976    3.90  9.7e-05 *** #> PPTann → ARO.SAB       -0.071959  0.021524   -3.34  0.00083 *** #> Loaminess → ARO.SAB    -0.018187  0.016509   -1.10  0.27061     #> cvTemp → ARO.SAB       -0.104956  0.017885   -5.87  4.4e-09 *** #> T0 → ARO.SAB           -0.010473  0.016703   -0.63  0.53064     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> ── Standard Deviation of Conditional Effects #>                            ACE Std.Err Z value Pr(>|z|)     #> Rockiness → ALA        0.01891 0.00767    2.47  0.01363 *   #> Sandiness → ALA        0.01296 0.00632    2.05  0.04016 *   #> VallyBotFlat → ALA     0.02929 0.01222    2.40  0.01655 *   #> PPTann → ALA           0.01091 0.00694    1.57  0.11573     #> Loaminess → ALA        0.01855 0.00729    2.54  0.01093 *   #> cvTemp → ALA           0.01852 0.00840    2.20  0.02753 *   #> T0 → ALA               0.01885 0.00785    2.40  0.01632 *   #>                                                             #> Rockiness → ARE        0.02005 0.00741    2.70  0.00684 **  #> Sandiness → ARE        0.02258 0.01324    1.71  0.08815 .   #> VallyBotFlat → ARE     0.03524 0.01468    2.40  0.01639 *   #> PPTann → ARE           0.01595 0.00713    2.24  0.02521 *   #> Loaminess → ARE        0.03621 0.01260    2.87  0.00407 **  #> cvTemp → ARE           0.10603 0.02423    4.38  1.2e-05 *** #> T0 → ARE               0.01785 0.00994    1.80  0.07257 .   #>                                                             #> Rockiness → BAX        0.03826 0.01149    3.33  0.00087 *** #> Sandiness → BAX        0.03835 0.00853    4.49  7.0e-06 *** #> VallyBotFlat → BAX     0.05375 0.00939    5.72  1.0e-08 *** #> PPTann → BAX           0.01688 0.00553    3.05  0.00226 **  #> Loaminess → BAX        0.01364 0.00317    4.31  1.7e-05 *** #> cvTemp → BAX           0.05601 0.01324    4.23  2.3e-05 *** #> T0 → BAX               0.01219 0.00255    4.77  1.8e-06 *** #>                                                             #> Rockiness → CAM        0.03871 0.01197    3.23  0.00122 **  #> Sandiness → CAM        0.04723 0.01351    3.50  0.00047 *** #> VallyBotFlat → CAM     0.04881 0.01152    4.24  2.3e-05 *** #> PPTann → CAM           0.02328 0.01255    1.85  0.06364 .   #> Loaminess → CAM        0.02208 0.00880    2.51  0.01209 *   #> cvTemp → CAM           0.01169 0.00437    2.68  0.00746 **  #> T0 → CAM               0.01263 0.00506    2.50  0.01258 *   #>                                                             #> Rockiness → GON        0.03927 0.01030    3.81  0.00014 *** #> Sandiness → GON        0.01565 0.00880    1.78  0.07521 .   #> VallyBotFlat → GON     0.03470 0.01351    2.57  0.01019 *   #> PPTann → GON           0.02440 0.01049    2.33  0.02004 *   #> Loaminess → GON        0.03487 0.01189    2.93  0.00336 **  #> cvTemp → GON           0.10688 0.01872    5.71  1.1e-08 *** #> T0 → GON               0.01369 0.00601    2.28  0.02270 *   #>                                                             #> Rockiness → MEL        0.05372 0.02164    2.48  0.01306 *   #> Sandiness → MEL        0.01630 0.00820    1.99  0.04694 *   #> VallyBotFlat → MEL     0.01257 0.00499    2.52  0.01186 *   #> PPTann → MEL           0.02526 0.01001    2.52  0.01162 *   #> Loaminess → MEL        0.02468 0.00994    2.48  0.01302 *   #> cvTemp → MEL           0.01867 0.00783    2.38  0.01709 *   #> T0 → MEL               0.01580 0.00952    1.66  0.09697 .   #>                                                             #> Rockiness → OBL        0.04964 0.01679    2.96  0.00310 **  #> Sandiness → OBL        0.01974 0.00581    3.40  0.00068 *** #> VallyBotFlat → OBL     0.04075 0.01305    3.12  0.00180 **  #> PPTann → OBL           0.02174 0.00956    2.27  0.02301 *   #> Loaminess → OBL        0.03039 0.01270    2.39  0.01672 *   #> cvTemp → OBL           0.06780 0.01532    4.43  9.6e-06 *** #> T0 → OBL               0.01289 0.00387    3.33  0.00087 *** #>                                                             #> Rockiness → OVA        0.04019 0.01224    3.28  0.00102 **  #> Sandiness → OVA        0.03335 0.01264    2.64  0.00834 **  #> VallyBotFlat → OVA     0.02442 0.00920    2.65  0.00794 **  #> PPTann → OVA           0.01711 0.00832    2.06  0.03980 *   #> Loaminess → OVA        0.02404 0.00812    2.96  0.00308 **  #> cvTemp → OVA           0.01284 0.00711    1.81  0.07096 .   #> T0 → OVA               0.00869 0.00312    2.79  0.00529 **  #>                                                             #> Rockiness → WIL        0.03189 0.01090    2.93  0.00344 **  #> Sandiness → WIL        0.02465 0.01029    2.39  0.01663 *   #> VallyBotFlat → WIL     0.03782 0.01254    3.02  0.00257 **  #> PPTann → WIL           0.02472 0.00869    2.85  0.00443 **  #> Loaminess → WIL        0.02268 0.00897    2.53  0.01144 *   #> cvTemp → WIL           0.10938 0.02074    5.27  1.3e-07 *** #> T0 → WIL               0.01300 0.00424    3.06  0.00218 **  #>                                                             #> Rockiness → ALP        0.09195 0.01761    5.22  1.8e-07 *** #> Sandiness → ALP        0.01901 0.00862    2.21  0.02741 *   #> VallyBotFlat → ALP     0.03707 0.02078    1.78  0.07452 .   #> PPTann → ALP           0.07306 0.01311    5.57  2.5e-08 *** #> Loaminess → ALP        0.02372 0.01312    1.81  0.07063 .   #> cvTemp → ALP           0.03036 0.01170    2.59  0.00946 **  #> T0 → ALP               0.01335 0.00490    2.73  0.00641 **  #>                                                             #> Rockiness → VIM        0.04343 0.01141    3.81  0.00014 *** #> Sandiness → VIM        0.03041 0.00952    3.20  0.00139 **  #> VallyBotFlat → VIM     0.01537 0.00997    1.54  0.12330     #> PPTann → VIM           0.01771 0.00829    2.14  0.03258 *   #> Loaminess → VIM        0.02493 0.00719    3.46  0.00053 *** #> cvTemp → VIM           0.01504 0.00519    2.90  0.00376 **  #> T0 → VIM               0.01094 0.00482    2.27  0.02316 *   #>                                                             #> Rockiness → ARO.SAB    0.10781 0.01900    5.67  1.4e-08 *** #> Sandiness → ARO.SAB    0.01962 0.00995    1.97  0.04867 *   #> VallyBotFlat → ARO.SAB 0.05147 0.01240    4.15  3.3e-05 *** #> PPTann → ARO.SAB       0.05223 0.01751    2.98  0.00286 **  #> Loaminess → ARO.SAB    0.01985 0.00692    2.87  0.00412 **  #> cvTemp → ARO.SAB       0.07545 0.01460    5.17  2.4e-07 *** #> T0 → ARO.SAB           0.01658 0.00702    2.36  0.01813 *   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ale_plots = ALE(model_boot, variable = \"cvTemp\", plot = FALSE) do.call(gridExtra::grid.arrange, ale_plots)"},{"path":"/articles/C-Example_Species_distribution_modeling.html","id":"advanced-joint-species-distribution-model","dir":"Articles","previous_headings":"","what":"Advanced: Joint species distribution model","title":"Example: (Multi-) Species distribution models with cito","text":"recent years, joint species distribution models (JSDM) emerged new class models capable jointly modeling species. JSDM account co-occurrences species explained environment alone biotic associations Pollock et al., 2014. Technically, biotic associations coded covariance matrix absorbs species co-occurrences “left ” residuals. Two common models JSDMs latent variable model Warton et al., 2015 multivariate probit model (MVP) (Pollock et al., 2014). ‘cito’ provide experimental likelihood multivariate probit model based Monte-Carlo approximation (Chen et al., 2018). However, ‘cito’ JSDM-focused package means many interesting features JSDMs community assembly analyses available ‘cito’. want perform -depth analysis JSDM reveal internal metacommunity structure recommend, example, sjSDM package:  Building covariance matrix corresponds biotic associations: information community analyses JSDMs see vignette sjSDM package","code":"jsdm = dnn(cbind(ALA, ARE, BAX, CAM, GON, MEL, OBL, OVA, WIL, ALP, VIM, ARO.SAB)~.,             data = df,             lr = 0.1,             epochs = 200L,             verbose = FALSE,             loss = \"mvp\") L = jsdm$parameter$paramter biotic_association = cov2cor(L%*%t(L) + diag(1, 12)) #> Error in t.default(L): argument is not a matrix fields::image.plot(biotic_association) #> Error in eval(expr, envir, enclos): object 'biotic_association' not found"},{"path":"/articles/D-Advanced_custom_loss_functions.html","id":"custom-loss-functions","dir":"Articles","previous_headings":"","what":"Custom loss functions","title":"Advanced: Custom loss functions and prediction intervals","text":"can pass custom loss functions cito. R variables/values used within loss function additionally optimized must passed cito via custom_parameters argument dnn(...custom_parameters = list(name_of_parameter=...)) Examples: (Complex) likelihood functions Advanced: Quantile regression Requirements: - Complex calculations written torch - functions/calls must derivatives.","code":""},{"path":"/articles/D-Advanced_custom_loss_functions.html","id":"example-1-custom-likelihoodloss-functions","dir":"Articles","previous_headings":"Custom loss functions","what":"Example 1: Custom (likelihood/loss) functions","title":"Advanced: Custom loss functions and prediction intervals","text":"Gaussian likelihood (already implemented, still nice example). Custom parameters must passed list custom_parameters function. names must match names parameters custom loss function. values named custom parameters initial values. Cito automatically convert torch tensors:  optimized parameters saved parameter field:","code":"library(cito) library(torch) gaussian_ll = function(pred, true, ...) {   loss = -torch::distr_normal(pred, scale = torch::torch_exp(scale_par))$log_prob(true)   return(loss$mean()) }  # Simulate some data X = runif(200) Y = 2*X + rnorm(200, sd = 0.4) df = data.frame(X = X, Y = Y)  m = dnn(Y~X, data = df,         loss = gaussian_ll, # custom function         custom_parameters = list(scale_par = 0.0) # custom parameter that should be addtionally optimized         ) #> Loss at epoch 1: 1.334335, lr: 0.01000 #> Loss at epoch 2: 1.154231, lr: 0.01000 #> Loss at epoch 3: 1.068738, lr: 0.01000 #> Loss at epoch 4: 1.016910, lr: 0.01000 #> Loss at epoch 5: 0.976305, lr: 0.01000 #> Loss at epoch 6: 0.937856, lr: 0.01000 #> Loss at epoch 7: 0.899509, lr: 0.01000 #> Loss at epoch 8: 0.863034, lr: 0.01000 #> Loss at epoch 9: 0.824331, lr: 0.01000 #> Loss at epoch 10: 0.786820, lr: 0.01000 #> Loss at epoch 11: 0.749023, lr: 0.01000 #> Loss at epoch 12: 0.716187, lr: 0.01000 #> Loss at epoch 13: 0.684993, lr: 0.01000 #> Loss at epoch 14: 0.651024, lr: 0.01000 #> Loss at epoch 15: 0.630259, lr: 0.01000 #> Loss at epoch 16: 0.602878, lr: 0.01000 #> Loss at epoch 17: 0.594161, lr: 0.01000 #> Loss at epoch 18: 0.585590, lr: 0.01000 #> Loss at epoch 19: 0.572606, lr: 0.01000 #> Loss at epoch 20: 0.596161, lr: 0.01000 #> Loss at epoch 21: 0.560749, lr: 0.01000 #> Loss at epoch 22: 0.569604, lr: 0.01000 #> Loss at epoch 23: 0.557299, lr: 0.01000 #> Loss at epoch 24: 0.562676, lr: 0.01000 #> Loss at epoch 25: 0.566415, lr: 0.01000 #> Loss at epoch 26: 0.545704, lr: 0.01000 #> Loss at epoch 27: 0.563066, lr: 0.01000 #> Loss at epoch 28: 0.579306, lr: 0.01000 #> Loss at epoch 29: 0.548550, lr: 0.01000 #> Loss at epoch 30: 0.566733, lr: 0.01000 #> Loss at epoch 31: 0.602605, lr: 0.01000 #> Loss at epoch 32: 0.566520, lr: 0.01000 #> Loss at epoch 33: 0.555276, lr: 0.01000 #> Loss at epoch 34: 0.573158, lr: 0.01000 #> Loss at epoch 35: 0.553411, lr: 0.01000 #> Loss at epoch 36: 0.562307, lr: 0.01000 #> Loss at epoch 37: 0.553605, lr: 0.01000 #> Loss at epoch 38: 0.561382, lr: 0.01000 #> Loss at epoch 39: 0.542558, lr: 0.01000 #> Loss at epoch 40: 0.555270, lr: 0.01000 #> Loss at epoch 41: 0.569742, lr: 0.01000 #> Loss at epoch 42: 0.559802, lr: 0.01000 #> Loss at epoch 43: 0.561651, lr: 0.01000 #> Loss at epoch 44: 0.550025, lr: 0.01000 #> Loss at epoch 45: 0.551257, lr: 0.01000 #> Loss at epoch 46: 0.553354, lr: 0.01000 #> Loss at epoch 47: 0.548418, lr: 0.01000 #> Loss at epoch 48: 0.572100, lr: 0.01000 #> Loss at epoch 49: 0.566985, lr: 0.01000 #> Loss at epoch 50: 0.563628, lr: 0.01000 #> Loss at epoch 51: 0.565352, lr: 0.01000 #> Loss at epoch 52: 0.557491, lr: 0.01000 #> Loss at epoch 53: 0.553377, lr: 0.01000 #> Loss at epoch 54: 0.543934, lr: 0.01000 #> Loss at epoch 55: 0.591781, lr: 0.01000 #> Loss at epoch 56: 0.551933, lr: 0.01000 #> Loss at epoch 57: 0.556685, lr: 0.01000 #> Loss at epoch 58: 0.557246, lr: 0.01000 #> Loss at epoch 59: 0.550845, lr: 0.01000 #> Loss at epoch 60: 0.568086, lr: 0.01000 #> Loss at epoch 61: 0.547975, lr: 0.01000 #> Loss at epoch 62: 0.553804, lr: 0.01000 #> Loss at epoch 63: 0.550696, lr: 0.01000 #> Loss at epoch 64: 0.553359, lr: 0.01000 #> Loss at epoch 65: 0.555588, lr: 0.01000 #> Loss at epoch 66: 0.556177, lr: 0.01000 #> Loss at epoch 67: 0.548261, lr: 0.01000 #> Loss at epoch 68: 0.575579, lr: 0.01000 #> Loss at epoch 69: 0.555330, lr: 0.01000 #> Loss at epoch 70: 0.567671, lr: 0.01000 #> Loss at epoch 71: 0.550055, lr: 0.01000 #> Loss at epoch 72: 0.542451, lr: 0.01000 #> Loss at epoch 73: 0.563940, lr: 0.01000 #> Loss at epoch 74: 0.550842, lr: 0.01000 #> Loss at epoch 75: 0.562200, lr: 0.01000 #> Loss at epoch 76: 0.557705, lr: 0.01000 #> Loss at epoch 77: 0.557986, lr: 0.01000 #> Loss at epoch 78: 0.556814, lr: 0.01000 #> Loss at epoch 79: 0.560184, lr: 0.01000 #> Loss at epoch 80: 0.548673, lr: 0.01000 #> Loss at epoch 81: 0.591368, lr: 0.01000 #> Loss at epoch 82: 0.556005, lr: 0.01000 #> Loss at epoch 83: 0.544128, lr: 0.01000 #> Loss at epoch 84: 0.585111, lr: 0.01000 #> Loss at epoch 85: 0.565595, lr: 0.01000 #> Loss at epoch 86: 0.555380, lr: 0.01000 #> Loss at epoch 87: 0.553692, lr: 0.01000 #> Loss at epoch 88: 0.554190, lr: 0.01000 #> Loss at epoch 89: 0.550925, lr: 0.01000 #> Loss at epoch 90: 0.546147, lr: 0.01000 #> Loss at epoch 91: 0.550892, lr: 0.01000 #> Loss at epoch 92: 0.560193, lr: 0.01000 #> Loss at epoch 93: 0.570056, lr: 0.01000 #> Loss at epoch 94: 0.553779, lr: 0.01000 #> Loss at epoch 95: 0.558661, lr: 0.01000 #> Loss at epoch 96: 0.546044, lr: 0.01000 #> Loss at epoch 97: 0.549163, lr: 0.01000 #> Loss at epoch 98: 0.550264, lr: 0.01000 #> Loss at epoch 99: 0.549252, lr: 0.01000 #> Loss at epoch 100: 0.562601, lr: 0.01000 exp(m$parameter$scale_par) # true scale parameter: 0.4! #> [1] 0.4217262"},{"path":"/articles/D-Advanced_custom_loss_functions.html","id":"example-2-quantile-regression","dir":"Articles","previous_headings":"Custom loss functions","what":"Example 2: Quantile regression","title":"Advanced: Custom loss functions and prediction intervals","text":"bootstrapping approach provides confidence intervals, prediction intervals. use likelihoods, Gaussian likelihood, fit constant prediction interval. However, often use loss functions, mean squared error ML/DL, don’t intrinsic parametrization prediction intervals. can approximate prediction intervals quantile regression, advantage providing non-constant prediction intervals (example heteroscedasticity): Simulate data:  variance increases higher feature values Quantile Regression:","code":"sim_in = function(n = 5) {   S = diag(1., 3)   S[1,2]=S[2,1]=0.0   X = mvtnorm::rmvnorm(n, sigma = S)   X1 = X[,1]   C = X[,2]   X2 = X[,3]   Y = 1*X1 + 0.1*X2 + 0.0*C + rnorm(n, sd = 0.3+2*1.8^(X1+1))   return(data.frame(Y = Y, X1 = X1, X2 = X2, C = C)) }  data = sim_in(500L) plot(data$X1, data$Y) library(torch)  q1 = torch_tensor(0.05) q2 = torch_tensor(0.5) q3 = torch_tensor(0.95) loss_func = function(pred, true,...) {   l1 = torch_max(q1*(true[,1,drop=FALSE]-pred[,1,drop=FALSE]), other = (1.0-q1)*(pred[,1,drop=FALSE]-true[,1,drop=FALSE]))   l2 = torch_max(q2*(true[,2,drop=FALSE]-pred[,2,drop=FALSE]), other = (1.0-q2)*(pred[,2,drop=FALSE]-true[,2,drop=FALSE]))   l3 = torch_max(q3*(true[,3,drop=FALSE]-pred[,3,drop=FALSE]), other = (1.0-q3)*(pred[,3,drop=FALSE]-true[,3,drop=FALSE]))   return(l1+l2+l3) }   m = dnn(cbind(Y, Y, Y)~., data = data,         lr = 0.01,         loss = loss_func,         lambda = 0.000, alpha = 0.5,         epochs = 70L, hidden = c(30L, 30L),         activation = \"selu\", verbose = TRUE, plot = FALSE) #> Loss at epoch 1: 5.470749, lr: 0.01000 #> Loss at epoch 2: 5.268569, lr: 0.01000 #> Loss at epoch 3: 5.076637, lr: 0.01000 #> Loss at epoch 4: 4.884690, lr: 0.01000 #> Loss at epoch 5: 4.684872, lr: 0.01000 #> Loss at epoch 6: 4.477314, lr: 0.01000 #> Loss at epoch 7: 4.274307, lr: 0.01000 #> Loss at epoch 8: 4.078366, lr: 0.01000 #> Loss at epoch 9: 3.909358, lr: 0.01000 #> Loss at epoch 10: 3.758730, lr: 0.01000 #> Loss at epoch 11: 3.627732, lr: 0.01000 #> Loss at epoch 12: 3.520284, lr: 0.01000 #> Loss at epoch 13: 3.424504, lr: 0.01000 #> Loss at epoch 14: 3.341247, lr: 0.01000 #> Loss at epoch 15: 3.270656, lr: 0.01000 #> Loss at epoch 16: 3.210762, lr: 0.01000 #> Loss at epoch 17: 3.154351, lr: 0.01000 #> Loss at epoch 18: 3.105250, lr: 0.01000 #> Loss at epoch 19: 3.063805, lr: 0.01000 #> Loss at epoch 20: 3.032800, lr: 0.01000 #> Loss at epoch 21: 3.005759, lr: 0.01000 #> Loss at epoch 22: 2.983023, lr: 0.01000 #> Loss at epoch 23: 2.964745, lr: 0.01000 #> Loss at epoch 24: 2.950813, lr: 0.01000 #> Loss at epoch 25: 2.935929, lr: 0.01000 #> Loss at epoch 26: 2.922020, lr: 0.01000 #> Loss at epoch 27: 2.911182, lr: 0.01000 #> Loss at epoch 28: 2.903018, lr: 0.01000 #> Loss at epoch 29: 2.894961, lr: 0.01000 #> Loss at epoch 30: 2.888757, lr: 0.01000 #> Loss at epoch 31: 2.882994, lr: 0.01000 #> Loss at epoch 32: 2.878412, lr: 0.01000 #> Loss at epoch 33: 2.874529, lr: 0.01000 #> Loss at epoch 34: 2.871417, lr: 0.01000 #> Loss at epoch 35: 2.868292, lr: 0.01000 #> Loss at epoch 36: 2.867184, lr: 0.01000 #> Loss at epoch 37: 2.863862, lr: 0.01000 #> Loss at epoch 38: 2.861748, lr: 0.01000 #> Loss at epoch 39: 2.859973, lr: 0.01000 #> Loss at epoch 40: 2.858448, lr: 0.01000 #> Loss at epoch 41: 2.856646, lr: 0.01000 #> Loss at epoch 42: 2.854968, lr: 0.01000 #> Loss at epoch 43: 2.854192, lr: 0.01000 #> Loss at epoch 44: 2.852455, lr: 0.01000 #> Loss at epoch 45: 2.851032, lr: 0.01000 #> Loss at epoch 46: 2.850336, lr: 0.01000 #> Loss at epoch 47: 2.849624, lr: 0.01000 #> Loss at epoch 48: 2.848325, lr: 0.01000 #> Loss at epoch 49: 2.846308, lr: 0.01000 #> Loss at epoch 50: 2.845728, lr: 0.01000 #> Loss at epoch 51: 2.844210, lr: 0.01000 #> Loss at epoch 52: 2.844008, lr: 0.01000 #> Loss at epoch 53: 2.842485, lr: 0.01000 #> Loss at epoch 54: 2.841521, lr: 0.01000 #> Loss at epoch 55: 2.841301, lr: 0.01000 #> Loss at epoch 56: 2.839583, lr: 0.01000 #> Loss at epoch 57: 2.839782, lr: 0.01000 #> Loss at epoch 58: 2.837819, lr: 0.01000 #> Loss at epoch 59: 2.837510, lr: 0.01000 #> Loss at epoch 60: 2.836291, lr: 0.01000 #> Loss at epoch 61: 2.835764, lr: 0.01000 #> Loss at epoch 62: 2.835144, lr: 0.01000 #> Loss at epoch 63: 2.834413, lr: 0.01000 #> Loss at epoch 64: 2.834573, lr: 0.01000 #> Loss at epoch 65: 2.832787, lr: 0.01000 #> Loss at epoch 66: 2.831882, lr: 0.01000 #> Loss at epoch 67: 2.832079, lr: 0.01000 #> Loss at epoch 68: 2.831004, lr: 0.01000 #> Loss at epoch 69: 2.829836, lr: 0.01000 #> Loss at epoch 70: 2.829776, lr: 0.01000  plot(data$X1, data$Y) lines(smooth.spline(data$X1, predict(m)[,1], spar = 0.01), col = \"blue\") lines(smooth.spline(data$X1, predict(m)[,3], spar = 0.01), col = \"blue\") lines(smooth.spline(data$X1, predict(m)[,2], spar = 0.01), col = \"red\")"},{"path":"/articles/D-Advanced_custom_loss_functions.html","id":"example-3-using-cito-for-optimization-active-learning","dir":"Articles","previous_headings":"Custom loss functions","what":"Example 3: Using cito for optimization / active learning","title":"Advanced: Custom loss functions and prediction intervals","text":"Neural networks can used unconventional way optimize arbitrary functions (sometimes called active learning, related reinforcement learning) - prerequisite analytic derivative function using torch must available. provide function optimized series Torch operations. First, model predict parameters (based noise, inputs don’t matter) passed custom loss function use model function (optimize) compute loss return optimizer. way overfit noisy inputs DNN learn predict optimal set parameters - independent input.","code":"X = runif(200) Y = 2*X + rnorm(200, sd = 0.4) df = data.frame(X = X, Y = Y)  # Function we want to optimize (linear model) Xt = torch_tensor(matrix(X)) Yt = torch_tensor(matrix(Y))  model_lm = function(par) {   pred = Xt$matmul(par[,1,drop=FALSE])   loss = -torch::distr_normal(pred, scale = torch::torch_exp(par[,2,drop=FALSE]))$log_prob(Yt)   return(loss$mean()) }  custom_loss = function(pred, true, ...) {   if(nrow(pred) > 1) return(torch_zeros(1L)) # disable loss calculation   loss = model_lm(pred)   return(loss) }  # X and Y values don't matter, number of columns in Y has to match the number of parameters we want to optimize noise = matrix(runif(300*5), 300, 5) noise_y = matrix(runif(300*2), 300, 2) df = data.frame(y1 = noise_y[,1], y2 = noise_y[,2], noise)  m = dnn(cbind(y1, y2)~., data = df, loss = custom_loss, batchsize = 1L, epochs = 20L, verbose = FALSE) # Effect: mean(predict(m)[,1]) #> [1] 2.035041 # SD mean(exp(predict(m)[,2])) #> [1] 0.4103649"},{"path":"/articles/E-CNN_and_MMN.html","id":"data-preparation-of-complex-data","dir":"Articles","previous_headings":"","what":"Data Preparation of complex data","title":"Convultions neural networks and Multi modal neural networks","text":"Cito, workflow preparing complex data Convolutional Neural Networks (CNNs) Multimodal Neural Networks (MMNs) . difference MMNs can process multiple data types simultaneously (see ‘MMN’ section ). dive details, let’s clarify represent different types complex data R using multidimensional arrays: Black/white image: [height,width][height, width] height/width number pixels Colored images: [3,height,width][3, height, width] 3 channels three colors LiDAR point clouds: [x,y,z][x, y, z] Environmental time series (can also represented “image”): [time_steps,n_covariates][\\text{time_steps}, \\text{n_covariates}] Note: Cito currently supports three-dimensional inputs (excluding sample dimension). Four-dimensional arrays, temporal RGB sequences [3,height,width,timesteps][3, height, width, time_steps], yet supported. Please contact us need support 4D inputs.","code":""},{"path":"/articles/E-CNN_and_MMN.html","id":"the-format-of-the-inputs-we-expect-in-cito","dir":"Articles","previous_headings":"Data Preparation of complex data","what":"The format of the inputs we expect in cito","title":"Convultions neural networks and Multi modal neural networks","text":"cnn() mmn() functions expect X argument single array, first dimension indexing samples. subsequent dimensions correspond data structure sample. Specifically: Grayscale images: [n_samples,height,width][\\text{n_samples}, height, width] RGB images: [n_samples,3,height,width][\\text{n_samples}, 3, height, width] LiDAR point clouds: [n_samples,x,y,z][\\text{n_samples}, x, y, z] Time series data: [n_samples,timesteps,ncovariates][\\text{n_samples}, time_steps, n_covariates] crucial order samples X matches order observations response (target) vector (matrix multiple response) y. Ultimately, requirement cito multidimensional arrays inputs. Please note several ways can build ; following workflow just one example.","code":""},{"path":"/articles/E-CNN_and_MMN.html","id":"preparing-your-data-on-disk","dir":"Articles","previous_headings":"Data Preparation of complex data","what":"1. Preparing your data on disk","title":"Convultions neural networks and Multi modal neural networks","text":"Although images can saved different formats, recommend using formats R function R package available allow load images R. Grayscale RGB images saved .png .jpeg. Time series data can technically interpreted grayscale images therefore also saved .png .jpeg. However, LiDAR point clouds /remote sensing data ‘channels’ (ofc, channels ) grayscale RGB images therefore saved .png .jpeg. Classical formats saving data .tiff (GeoTiff) .nc (netCDF). recommend saving image individually hard drive using naming strategy allows observation ID inferred image name. example:","code":"project/ ├── data/ │   ├── RGBimages/ │   │   ├── 001-img.jpeg │   │   ├── 002-img.jpeg │   │   ├── 003-img.jpeg │   │   ├── 004-img.jpeg │   │   └── ... │   ├── LiDAR/ │   │   ├── 001-LiDAR.tiff │   │   ├── 002-LiDAR.tiff │   │   ├── 003-LiDAR.tiff │   │   ├── 004-LiDAR.tiff │   │   └── ... │   └── Response/ │       └── Y.csv └── code/     ├── 01-CNN.R     └── 02-MMN.R"},{"path":"/articles/E-CNN_and_MMN.html","id":"load-images-into-r","dir":"Articles","previous_headings":"Data Preparation of complex data","what":"2. Load images into R","title":"Convultions neural networks and Multi modal neural networks","text":"can run/train cito, must load images R, transform arrays, concatenate individual images one input type one array. Reading .jpeg files: can done either using imager package via .array(imager::load.image(\"path--img.jpeg\"))) using torchvision package (dependency cito) via torchvision::base_loader(\"path--img.jpeg\") Reading .png files: can done using torchvision package (dependency cito) via torchvision::base_loader(\"path--img.jpeg\") Reading .tiff files: tiff::readTIFF(\"path--img.tiff\") Reading .tiff (GeoTIFF) files: .array(raster::brick(\"path--img.tiff\")) Reading .nc (netCDF) files: ncdf4::ncvar_get(ncdf4::nc_open(\"path--img.nc\")) Loop read images R: First data type: Second data type: Change list arrays one array:","code":"RGBimages_files = list.files(path = \"RGBimages/\", full.names = TRUE) RGBimages = vector(\"list\", length(RGBimages_files))  for(i in 1:length(RGBimages_files)) {   RGBimages[[i]] = torchvision::base_loader(RGBimages_files[i]) } LiDAR_files = list.files(path = \"LiDAR/\", full.names = TRUE) LiDAR = vector(\"list\", length(RGBimages_files))  for(i in 1:length(LiDAR_files)) {   LiDAR[[i]] = torchvision::base_loader(LiDAR_files[i]) } RGBimages = abind::abind(RGBimages, along = -1) LiDAR = abind::abind(LiDAR, along = -1)"},{"path":"/articles/E-CNN_and_MMN.html","id":"normalize-and-check-channel-dimension","dir":"Articles","previous_headings":"Data Preparation of complex data","what":"3. Normalize and check channel dimension","title":"Convultions neural networks and Multi modal neural networks","text":"Deep Neural Networks converge better inputs normalized/standardized, complex data, can divide max value bring values range [0,1][0, 1] Also, cito expects channel dimension RGB images second dimension. LiDAR, question dimension treated channel dimension. channel dimension treated slightly differently CNN, propose setting z dimension channel dimension. However, read images R, channel dimension usually last dimension. Cito, though, must second dimension. (Reminder: dimensions RGB currently: [n,height,width,3][n, height, width, 3])","code":"RGBimages = RGBimages/max(RGBimages) LiDAR = LiDAR/max(LiDAR) RGBimages = aperm(RGBimages, c(1, 4, 2, 3)) # change order of dimensions LiDAR = aperm(LiDAR, c(1, 4, 2, 3))  # change order of dimensions"},{"path":"/articles/E-CNN_and_MMN.html","id":"prepare-tabular-data-response-and-other-tabular-data-such-as-altitude-and-spatial-coordinates","dir":"Articles","previous_headings":"Data Preparation of complex data","what":"4. Prepare tabular data (response and other tabular data such as altitude and spatial coordinates)","title":"Convultions neural networks and Multi modal neural networks","text":"Read tabular data R using read.csv function. Predictors (e.g. spatial coordinates, altitude climatic variables bioclim variables) standardised using scale function. Note: missing values data! 1,000 images 1,000 response values NAs, Cito/R drop NA observations response, meaning number observations longer match . course, also NAs images! Note: order tabular data (responses predictors) match order images.","code":""},{"path":"/articles/E-CNN_and_MMN.html","id":"convolutional-neural-networks","dir":"Articles","previous_headings":"","what":"Convolutional neural networks","title":"Convultions neural networks and Multi modal neural networks","text":"can setup architecture CNN using create_architecture function. CNN usually consist several convolutional layers, layer followed pooling layer, finally fully connected layers: idea convolutional layers learn extract structures images shapes edges. structures presented fully connected layer actual classification regression. Finding good architecture can require lot experience knowledge CNNs. alternative, recommend using transfer learning, also state art. Rather training convolutional layers, use pre-trained CNN (usually trained large dataset hundreds thousands response categories) train final fully connected layer. found convolutional layers often learn things, need retrain time. saves lot computational runtime, importantly, don’t need much training data train small part model: Also, , don’t think architecture! Finally can fit model: Note: format Y depends loss task. aware convergence issues; loss higher baseline loss. Use validation split monitor overfitting; training can cancelled automatically based validation loss using early stopping. points described Introduction cito vignette apply dnn() cnn() functions. model trained, can make predictions via predict method: Model can visualized via plot(model)","code":"architecture <- create_architecture(conv(5), # convolutional layer with 5 kernels                                     maxPool(),  # max pooling layer to reduce the dimension of the feature maps                                     conv(5), # convolutional layer with 5 kernels                                     maxPool(), # max pooling layer to reduce the dimension of the feature maps                                     linear(10)) # fully connected layer architecture <- create_architecture(transfer(\"resnet18\"), # use pretrained resnet18 architecture                                     linear(100)) # our fully connnected layer model <- cnn(X = LiDAR, Y, architecture, loss = \"binomial\",               epochs = 10, validation = 0.1, lr = 0.05, device=device) pred = predict(model, LiDAR) # by default predictions will be on the scale of the link (so no probabilities) pred_proba = predict(model, LiDAR, type = \"response\") # change type to get probabilities"},{"path":"/articles/E-CNN_and_MMN.html","id":"multi-modal-neural-networks","dir":"Articles","previous_headings":"","what":"Multi-modal neural networks","title":"Convultions neural networks and Multi modal neural networks","text":"Multi-modal neural networks (MMNs) useful : different input data types, e.g. combining LiDAR optical satellite images (RGB images), combining LiDAR tabular data (e.g. bioclimatic variables). want combine different resolutions input data type complex input data must passed within multidimensional array architecture: Important: Tabular data must within one data.frame, , response variable Y data.frame Temp Precip! multiple responses: Newdata must passed list predict function. datasets must order model components mmn: Multiple different responses different losses: cito now lacks inverse link functions, apply predictions : Note: format Y depends loss task. aware convergence issues; loss higher baseline loss. Use validation split monitor overfitting; training can cancelled automatically based validation loss using early stopping. points described Introduction cito vignette apply dnn() cnn() functions.","code":"architecture_LiDAR <- create_architecture(transfer(\"resnet18\")) architecture_RGBimages <- create_architecture(transfer(\"resnet18\"))  model =   mmn(df$Y ~       cnn(X = LiDAR, architecture = architecture_LiDAR) +       cnn(X = RGBimages , architecture = architecture_RGBimages) +       dnn(~Temp+Precip, data = df),       loss = 'binomial',       optimizer = \"adam\") model =   mmn(cbind(df$Y1, df$Y2, df$Y3) ~       cnn(X = LiDAR, architecture = architecture_LiDAR) +       cnn(X = RGBimages , architecture = architecture_RGBimages) +       dnn(~Temp+Precip, data = df),       loss = 'binomial',       optimizer = \"adam\") predict(model, newdata = list(LiDAR, RGBimages, df), type = \"response\") custom_joint_loss = function(pred, true) {    # first loss, e.g. binomial -> negative loglikelihood   loss1 = -torch::distr_bernoulli(logits = torch_sigmoid(pred[,1]))$log_prob(true[,1])$mean()    # second loss, e.g. mse   loss2 = torch::nnf_mse_loss(pred[,2], true[,2])    # third loss, e.g. poisson   loss3 = -torch::distr_poisson(pred[,3]$exp())$log_prob(true[,3])$mean()    # return joint loss   return(loss1 + loss2 + loss3) }  model =   mmn(cbind(df$Y1, df$Y2, df$Y3) ~       cnn(X = LiDAR, architecture = architecture_LiDAR) +       cnn(X = RGBimages , architecture = architecture_RGBimages) +       dnn(~Temp+Precip, data = df),       loss = custom_joint_loss,       epochs = 5L,       optimizer = \"adam\") pred = predict(model, newdata = list(LiDAR, RGBimages, df)) pred[,1] = plogis(pred[,1]) pred[,3] = exp(pred[,3])"},{"path":"/articles/E-CNN_and_MMN.html","id":"computational-considerations-and-constraints","dir":"Articles","previous_headings":"","what":"Computational Considerations and Constraints","title":"Convultions neural networks and Multi modal neural networks","text":"working convolutional neural networks (CNNs) multimodal networks (MMNs), two critical computational factors memory (RAM) GPU availability.","code":""},{"path":"/articles/E-CNN_and_MMN.html","id":"gpu-requirements","dir":"Articles","previous_headings":"Computational Considerations and Constraints","what":"1. GPU Requirements","title":"Convultions neural networks and Multi modal neural networks","text":"CNNs benefit significantly GPU acceleration: Speed: Training GPU orders magnitude faster CPU. Memory: Due intensive tensor operations, recommend GPU least 12 GB VRAM handle typical batch sizes (e.g., batch_size = 20).","code":""},{"path":"/articles/E-CNN_and_MMN.html","id":"system-memory-ram","dir":"Articles","previous_headings":"Computational Considerations and Constraints","what":"2. System Memory (RAM)","title":"Convultions neural networks and Multi modal neural networks","text":"Currently, images must loaded single R session: approach limits number observations available system RAM. implementing data loaders stream mini-batches memory.","code":""},{"path":"/articles/E-CNN_and_MMN.html","id":"example-calculation-500-observations","dir":"Articles","previous_headings":"Computational Considerations and Constraints > 2. System Memory (RAM)","what":"Example Calculation (500 observations)","title":"Convultions neural networks and Multi modal neural networks","text":"run dataset single R session need ~550 GB system RAM. contrast, GPU memory less constraining one batch loaded time GPU. batch_size = 20, 12–14 GB GPU suffice. Summary: primary bottleneck system RAM CPU, VRAM GPU.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Christian Amesöder. Author. Maximilian Pichler. Author, maintainer. Florian Hartig. Contributor. Armin Schenk. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Amesöder, C., Hartig, F. Pichler, M. (2024), 'cito': R package training neural networks using 'torch'. Ecography e07143. https://doi.org/10.1111/ecog.07143","code":"@Article{,   title = {'cito': an R package for training neural networks using 'torch'},   author = {Christian Amesoeder and Florian Hartig and Maximilian Pichler},   journal = {Ecography},   year = {2024},   doi = {10.1111/ecog.07143}, }"},{"path":"/index.html","id":"cito","dir":"","previous_headings":"","what":"Building and Training Neural Networks","title":"Building and Training Neural Networks","text":"‘cito’ package provides user-friendly interface training interpreting deep neural networks (DNN). ‘cito’ simplifies fitting DNNs supporting familiar formula syntax, hyperparameter tuning cross-validation, helps detect handle convergence problems. DNNs can trained CPU, GPU MacOS GPUs. addition, ‘cito’ many downstream functionalities various explainable AI (xAI) metrics (e.g. variable importance, partial dependence plots, accumulated local effect plots, effect estimates) interpret trained DNNs. ‘cito’ optionally provides confidence intervals (p-values) xAI metrics predictions. time, ‘cito’ computationally efficient based deep learning framework ‘torch’. ‘torch’ package native R, Python installation API required package.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Building and Training Neural Networks","text":"installing ‘cito’ make sure ‘torch’ installed. See code chunk unsure check trouble installing ‘torch’, please visit website ‘torch’ package create issue github website. happy help . stable version cito CRAN can installed : development version GitHub can installed :","code":"# check package  if(!require('torch',quietly = TRUE)) install.packages('torch') library('torch')   #install torch if(!torch_is_installed()) install_torch() install.packages(\"cito\") if(!require('devtools', quietly = TRUE)) install.packages('devtools') devtools::install_github('citoverse/cito')"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Building and Training Neural Networks","text":"installed, main function dnn() can used. See example . depth explanation can found vignettes articles. Fit model bootstrapping (obtain confidence intervals). methods work without bootstrapping Check models converged (compare training loss baseline loss (=intercept model)): Plot model architecture  ‘cito’ supports many advanced functionalities common explainable AI metrics can used inference (.e. interpret models). Variable importance (similar variation partitioning) linear effects directly returned summary function: Predict (confidence intervals):","code":"library(cito) nn.fit <- dnn(Sepal.Length~., data = datasets::iris, bootstrap = 30L) analyze_training(nn.fit) # At 1st glance, the networks converged since the loss is lower than the baseline loss and the training loss is on a plateau at the end of the training. plot(nn.fit) summary(nn.fit) ## Summary of Deep Neural Network Model ##  ## ── Feature Importance ##                 Importance Std.Err Z value Pr(>|z|)   ## Sepal.Width →        0.897   0.443    2.02    0.043 * ## Petal.Length →      20.428   8.032    2.54    0.011 * ## Petal.Width →        0.695   0.690    1.01    0.314   ## Species →            0.647   0.634    1.02    0.307   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## ── Average Conditional Effects ##                     ACE Std.Err Z value Pr(>|z|)     ## Sepal.Width →    0.4838  0.0873    5.54    3e-08 *** ## Petal.Length →   0.6485  0.0745    8.71   <2e-16 *** ## Petal.Width →   -0.2264  0.1335   -1.70     0.09 .   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## ── Standard Deviation of Conditional Effects ##                    ACE Std.Err Z value Pr(>|z|)     ## Sepal.Width →   0.0657  0.0176    3.73  0.00019 *** ## Petal.Length →  0.0503  0.0178    2.83  0.00467 **  ## Petal.Width →   0.0382  0.0139    2.75  0.00596 **  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 dim(predict(nn.fit, newdata = datasets::iris)) ## [1] 150   1"},{"path":"/index.html","id":"hyperparameter-tuning","dir":"","previous_headings":"Example","what":"Hyperparameter tuning","title":"Building and Training Neural Networks","text":"Certain arguments/parameters architecture, activation function, learning rate can automatically tuned crossvalidation (full list, see ?dnn). Parameters tuned, can flagged using function tune() instead hyperparameter value: tuning can configured tuning=config_tuning(). tuning, final model trained best hyperparameters returned. Hyperparameter combinations achieve loss baseline loss aborted early fully cross-validated. runs given test loss infinity.","code":"nn.fit <- dnn(Sepal.Length~., data = datasets::iris, lr = tune(0.0001, 0.1)) ## Starting hyperparameter tuning... ## Fitting final model... nn.fit$tuning ## # A tibble: 10 × 5 ##    steps    test train models      lr ##    <int>   <dbl> <dbl> <lgl>    <dbl> ##  1     1 Inf         0 NA     0.0155  ##  2     2 Inf         0 NA     0.0993  ##  3     3   0.553     0 NA     0.00393 ##  4     4 Inf         0 NA     0.0817  ##  5     5 Inf         0 NA     0.0179  ##  6     6 Inf         0 NA     0.0947  ##  7     7 Inf         0 NA     0.0176  ##  8     8 Inf         0 NA     0.0241  ##  9     9 Inf         0 NA     0.0817  ## 10    10 Inf         0 NA     0.0337"},{"path":"/index.html","id":"advanced","dir":"","previous_headings":"","what":"Advanced","title":"Building and Training Neural Networks","text":"can pass custom loss functions ‘cito’, optionally additional parameters fitted. requirement calculations must written using ‘torch’ package (cito automatically converts initial values custom parameters ‘torch’ objects). use multivariate normal distribution likelihood function want parameterize/fit covariance matrix multivariate normal distribution: need one helper function, create_cov() builds covariance matrix based lower triangular matrix diagonals (low-rank approximation covariance matrix) need custom likelihood function uses distr_multivariate_normal(…) function torch package: use “SigmaPar” “SigmaDiag” parameters want optimize along DNN. pass named list starting values ‘cito’ ‘cito’ infer automatically (based R shape) shape parameters: Estimated covariance matrix: Empirical covariance matrix:","code":"create_cov = function(L, Diag) {   return(torch::torch_matmul(L, L$t()) + torch::torch_diag(Diag$exp()+0.001)) }  custom_loss_MVN = function(true, pred) {   Sigma = create_cov(SigmaPar, SigmaDiag)   logLik = torch::distr_multivariate_normal(pred,                                             covariance_matrix = Sigma)$     log_prob(true)   return(-logLik$mean()) } nn.fit<- dnn(cbind(Sepal.Length, Sepal.Width, Petal.Length)~.,              data = datasets::iris,              lr = 0.01,              epochs = 200L,              loss = custom_loss_MVN,              verbose = FALSE,              plot = FALSE,              custom_parameters =                list(SigmaDiag =  rep(0, 3), # Our parameters with starting values                     SigmaPar = matrix(rnorm(6, sd = 0.001), 3, 2)) # Our parameters with starting values ) as.matrix(create_cov(nn.fit$loss$parameter$SigmaPar,                      nn.fit$loss$parameter$SigmaDiag)) ##            [,1]       [,2]       [,3] ## [1,] 0.26974857 0.06961995 0.11768616 ## [2,] 0.06961995 0.12192857 0.04327871 ## [3,] 0.11768616 0.04327871 0.15618347 cov(predict(nn.fit) - nn.fit$data$Y) ##            [,1]       [,2]      [,3] ## [1,] 0.23646916 0.06383643 0.1227149 ## [2,] 0.06383643 0.08887552 0.0185613 ## [3,] 0.12271493 0.01856130 0.1308537"},{"path":"/reference/ALE.html","id":null,"dir":"Reference","previous_headings":"","what":"Accumulated Local Effect Plot (ALE) — ALE","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"Performs ALE one features.","code":""},{"path":"/reference/ALE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"","code":"ALE(   model,   variable = NULL,   data = NULL,   type = \"response\",   K = 10,   ALE_type = c(\"equidistant\", \"quantile\"),   plot = TRUE,   parallel = FALSE,   ... )  # S3 method for class 'citodnn' ALE(   model,   variable = NULL,   data = NULL,   type = \"response\",   K = 10,   ALE_type = c(\"equidistant\", \"quantile\"),   plot = TRUE,   parallel = FALSE,   ... )  # S3 method for class 'citodnnBootstrap' ALE(   model,   variable = NULL,   data = NULL,   type = \"response\",   K = 10,   ALE_type = c(\"equidistant\", \"quantile\"),   plot = TRUE,   parallel = FALSE,   ... )"},{"path":"/reference/ALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"model model created dnn variable variable string PDP done data data ALE performed , NULL training data used. type ALE scale response link, default response K number neighborhoods original feature space gets divided ALE_type method feature space divided neighborhoods. plot plot ALE parallel parallelize bootstrap models ... arguments passed predict","code":""},{"path":"/reference/ALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"list plots made 'ggplot2' consisting individual plot defined variable.","code":""},{"path":"/reference/ALE.html","id":"explanation","dir":"Reference","previous_headings":"","what":"Explanation","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"Accumulated Local Effect plots (ALE) quantify predictions change features change. similar partial dependency plots robust feature collinearity.","code":""},{"path":"/reference/ALE.html","id":"mathematical-details","dir":"Reference","previous_headings":"","what":"Mathematical details","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"defined variable numeric feature, ALE performed. , non centered effect feature j k equally distant neighborhoods defined : \\( \\hat{\\tilde{f}}_{j,ALE}(x)=\\sum_{k=1}^{k_j(x)}\\frac{1}{n_j(k)}\\sum_{:x_{j}^{()}\\{}N_j(k)}\\left[\\hat{f}(z_{k,j},x^{()}_{\\setminus{}j})-\\hat{f}(z_{k-1,j},x^{()}_{\\setminus{}j})\\right]\\) \\(N_j(k)\\) k-th neighborhood \\(n_j(k)\\) number observations k-th neighborhood. last part equation, \\(\\left[\\hat{f}(z_{k,j},x^{()}_{\\setminus{}j})-\\hat{f}(z_{k-1,j},x^{()}_{\\setminus{}j})\\right]\\) represents difference model prediction value feature j exchanged upper lower border current neighborhood.","code":""},{"path":[]},{"path":"/reference/ALE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Accumulated Local Effect Plot (ALE) — ALE","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris)  ALE(nn.fit, variable = \"Petal.Length\") } #> Registered S3 methods overwritten by 'reformulas': #>   method       from #>   head.call    cito #>   head.formula cito #>   head.name    cito #> Loss at epoch 1: 7.889025, lr: 0.01000  #> Loss at epoch 2: 0.512719, lr: 0.01000 #> Loss at epoch 3: 0.347656, lr: 0.01000 #> Loss at epoch 4: 0.133493, lr: 0.01000 #> Loss at epoch 5: 0.136497, lr: 0.01000 #> Loss at epoch 6: 0.161302, lr: 0.01000 #> Loss at epoch 7: 0.144902, lr: 0.01000 #> Loss at epoch 8: 0.318354, lr: 0.01000 #> Loss at epoch 9: 0.186123, lr: 0.01000 #> Loss at epoch 10: 0.142750, lr: 0.01000 #> Loss at epoch 11: 0.235318, lr: 0.01000 #> Loss at epoch 12: 0.176169, lr: 0.01000 #> Loss at epoch 13: 0.135905, lr: 0.01000 #> Loss at epoch 14: 0.191649, lr: 0.01000 #> Loss at epoch 15: 0.212641, lr: 0.01000 #> Loss at epoch 16: 0.170185, lr: 0.01000 #> Loss at epoch 17: 0.163705, lr: 0.01000 #> Loss at epoch 18: 0.123793, lr: 0.01000 #> Loss at epoch 19: 0.181584, lr: 0.01000 #> Loss at epoch 20: 0.266364, lr: 0.01000 #> Loss at epoch 21: 0.131292, lr: 0.01000 #> Loss at epoch 22: 0.140280, lr: 0.01000 #> Loss at epoch 23: 0.121795, lr: 0.01000 #> Loss at epoch 24: 0.127423, lr: 0.01000 #> Loss at epoch 25: 0.156479, lr: 0.01000 #> Loss at epoch 26: 0.181843, lr: 0.01000 #> Loss at epoch 27: 0.207243, lr: 0.01000 #> Loss at epoch 28: 0.114348, lr: 0.01000 #> Loss at epoch 29: 0.118947, lr: 0.01000 #> Loss at epoch 30: 0.227224, lr: 0.01000 #> Loss at epoch 31: 0.250363, lr: 0.01000 #> Loss at epoch 32: 0.120774, lr: 0.01000 #> Loss at epoch 33: 0.118991, lr: 0.01000 #> Loss at epoch 34: 0.136488, lr: 0.01000 #> Loss at epoch 35: 0.151361, lr: 0.01000 #> Loss at epoch 36: 0.174662, lr: 0.01000 #> Loss at epoch 37: 0.121635, lr: 0.01000 #> Loss at epoch 38: 0.157760, lr: 0.01000 #> Loss at epoch 39: 0.218447, lr: 0.01000 #> Loss at epoch 40: 0.138299, lr: 0.01000 #> Loss at epoch 41: 0.118832, lr: 0.01000 #> Loss at epoch 42: 0.193551, lr: 0.01000 #> Loss at epoch 43: 0.131657, lr: 0.01000 #> Loss at epoch 44: 0.165217, lr: 0.01000 #> Loss at epoch 45: 0.123828, lr: 0.01000 #> Loss at epoch 46: 0.189375, lr: 0.01000 #> Loss at epoch 47: 0.184541, lr: 0.01000 #> Loss at epoch 48: 0.143369, lr: 0.01000 #> Loss at epoch 49: 0.118727, lr: 0.01000 #> Loss at epoch 50: 0.147153, lr: 0.01000 #> Loss at epoch 51: 0.159745, lr: 0.01000 #> Loss at epoch 52: 0.172267, lr: 0.01000 #> Loss at epoch 53: 0.123218, lr: 0.01000 #> Loss at epoch 54: 0.110357, lr: 0.01000 #> Loss at epoch 55: 0.132339, lr: 0.01000 #> Loss at epoch 56: 0.171685, lr: 0.01000 #> Loss at epoch 57: 0.234976, lr: 0.01000 #> Loss at epoch 58: 0.164769, lr: 0.01000 #> Loss at epoch 59: 0.170867, lr: 0.01000 #> Loss at epoch 60: 0.117290, lr: 0.01000 #> Loss at epoch 61: 0.104408, lr: 0.01000 #> Loss at epoch 62: 0.125079, lr: 0.01000 #> Loss at epoch 63: 0.126700, lr: 0.01000 #> Loss at epoch 64: 0.187940, lr: 0.01000 #> Loss at epoch 65: 0.214467, lr: 0.01000 #> Loss at epoch 66: 0.134013, lr: 0.01000 #> Loss at epoch 67: 0.143070, lr: 0.01000 #> Loss at epoch 68: 0.111667, lr: 0.01000 #> Loss at epoch 69: 0.191072, lr: 0.01000 #> Loss at epoch 70: 0.206613, lr: 0.01000 #> Loss at epoch 71: 0.108522, lr: 0.01000 #> Loss at epoch 72: 0.153135, lr: 0.01000 #> Loss at epoch 73: 0.156445, lr: 0.01000 #> Loss at epoch 74: 0.114618, lr: 0.01000 #> Loss at epoch 75: 0.168166, lr: 0.01000 #> Loss at epoch 76: 0.105933, lr: 0.01000 #> Loss at epoch 77: 0.142420, lr: 0.01000 #> Loss at epoch 78: 0.109128, lr: 0.01000 #> Loss at epoch 79: 0.115850, lr: 0.01000 #> Loss at epoch 80: 0.156338, lr: 0.01000 #> Loss at epoch 81: 0.200598, lr: 0.01000 #> Loss at epoch 82: 0.099714, lr: 0.01000 #> Loss at epoch 83: 0.186532, lr: 0.01000 #> Loss at epoch 84: 0.122672, lr: 0.01000 #> Loss at epoch 85: 0.116775, lr: 0.01000 #> Loss at epoch 86: 0.113748, lr: 0.01000 #> Loss at epoch 87: 0.128192, lr: 0.01000 #> Loss at epoch 88: 0.121950, lr: 0.01000 #> Loss at epoch 89: 0.122903, lr: 0.01000 #> Loss at epoch 90: 0.127313, lr: 0.01000 #> Loss at epoch 91: 0.148167, lr: 0.01000 #> Loss at epoch 92: 0.149226, lr: 0.01000 #> Loss at epoch 93: 0.100185, lr: 0.01000 #> Loss at epoch 94: 0.178271, lr: 0.01000 #> Loss at epoch 95: 0.126860, lr: 0.01000 #> Loss at epoch 96: 0.108170, lr: 0.01000 #> Loss at epoch 97: 0.149426, lr: 0.01000 #> Loss at epoch 98: 0.099512, lr: 0.01000 #> Loss at epoch 99: 0.127643, lr: 0.01000 #> Loss at epoch 100: 0.114435, lr: 0.01000 #> Number of Neighborhoods reduced to 8  # }"},{"path":"/reference/PDP.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Dependence Plot (PDP) — PDP","title":"Partial Dependence Plot (PDP) — PDP","text":"Calculates Partial Dependency Plot one feature, either numeric categorical. Returns plot.","code":""},{"path":"/reference/PDP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Dependence Plot (PDP) — PDP","text":"","code":"PDP(   model,   variable = NULL,   data = NULL,   ice = FALSE,   resolution.ice = 20,   plot = TRUE,   parallel = FALSE,   ... )  # S3 method for class 'citodnn' PDP(   model,   variable = NULL,   data = NULL,   ice = FALSE,   resolution.ice = 20,   plot = TRUE,   parallel = FALSE,   ... )  # S3 method for class 'citodnnBootstrap' PDP(   model,   variable = NULL,   data = NULL,   ice = FALSE,   resolution.ice = 20,   plot = TRUE,   parallel = FALSE,   ... )"},{"path":"/reference/PDP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Dependence Plot (PDP) — PDP","text":"model model created dnn variable variable string PDP done. none supplied done variables. data specify new data PDP performed . NULL, PDP performed training data. ice Individual Conditional Dependence shown TRUE resolution.ice resolution ice computed plot plot PDP parallel parallelize bootstrap models ... arguments passed predict","code":""},{"path":"/reference/PDP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Dependence Plot (PDP) — PDP","text":"list plots made 'ggplot2' consisting individual plot defined variable.","code":""},{"path":"/reference/PDP.html","id":"description","dir":"Reference","previous_headings":"","what":"Description","title":"Partial Dependence Plot (PDP) — PDP","text":"Performs Partial Dependency Plot (PDP) estimation analyze relationship selected feature target variable. PDP function estimates partial function \\(\\hat{f}_S\\): \\(\\hat{f}_S(x_S)=\\frac{1}{n}\\sum_{=1}^n\\hat{f}(x_S,x^{()}_{C})\\) Monte Carlo Estimation: \\(\\hat{f}_S(x_S)=\\frac{1}{n}\\sum_{=1}^n\\hat{f}(x_S,x^{()}_{C})\\) using Monte Carlo estimation method. calculates average prediction target variable different values selected feature keeping features constant. categorical features, data instances used, instance set one level categorical feature. average prediction per category calculated visualized bar plot. ice parameter set TRUE, Individual Conditional Expectation (ICE) curves also shown. curves illustrate individual data sample reacts changes feature value. Please note option available categorical features. Unlike PDP, ICE curves computed using value grid instead utilizing every value every data entry. Note: PDP analysis provides valuable insights relationship specific feature target variable, helping understand feature's impact model's predictions. categorical feature analyzed, data instances used set level. average calculated per category put bar plot. ice set true additional individual conditional dependence shown original PDP colored yellow. lines show, individual data sample reacts changes feature. option available categorical features. Unlike PDP ICE curves computed value grid instead utilizing every value every data entry.","code":""},{"path":[]},{"path":"/reference/PDP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Dependence Plot (PDP) — PDP","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris)  PDP(nn.fit, variable = \"Petal.Length\") } #> Loss at epoch 1: 3.664424, lr: 0.01000  #> Loss at epoch 2: 1.497374, lr: 0.01000 #> Loss at epoch 3: 0.530163, lr: 0.01000 #> Loss at epoch 4: 0.178987, lr: 0.01000 #> Loss at epoch 5: 0.288653, lr: 0.01000 #> Loss at epoch 6: 0.130974, lr: 0.01000 #> Loss at epoch 7: 0.197148, lr: 0.01000 #> Loss at epoch 8: 0.486733, lr: 0.01000 #> Loss at epoch 9: 0.372030, lr: 0.01000 #> Loss at epoch 10: 0.345576, lr: 0.01000 #> Loss at epoch 11: 0.261917, lr: 0.01000 #> Loss at epoch 12: 0.184841, lr: 0.01000 #> Loss at epoch 13: 0.142929, lr: 0.01000 #> Loss at epoch 14: 0.343258, lr: 0.01000 #> Loss at epoch 15: 0.153308, lr: 0.01000 #> Loss at epoch 16: 0.128067, lr: 0.01000 #> Loss at epoch 17: 0.231181, lr: 0.01000 #> Loss at epoch 18: 0.167183, lr: 0.01000 #> Loss at epoch 19: 0.338393, lr: 0.01000 #> Loss at epoch 20: 0.182522, lr: 0.01000 #> Loss at epoch 21: 0.242890, lr: 0.01000 #> Loss at epoch 22: 0.174132, lr: 0.01000 #> Loss at epoch 23: 0.160364, lr: 0.01000 #> Loss at epoch 24: 0.187050, lr: 0.01000 #> Loss at epoch 25: 0.196678, lr: 0.01000 #> Loss at epoch 26: 0.344192, lr: 0.01000 #> Loss at epoch 27: 0.185613, lr: 0.01000 #> Loss at epoch 28: 0.168092, lr: 0.01000 #> Loss at epoch 29: 0.132117, lr: 0.01000 #> Loss at epoch 30: 0.175003, lr: 0.01000 #> Loss at epoch 31: 0.156258, lr: 0.01000 #> Loss at epoch 32: 0.135925, lr: 0.01000 #> Loss at epoch 33: 0.122647, lr: 0.01000 #> Loss at epoch 34: 0.198828, lr: 0.01000 #> Loss at epoch 35: 0.265848, lr: 0.01000 #> Loss at epoch 36: 0.114820, lr: 0.01000 #> Loss at epoch 37: 0.174555, lr: 0.01000 #> Loss at epoch 38: 0.128287, lr: 0.01000 #> Loss at epoch 39: 0.212362, lr: 0.01000 #> Loss at epoch 40: 0.127659, lr: 0.01000 #> Loss at epoch 41: 0.138128, lr: 0.01000 #> Loss at epoch 42: 0.143118, lr: 0.01000 #> Loss at epoch 43: 0.169750, lr: 0.01000 #> Loss at epoch 44: 0.150594, lr: 0.01000 #> Loss at epoch 45: 0.291155, lr: 0.01000 #> Loss at epoch 46: 0.148066, lr: 0.01000 #> Loss at epoch 47: 0.144092, lr: 0.01000 #> Loss at epoch 48: 0.150879, lr: 0.01000 #> Loss at epoch 49: 0.173141, lr: 0.01000 #> Loss at epoch 50: 0.148515, lr: 0.01000 #> Loss at epoch 51: 0.120425, lr: 0.01000 #> Loss at epoch 52: 0.218867, lr: 0.01000 #> Loss at epoch 53: 0.123754, lr: 0.01000 #> Loss at epoch 54: 0.176253, lr: 0.01000 #> Loss at epoch 55: 0.233659, lr: 0.01000 #> Loss at epoch 56: 0.159904, lr: 0.01000 #> Loss at epoch 57: 0.134267, lr: 0.01000 #> Loss at epoch 58: 0.143162, lr: 0.01000 #> Loss at epoch 59: 0.145228, lr: 0.01000 #> Loss at epoch 60: 0.113980, lr: 0.01000 #> Loss at epoch 61: 0.126273, lr: 0.01000 #> Loss at epoch 62: 0.123818, lr: 0.01000 #> Loss at epoch 63: 0.130005, lr: 0.01000 #> Loss at epoch 64: 0.178676, lr: 0.01000 #> Loss at epoch 65: 0.246696, lr: 0.01000 #> Loss at epoch 66: 0.175567, lr: 0.01000 #> Loss at epoch 67: 0.156420, lr: 0.01000 #> Loss at epoch 68: 0.128855, lr: 0.01000 #> Loss at epoch 69: 0.198549, lr: 0.01000 #> Loss at epoch 70: 0.110308, lr: 0.01000 #> Loss at epoch 71: 0.126377, lr: 0.01000 #> Loss at epoch 72: 0.180684, lr: 0.01000 #> Loss at epoch 73: 0.165441, lr: 0.01000 #> Loss at epoch 74: 0.130092, lr: 0.01000 #> Loss at epoch 75: 0.166000, lr: 0.01000 #> Loss at epoch 76: 0.137054, lr: 0.01000 #> Loss at epoch 77: 0.164392, lr: 0.01000 #> Loss at epoch 78: 0.125858, lr: 0.01000 #> Loss at epoch 79: 0.179265, lr: 0.01000 #> Loss at epoch 80: 0.145095, lr: 0.01000 #> Loss at epoch 81: 0.224620, lr: 0.01000 #> Loss at epoch 82: 0.118003, lr: 0.01000 #> Loss at epoch 83: 0.127677, lr: 0.01000 #> Loss at epoch 84: 0.157284, lr: 0.01000 #> Loss at epoch 85: 0.128797, lr: 0.01000 #> Loss at epoch 86: 0.172269, lr: 0.01000 #> Loss at epoch 87: 0.126245, lr: 0.01000 #> Loss at epoch 88: 0.138377, lr: 0.01000 #> Loss at epoch 89: 0.106076, lr: 0.01000 #> Loss at epoch 90: 0.201372, lr: 0.01000 #> Loss at epoch 91: 0.160302, lr: 0.01000 #> Loss at epoch 92: 0.138648, lr: 0.01000 #> Loss at epoch 93: 0.115474, lr: 0.01000 #> Loss at epoch 94: 0.135377, lr: 0.01000 #> Loss at epoch 95: 0.137939, lr: 0.01000 #> Loss at epoch 96: 0.135082, lr: 0.01000 #> Loss at epoch 97: 0.111533, lr: 0.01000 #> Loss at epoch 98: 0.138479, lr: 0.01000 #> Loss at epoch 99: 0.157114, lr: 0.01000 #> Loss at epoch 100: 0.206865, lr: 0.01000  # }"},{"path":"/reference/analyze_training.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize training of Neural Network — analyze_training","title":"Visualize training of Neural Network — analyze_training","text":"training model cito, function helps analyze training process decide best performing model. Creates 'plotly' figure allows zoom training graph","code":""},{"path":"/reference/analyze_training.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize training of Neural Network — analyze_training","text":"","code":"analyze_training(object)"},{"path":"/reference/analyze_training.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize training of Neural Network — analyze_training","text":"object model created dnn cnn","code":""},{"path":"/reference/analyze_training.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize training of Neural Network — analyze_training","text":"'plotly' figure","code":""},{"path":"/reference/analyze_training.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visualize training of Neural Network — analyze_training","text":"baseline loss important reference. model able achieve better (lower) loss baseline (loss intercept model), model probably converge. Possible reasons include improper learning rate, epochs, much regularization. See ?dnn help vignette(\"B-Training_neural_networks\").","code":""},{"path":"/reference/analyze_training.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize training of Neural Network — analyze_training","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito) set.seed(222) validation_set<- sample(c(1:nrow(datasets::iris)),25)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,],validation = 0.1)  # show zoomable plot of training and validation losses analyze_training(nn.fit)  # Use model on validation set predictions <- predict(nn.fit, iris[validation_set,])  # Scatterplot plot(iris[validation_set,]$Sepal.Length,predictions) } #> Loss at epoch 1: training: 5.229, validation: 0.604, lr: 0.01000  #> Loss at epoch 2: training: 0.481, validation: 1.757, lr: 0.01000 #> Loss at epoch 3: training: 0.400, validation: 0.367, lr: 0.01000 #> Loss at epoch 4: training: 0.211, validation: 0.591, lr: 0.01000 #> Loss at epoch 5: training: 0.213, validation: 0.209, lr: 0.01000 #> Loss at epoch 6: training: 0.254, validation: 0.507, lr: 0.01000 #> Loss at epoch 7: training: 0.277, validation: 0.323, lr: 0.01000 #> Loss at epoch 8: training: 0.168, validation: 0.267, lr: 0.01000 #> Loss at epoch 9: training: 0.148, validation: 0.391, lr: 0.01000 #> Loss at epoch 10: training: 0.162, validation: 0.253, lr: 0.01000 #> Loss at epoch 11: training: 0.338, validation: 0.161, lr: 0.01000 #> Loss at epoch 12: training: 0.174, validation: 0.265, lr: 0.01000 #> Loss at epoch 13: training: 0.154, validation: 0.142, lr: 0.01000 #> Loss at epoch 14: training: 0.314, validation: 0.404, lr: 0.01000 #> Loss at epoch 15: training: 0.142, validation: 0.120, lr: 0.01000 #> Loss at epoch 16: training: 0.197, validation: 1.106, lr: 0.01000 #> Loss at epoch 17: training: 0.183, validation: 0.329, lr: 0.01000 #> Loss at epoch 18: training: 0.381, validation: 0.173, lr: 0.01000 #> Loss at epoch 19: training: 0.248, validation: 0.200, lr: 0.01000 #> Loss at epoch 20: training: 0.147, validation: 0.151, lr: 0.01000 #> Loss at epoch 21: training: 0.317, validation: 0.106, lr: 0.01000 #> Loss at epoch 22: training: 0.154, validation: 0.189, lr: 0.01000 #> Loss at epoch 23: training: 0.162, validation: 0.192, lr: 0.01000 #> Loss at epoch 24: training: 0.187, validation: 0.107, lr: 0.01000 #> Loss at epoch 25: training: 0.177, validation: 0.592, lr: 0.01000 #> Loss at epoch 26: training: 0.270, validation: 0.107, lr: 0.01000 #> Loss at epoch 27: training: 0.342, validation: 0.636, lr: 0.01000 #> Loss at epoch 28: training: 0.194, validation: 0.362, lr: 0.01000 #> Loss at epoch 29: training: 0.170, validation: 0.123, lr: 0.01000 #> Loss at epoch 30: training: 0.278, validation: 0.692, lr: 0.01000 #> Loss at epoch 31: training: 0.282, validation: 0.161, lr: 0.01000 #> Loss at epoch 32: training: 0.155, validation: 0.112, lr: 0.01000 #> Loss at epoch 33: training: 0.129, validation: 0.129, lr: 0.01000 #> Loss at epoch 34: training: 0.146, validation: 0.412, lr: 0.01000 #> Loss at epoch 35: training: 0.194, validation: 0.222, lr: 0.01000 #> Loss at epoch 36: training: 0.141, validation: 0.254, lr: 0.01000 #> Loss at epoch 37: training: 0.183, validation: 0.190, lr: 0.01000 #> Loss at epoch 38: training: 0.194, validation: 0.160, lr: 0.01000 #> Loss at epoch 39: training: 0.152, validation: 0.558, lr: 0.01000 #> Loss at epoch 40: training: 0.149, validation: 0.090, lr: 0.01000 #> Loss at epoch 41: training: 0.149, validation: 0.181, lr: 0.01000 #> Loss at epoch 42: training: 0.155, validation: 0.274, lr: 0.01000 #> Loss at epoch 43: training: 0.171, validation: 1.030, lr: 0.01000 #> Loss at epoch 44: training: 0.182, validation: 0.156, lr: 0.01000 #> Loss at epoch 45: training: 0.186, validation: 0.090, lr: 0.01000 #> Loss at epoch 46: training: 0.159, validation: 0.462, lr: 0.01000 #> Loss at epoch 47: training: 0.175, validation: 0.210, lr: 0.01000 #> Loss at epoch 48: training: 0.149, validation: 0.096, lr: 0.01000 #> Loss at epoch 49: training: 0.172, validation: 0.654, lr: 0.01000 #> Loss at epoch 50: training: 0.337, validation: 0.358, lr: 0.01000 #> Loss at epoch 51: training: 0.174, validation: 0.087, lr: 0.01000 #> Loss at epoch 52: training: 0.224, validation: 0.094, lr: 0.01000 #> Loss at epoch 53: training: 0.145, validation: 0.098, lr: 0.01000 #> Loss at epoch 54: training: 0.160, validation: 0.390, lr: 0.01000 #> Loss at epoch 55: training: 0.129, validation: 0.112, lr: 0.01000 #> Loss at epoch 56: training: 0.122, validation: 0.103, lr: 0.01000 #> Loss at epoch 57: training: 0.115, validation: 0.131, lr: 0.01000 #> Loss at epoch 58: training: 0.309, validation: 0.206, lr: 0.01000 #> Loss at epoch 59: training: 0.129, validation: 0.223, lr: 0.01000 #> Loss at epoch 60: training: 0.225, validation: 0.086, lr: 0.01000 #> Loss at epoch 61: training: 0.143, validation: 0.135, lr: 0.01000 #> Loss at epoch 62: training: 0.147, validation: 0.172, lr: 0.01000 #> Loss at epoch 63: training: 0.140, validation: 0.093, lr: 0.01000 #> Loss at epoch 64: training: 0.153, validation: 0.108, lr: 0.01000 #> Loss at epoch 65: training: 0.122, validation: 0.176, lr: 0.01000 #> Loss at epoch 66: training: 0.163, validation: 0.093, lr: 0.01000 #> Loss at epoch 67: training: 0.112, validation: 0.086, lr: 0.01000 #> Loss at epoch 68: training: 0.159, validation: 0.267, lr: 0.01000 #> Loss at epoch 69: training: 0.277, validation: 0.494, lr: 0.01000 #> Loss at epoch 70: training: 0.177, validation: 0.944, lr: 0.01000 #> Loss at epoch 71: training: 0.240, validation: 0.350, lr: 0.01000 #> Loss at epoch 72: training: 0.133, validation: 0.083, lr: 0.01000 #> Loss at epoch 73: training: 0.147, validation: 0.093, lr: 0.01000 #> Loss at epoch 74: training: 0.170, validation: 0.279, lr: 0.01000 #> Loss at epoch 75: training: 0.149, validation: 0.109, lr: 0.01000 #> Loss at epoch 76: training: 0.156, validation: 0.079, lr: 0.01000 #> Loss at epoch 77: training: 0.178, validation: 0.887, lr: 0.01000 #> Loss at epoch 78: training: 0.231, validation: 0.264, lr: 0.01000 #> Loss at epoch 79: training: 0.115, validation: 0.076, lr: 0.01000 #> Loss at epoch 80: training: 0.121, validation: 0.136, lr: 0.01000 #> Loss at epoch 81: training: 0.124, validation: 0.105, lr: 0.01000 #> Loss at epoch 82: training: 0.115, validation: 0.405, lr: 0.01000 #> Loss at epoch 83: training: 0.128, validation: 0.133, lr: 0.01000 #> Loss at epoch 84: training: 0.115, validation: 0.186, lr: 0.01000 #> Loss at epoch 85: training: 0.142, validation: 0.103, lr: 0.01000 #> Loss at epoch 86: training: 0.110, validation: 0.078, lr: 0.01000 #> Loss at epoch 87: training: 0.184, validation: 0.518, lr: 0.01000 #> Loss at epoch 88: training: 0.220, validation: 0.081, lr: 0.01000 #> Loss at epoch 89: training: 0.143, validation: 0.103, lr: 0.01000 #> Loss at epoch 90: training: 0.163, validation: 0.216, lr: 0.01000 #> Loss at epoch 91: training: 0.193, validation: 0.077, lr: 0.01000 #> Loss at epoch 92: training: 0.143, validation: 0.076, lr: 0.01000 #> Loss at epoch 93: training: 0.121, validation: 0.231, lr: 0.01000 #> Loss at epoch 94: training: 0.131, validation: 0.331, lr: 0.01000 #> Loss at epoch 95: training: 0.119, validation: 0.089, lr: 0.01000 #> Loss at epoch 96: training: 0.253, validation: 0.092, lr: 0.01000 #> Loss at epoch 97: training: 0.103, validation: 0.157, lr: 0.01000 #> Loss at epoch 98: training: 0.183, validation: 0.515, lr: 0.01000 #> Loss at epoch 99: training: 0.180, validation: 0.151, lr: 0.01000 #> Loss at epoch 100: training: 0.125, validation: 0.072, lr: 0.01000  # }"},{"path":"/reference/avgPool.html","id":null,"dir":"Reference","previous_headings":"","what":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"function creates avgPool layer object class citolayer use constructing Convolutional Neural Network (CNN) architecture. resulting layer object can passed create_architecture function define structure network.","code":""},{"path":"/reference/avgPool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"","code":"avgPool(kernel_size = NULL, stride = NULL, padding = NULL)"},{"path":"/reference/avgPool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"kernel_size (integer tuple) size kernel layer. Use tuple kernel size differs across dimensions. stride (integer tuple) stride kernel layer. NULL, stride set kernel size. Use tuple stride differs across dimensions. padding (integer tuple) amount zero-padding added input sides. Use tuple padding differs across dimensions.","code":""},{"path":"/reference/avgPool.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"S3 object class \"avgPool\" \"citolayer\", representing average pooling layer CNN architecture.","code":""},{"path":"/reference/avgPool.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"function creates avgPool layer object, represents average pooling layer CNN architecture. Parameters specified (thus set NULL) filled default values provided create_architecture function.","code":""},{"path":[]},{"path":"/reference/avgPool.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"Armin Schenk","code":""},{"path":"/reference/avgPool.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This function creates an avgPool layer object of class citolayer for use in constructing a Convolutional Neural Network (CNN) architecture. The resulting layer object can be passed to the create_architecture function to define the structure of the network. — avgPool","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # A average pooling layer where all available parameters are assigned # No value will be overwritten by 'create_architecture()' layer1 <- avgPool(3, 1, 0)  # A average pooling layer where only the kernel size is assigned # stride and padding are filled with the defaults # passed to the 'create_architecture()' function layer2 <- avgPool(kernel_size=4) } # }"},{"path":"/reference/cito.html","id":null,"dir":"Reference","previous_headings":"","what":"'cito': Building and training neural networks — cito","title":"'cito': Building and training neural networks — cito","text":"'cito' package provides user-friendly interface training interpreting deep neural networks (DNN). 'cito' simplifies fitting DNNs supporting familiar formula syntax, hyperparameter tuning cross-validation, helps detect handle convergence problems.  DNNs can trained CPU, GPU MacOS GPUs. addition, 'cito' many downstream functionalities various explainable AI (xAI) metrics (e.g. variable importance, partial dependence plots, accumulated local effect plots, effect estimates) interpret trained DNNs. 'cito' optionally provides confidence intervals (p-values) xAI metrics predictions. time, 'cito' computationally efficient based deep learning framework 'torch'. 'torch' package native R, Python installation API required package.","code":""},{"path":"/reference/cito.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"'cito': Building and training neural networks — cito","text":"Cito built around main function dnn, creates trains deep neural network. Various tools analyzing trained neural network available.","code":""},{"path":"/reference/cito.html","id":"installation","dir":"Reference","previous_headings":"","what":"Installation","title":"'cito': Building and training neural networks — cito","text":"order install cito please follow steps: install.packages(\"cito\") library(torch) install_torch(reinstall = TRUE) library(cito)","code":""},{"path":"/reference/cito.html","id":"cito-functions-and-typical-workflow","dir":"Reference","previous_headings":"","what":"cito functions and typical workflow","title":"'cito': Building and training neural networks — cito","text":"dnn: train deep neural network analyze_training: check convergence comparing training loss baseline loss continue_training: continues training existing cito dnn model additional epochs summary.citodnn: extract xAI metrics/effects understand predictions made PDP: plot partial dependency plot specific feature ALE: plot accumulated local effect plot specific feature Check vignettes details training NN typical workflow 'cito' look like.","code":""},{"path":[]},{"path":"/reference/cito.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"'cito': Building and training neural networks — cito","text":"Maintainer: Maximilian Pichler maximilian.pichler@biologie.uni-regensburg.de (ORCID) Authors: Christian Amesöder Christian.Amesoeder@informatik.uni-regensburg.de contributors: Florian Hartig florian.hartig@biologie.uni-regensburg.de (ORCID) [contributor] Armin Schenk armin.schenk99@gmail.com [contributor]","code":""},{"path":"/reference/cito.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"'cito': Building and training neural networks — cito","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Example workflow in cito  ## Build and train  Network ### softmax is used for multi-class responses (e.g., Species) nn.fit<- dnn(Species~., data = datasets::iris, loss = \"softmax\")  ## The training loss is below the baseline loss but at the end of the ## training the loss was still decreasing, so continue training for another 50 ## epochs nn.fit <- continue_training(nn.fit, epochs = 50L)  # Sturcture of Neural Network print(nn.fit)  # Plot Neural Network plot(nn.fit) ## 4 Input nodes (first layer) because of 4 features ## 3 Output nodes (last layer) because of 3 response species (one node for each ## level in the response variable). ## The layers between the input and output layer are called hidden layers (two ## of them)  ## We now want to understand how the predictions are made, what are the ## important features? The summary function automatically calculates feature ## importance (the interpretation is similar to an anova) and calculates ## average conditional effects that are similar to linear effects: summary(nn.fit)  ## To visualize the effect (response-feature effect), we can use the ALE and ## PDP functions  # Partial dependencies PDP(nn.fit, variable = \"Petal.Length\")  # Accumulated local effect plots ALE(nn.fit, variable = \"Petal.Length\")    # Per se, it is difficult to get confidence intervals for our xAI metrics (or # for the predictions). But we can use bootstrapping to obtain uncertainties # for all cito outputs: ## Re-fit the neural network with bootstrapping nn.fit<- dnn(Species~.,              data = datasets::iris,              loss = \"softmax\",              epochs = 150L,              verbose = FALSE,              bootstrap = 20L) ## convergence can be tested via the analyze_training function analyze_training(nn.fit)  ## Summary for xAI metrics (can take some time): summary(nn.fit) ## Now with standard errors and p-values ## Note: Take the p-values with a grain of salt! We do not know yet if they are ## correct (e.g. if you use regularization, they are likely conservative == too ## large)  ## Predictions with bootstrapping: dim(predict(nn.fit)) ## predictions are by default averaged (over the bootstrap samples)  ## Multinomial and conditional logit regression m = dnn(Species~., data = iris, loss = \"clogit\", lr = 0.01) m = dnn(Species~., data = iris, loss = \"multinomial\", lr = 0.01)  Y = t(stats::rmultinom(100, 10, prob = c(0.2, 0.2, 0.5))) m = dnn(cbind(X1, X2, X3)~., data = data.frame(Y, A = as.factor(runif(100))), loss = \"multinomial\", lr = 0.01) ## conditional logit for size > 1 is not supported yet   # Hyperparameter tuning (experimental feature) hidden_values = matrix(c(5, 2,                          4, 2,                          10,2,                          15,2), 4, 2, byrow = TRUE) ## Potential architectures we want to test, first column == number of nodes print(hidden_values)  nn.fit = dnn(Species~.,              data = iris,              epochs = 30L,              loss = \"softmax\",              hidden = tune(values = hidden_values),              lr = tune(0.00001, 0.1) # tune lr between range 0.00001 and 0.1              ) ## Tuning results: print(nn.fit$tuning)  # test = Inf means that tuning was cancelled after only one fit (within the CV)   # Advanced: Custom loss functions and additional parameters ## Normal Likelihood with sd parameter: custom_loss = function(pred, true) {   logLik = torch::distr_normal(pred,                                scale = torch::nnf_relu(scale)+                                  0.001)$log_prob(true)   return(-logLik$mean()) }  nn.fit<- dnn(Sepal.Length~.,              data = datasets::iris,              loss = custom_loss,              verbose = FALSE,              custom_parameters = list(scale = 1.0) ) nn.fit$parameter$scale  ## Multivariate normal likelihood with parametrized covariance matrix ## Sigma = L*L^t + D ## Helper function to build covariance matrix create_cov = function(LU, Diag) {   return(torch::torch_matmul(LU, LU$t()) + torch::torch_diag(Diag$exp()+0.01)) }  custom_loss_MVN = function(true, pred) {   Sigma = create_cov(SigmaPar, SigmaDiag)   logLik = torch::distr_multivariate_normal(pred,                                             covariance_matrix = Sigma)$     log_prob(true)   return(-logLik$mean()) }   nn.fit<- dnn(cbind(Sepal.Length, Sepal.Width, Petal.Length)~.,              data = datasets::iris,              lr = 0.01,              verbose = FALSE,              loss = custom_loss_MVN,              custom_parameters =                list(SigmaDiag =  rep(0, 3),                     SigmaPar = matrix(rnorm(6, sd = 0.001), 3, 2)) ) as.matrix(create_cov(nn.fit$loss$parameter$SigmaPar,                      nn.fit$loss$parameter$SigmaDiag))  } #> Loss at epoch 1: 1.028129, lr: 0.01000  #> Loss at epoch 2: 0.901958, lr: 0.01000 #> Loss at epoch 3: 0.796776, lr: 0.01000 #> Loss at epoch 4: 0.729468, lr: 0.01000 #> Loss at epoch 5: 0.644836, lr: 0.01000 #> Loss at epoch 6: 0.636941, lr: 0.01000 #> Loss at epoch 7: 0.574591, lr: 0.01000 #> Loss at epoch 8: 0.535066, lr: 0.01000 #> Loss at epoch 9: 0.495465, lr: 0.01000 #> Loss at epoch 10: 0.491982, lr: 0.01000 #> Loss at epoch 11: 0.455357, lr: 0.01000 #> Loss at epoch 12: 0.440196, lr: 0.01000 #> Loss at epoch 13: 0.423234, lr: 0.01000 #> Loss at epoch 14: 0.404440, lr: 0.01000 #> Loss at epoch 15: 0.389705, lr: 0.01000 #> Loss at epoch 16: 0.373012, lr: 0.01000 #> Loss at epoch 17: 0.364483, lr: 0.01000 #> Loss at epoch 18: 0.347243, lr: 0.01000 #> Loss at epoch 19: 0.325396, lr: 0.01000 #> Loss at epoch 20: 0.319343, lr: 0.01000 #> Loss at epoch 21: 0.302919, lr: 0.01000 #> Loss at epoch 22: 0.308175, lr: 0.01000 #> Loss at epoch 23: 0.285796, lr: 0.01000 #> Loss at epoch 24: 0.304754, lr: 0.01000 #> Loss at epoch 25: 0.285883, lr: 0.01000 #> Loss at epoch 26: 0.265439, lr: 0.01000 #> Loss at epoch 27: 0.251801, lr: 0.01000 #> Loss at epoch 28: 0.243715, lr: 0.01000 #> Loss at epoch 29: 0.237872, lr: 0.01000 #> Loss at epoch 30: 0.227322, lr: 0.01000 #> Loss at epoch 31: 0.217828, lr: 0.01000 #> Loss at epoch 32: 0.211607, lr: 0.01000 #> Loss at epoch 33: 0.207035, lr: 0.01000 #> Loss at epoch 34: 0.215674, lr: 0.01000 #> Loss at epoch 35: 0.194667, lr: 0.01000 #> Loss at epoch 36: 0.193276, lr: 0.01000 #> Loss at epoch 37: 0.191401, lr: 0.01000 #> Loss at epoch 38: 0.173749, lr: 0.01000 #> Loss at epoch 39: 0.173219, lr: 0.01000 #> Loss at epoch 40: 0.189330, lr: 0.01000 #> Loss at epoch 41: 0.178352, lr: 0.01000 #> Loss at epoch 42: 0.165828, lr: 0.01000 #> Loss at epoch 43: 0.160566, lr: 0.01000 #> Loss at epoch 44: 0.175424, lr: 0.01000 #> Loss at epoch 45: 0.160873, lr: 0.01000 #> Loss at epoch 46: 0.162290, lr: 0.01000 #> Loss at epoch 47: 0.170782, lr: 0.01000 #> Loss at epoch 48: 0.142525, lr: 0.01000 #> Loss at epoch 49: 0.136984, lr: 0.01000 #> Loss at epoch 50: 0.134339, lr: 0.01000 #> Loss at epoch 51: 0.149776, lr: 0.01000 #> Loss at epoch 52: 0.139126, lr: 0.01000 #> Loss at epoch 53: 0.145396, lr: 0.01000 #> Loss at epoch 54: 0.132434, lr: 0.01000 #> Loss at epoch 55: 0.139382, lr: 0.01000 #> Loss at epoch 56: 0.121038, lr: 0.01000 #> Loss at epoch 57: 0.111437, lr: 0.01000 #> Loss at epoch 58: 0.120576, lr: 0.01000 #> Loss at epoch 59: 0.126434, lr: 0.01000 #> Loss at epoch 60: 0.122956, lr: 0.01000 #> Loss at epoch 61: 0.135895, lr: 0.01000 #> Loss at epoch 62: 0.118843, lr: 0.01000 #> Loss at epoch 63: 0.119675, lr: 0.01000 #> Loss at epoch 64: 0.155256, lr: 0.01000 #> Loss at epoch 65: 0.137365, lr: 0.01000 #> Loss at epoch 66: 0.112379, lr: 0.01000 #> Loss at epoch 67: 0.102348, lr: 0.01000 #> Loss at epoch 68: 0.106337, lr: 0.01000 #> Loss at epoch 69: 0.106938, lr: 0.01000 #> Loss at epoch 70: 0.104467, lr: 0.01000 #> Loss at epoch 71: 0.097326, lr: 0.01000 #> Loss at epoch 72: 0.117703, lr: 0.01000 #> Loss at epoch 73: 0.100832, lr: 0.01000 #> Loss at epoch 74: 0.113942, lr: 0.01000 #> Loss at epoch 75: 0.098676, lr: 0.01000 #> Loss at epoch 76: 0.104589, lr: 0.01000 #> Loss at epoch 77: 0.100378, lr: 0.01000 #> Loss at epoch 78: 0.093891, lr: 0.01000 #> Loss at epoch 79: 0.093112, lr: 0.01000 #> Loss at epoch 80: 0.094668, lr: 0.01000 #> Loss at epoch 81: 0.118778, lr: 0.01000 #> Loss at epoch 82: 0.088652, lr: 0.01000 #> Loss at epoch 83: 0.092798, lr: 0.01000 #> Loss at epoch 84: 0.089796, lr: 0.01000 #> Loss at epoch 85: 0.102770, lr: 0.01000 #> Loss at epoch 86: 0.095056, lr: 0.01000 #> Loss at epoch 87: 0.115043, lr: 0.01000 #> Loss at epoch 88: 0.095890, lr: 0.01000 #> Loss at epoch 89: 0.094287, lr: 0.01000 #> Loss at epoch 90: 0.079088, lr: 0.01000 #> Loss at epoch 91: 0.119451, lr: 0.01000 #> Loss at epoch 92: 0.088465, lr: 0.01000 #> Loss at epoch 93: 0.098638, lr: 0.01000 #> Loss at epoch 94: 0.092730, lr: 0.01000 #> Loss at epoch 95: 0.085831, lr: 0.01000 #> Loss at epoch 96: 0.088967, lr: 0.01000 #> Loss at epoch 97: 0.094985, lr: 0.01000 #> Loss at epoch 98: 0.108592, lr: 0.01000 #> Loss at epoch 99: 0.077884, lr: 0.01000 #> Loss at epoch 100: 0.088470, lr: 0.01000 #> Loss at epoch 101: 0.095510, lr: 0.01000  #> Loss at epoch 102: 0.089307, lr: 0.01000 #> Loss at epoch 103: 0.071911, lr: 0.01000 #> Loss at epoch 104: 0.095836, lr: 0.01000 #> Loss at epoch 105: 0.074341, lr: 0.01000 #> Loss at epoch 106: 0.083014, lr: 0.01000 #> Loss at epoch 107: 0.090436, lr: 0.01000 #> Loss at epoch 108: 0.081577, lr: 0.01000 #> Loss at epoch 109: 0.102380, lr: 0.01000 #> Loss at epoch 110: 0.082503, lr: 0.01000 #> Loss at epoch 111: 0.087474, lr: 0.01000 #> Loss at epoch 112: 0.077108, lr: 0.01000 #> Loss at epoch 113: 0.114079, lr: 0.01000 #> Loss at epoch 114: 0.100395, lr: 0.01000 #> Loss at epoch 115: 0.083112, lr: 0.01000 #> Loss at epoch 116: 0.094819, lr: 0.01000 #> Loss at epoch 117: 0.076733, lr: 0.01000 #> Loss at epoch 118: 0.091762, lr: 0.01000 #> Loss at epoch 119: 0.065681, lr: 0.01000 #> Loss at epoch 120: 0.085504, lr: 0.01000 #> Loss at epoch 121: 0.069642, lr: 0.01000 #> Loss at epoch 122: 0.070765, lr: 0.01000 #> Loss at epoch 123: 0.074615, lr: 0.01000 #> Loss at epoch 124: 0.084287, lr: 0.01000 #> Loss at epoch 125: 0.074067, lr: 0.01000 #> Loss at epoch 126: 0.097645, lr: 0.01000 #> Loss at epoch 127: 0.090851, lr: 0.01000 #> Loss at epoch 128: 0.068881, lr: 0.01000 #> Loss at epoch 129: 0.081341, lr: 0.01000 #> Loss at epoch 130: 0.066448, lr: 0.01000 #> Loss at epoch 131: 0.087900, lr: 0.01000 #> Loss at epoch 132: 0.082455, lr: 0.01000 #> Loss at epoch 133: 0.070454, lr: 0.01000 #> Loss at epoch 134: 0.106875, lr: 0.01000 #> Loss at epoch 135: 0.080947, lr: 0.01000 #> Loss at epoch 136: 0.072918, lr: 0.01000 #> Loss at epoch 137: 0.075408, lr: 0.01000 #> Loss at epoch 138: 0.065989, lr: 0.01000 #> Loss at epoch 139: 0.073839, lr: 0.01000 #> Loss at epoch 140: 0.083702, lr: 0.01000 #> Loss at epoch 141: 0.067250, lr: 0.01000 #> Loss at epoch 142: 0.073940, lr: 0.01000 #> Loss at epoch 143: 0.079373, lr: 0.01000 #> Loss at epoch 144: 0.078913, lr: 0.01000 #> Loss at epoch 145: 0.066251, lr: 0.01000 #> Loss at epoch 146: 0.095477, lr: 0.01000 #> Loss at epoch 147: 0.079328, lr: 0.01000 #> Loss at epoch 148: 0.101016, lr: 0.01000 #> Loss at epoch 149: 0.083090, lr: 0.01000 #> Loss at epoch 150: 0.077563, lr: 0.01000 #> dnn(formula = Species ~ Sepal.Length + Sepal.Width + Petal.Length +  #>     Petal.Width, data = datasets::iris, loss = \"softmax\") #> An `nn_module` containing 2,953 parameters. #>  #> ── Modules ───────────────────────────────────────────────────────────────────── #> • 0: <nn_linear> #250 parameters #> • 1: <nn_selu> #0 parameters #> • 2: <nn_linear> #2,550 parameters #> • 3: <nn_selu> #0 parameters #> • 4: <nn_linear> #153 parameters   #> Number of Neighborhoods reduced to 8 #> Number of Neighborhoods reduced to 8 #> Number of Neighborhoods reduced to 8  #> Loss at epoch 1: 0.621228, lr: 0.01000  #> Loss at epoch 2: 0.580236, lr: 0.01000 #> Loss at epoch 3: 0.549974, lr: 0.01000 #> Loss at epoch 4: 0.516203, lr: 0.01000 #> Loss at epoch 5: 0.492190, lr: 0.01000 #> Loss at epoch 6: 0.467423, lr: 0.01000 #> Loss at epoch 7: 0.445653, lr: 0.01000 #> Loss at epoch 8: 0.425039, lr: 0.01000 #> Loss at epoch 9: 0.405358, lr: 0.01000 #> Loss at epoch 10: 0.386309, lr: 0.01000 #> Loss at epoch 11: 0.372660, lr: 0.01000 #> Loss at epoch 12: 0.359912, lr: 0.01000 #> Loss at epoch 13: 0.347467, lr: 0.01000 #> Loss at epoch 14: 0.333965, lr: 0.01000 #> Loss at epoch 15: 0.324504, lr: 0.01000 #> Loss at epoch 16: 0.316904, lr: 0.01000 #> Loss at epoch 17: 0.304670, lr: 0.01000 #> Loss at epoch 18: 0.293441, lr: 0.01000 #> Loss at epoch 19: 0.287496, lr: 0.01000 #> Loss at epoch 20: 0.278483, lr: 0.01000 #> Loss at epoch 21: 0.273015, lr: 0.01000 #> Loss at epoch 22: 0.264038, lr: 0.01000 #> Loss at epoch 23: 0.259724, lr: 0.01000 #> Loss at epoch 24: 0.254735, lr: 0.01000 #> Loss at epoch 25: 0.243558, lr: 0.01000 #> Loss at epoch 26: 0.241815, lr: 0.01000 #> Loss at epoch 27: 0.232573, lr: 0.01000 #> Loss at epoch 28: 0.225291, lr: 0.01000 #> Loss at epoch 29: 0.219698, lr: 0.01000 #> Loss at epoch 30: 0.216967, lr: 0.01000 #> Loss at epoch 31: 0.213643, lr: 0.01000 #> Loss at epoch 32: 0.209031, lr: 0.01000 #> Loss at epoch 33: 0.201099, lr: 0.01000 #> Loss at epoch 34: 0.196401, lr: 0.01000 #> Loss at epoch 35: 0.190332, lr: 0.01000 #> Loss at epoch 36: 0.188689, lr: 0.01000 #> Loss at epoch 37: 0.180711, lr: 0.01000 #> Loss at epoch 38: 0.181188, lr: 0.01000 #> Loss at epoch 39: 0.169237, lr: 0.01000 #> Loss at epoch 40: 0.170794, lr: 0.01000 #> Loss at epoch 41: 0.164362, lr: 0.01000 #> Loss at epoch 42: 0.161676, lr: 0.01000 #> Loss at epoch 43: 0.158048, lr: 0.01000 #> Loss at epoch 44: 0.151875, lr: 0.01000 #> Loss at epoch 45: 0.151100, lr: 0.01000 #> Loss at epoch 46: 0.147166, lr: 0.01000 #> Loss at epoch 47: 0.142907, lr: 0.01000 #> Loss at epoch 48: 0.141146, lr: 0.01000 #> Loss at epoch 49: 0.136725, lr: 0.01000 #> Loss at epoch 50: 0.132671, lr: 0.01000 #> Loss at epoch 51: 0.130276, lr: 0.01000 #> Loss at epoch 52: 0.130272, lr: 0.01000 #> Loss at epoch 53: 0.128855, lr: 0.01000 #> Loss at epoch 54: 0.129522, lr: 0.01000 #> Loss at epoch 55: 0.121622, lr: 0.01000 #> Loss at epoch 56: 0.119577, lr: 0.01000 #> Loss at epoch 57: 0.115492, lr: 0.01000 #> Loss at epoch 58: 0.116751, lr: 0.01000 #> Loss at epoch 59: 0.118607, lr: 0.01000 #> Loss at epoch 60: 0.112974, lr: 0.01000 #> Loss at epoch 61: 0.105417, lr: 0.01000 #> Loss at epoch 62: 0.108555, lr: 0.01000 #> Loss at epoch 63: 0.108640, lr: 0.01000 #> Loss at epoch 64: 0.101279, lr: 0.01000 #> Loss at epoch 65: 0.103371, lr: 0.01000 #> Loss at epoch 66: 0.100340, lr: 0.01000 #> Loss at epoch 67: 0.098973, lr: 0.01000 #> Loss at epoch 68: 0.098083, lr: 0.01000 #> Loss at epoch 69: 0.096918, lr: 0.01000 #> Loss at epoch 70: 0.099659, lr: 0.01000 #> Loss at epoch 71: 0.094592, lr: 0.01000 #> Loss at epoch 72: 0.092785, lr: 0.01000 #> Loss at epoch 73: 0.090593, lr: 0.01000 #> Loss at epoch 74: 0.091643, lr: 0.01000 #> Loss at epoch 75: 0.092637, lr: 0.01000 #> Loss at epoch 76: 0.089657, lr: 0.01000 #> Loss at epoch 77: 0.086581, lr: 0.01000 #> Loss at epoch 78: 0.088828, lr: 0.01000 #> Loss at epoch 79: 0.087774, lr: 0.01000 #> Loss at epoch 80: 0.080636, lr: 0.01000 #> Loss at epoch 81: 0.082332, lr: 0.01000 #> Loss at epoch 82: 0.081213, lr: 0.01000 #> Loss at epoch 83: 0.080078, lr: 0.01000 #> Loss at epoch 84: 0.082587, lr: 0.01000 #> Loss at epoch 85: 0.081111, lr: 0.01000 #> Loss at epoch 86: 0.079289, lr: 0.01000 #> Loss at epoch 87: 0.077370, lr: 0.01000 #> Loss at epoch 88: 0.078495, lr: 0.01000 #> Loss at epoch 89: 0.077228, lr: 0.01000 #> Loss at epoch 90: 0.072742, lr: 0.01000 #> Loss at epoch 91: 0.074160, lr: 0.01000 #> Loss at epoch 92: 0.072535, lr: 0.01000 #> Loss at epoch 93: 0.072903, lr: 0.01000 #> Loss at epoch 94: 0.071393, lr: 0.01000 #> Loss at epoch 95: 0.074971, lr: 0.01000 #> Loss at epoch 96: 0.071612, lr: 0.01000 #> Loss at epoch 97: 0.068308, lr: 0.01000 #> Loss at epoch 98: 0.068272, lr: 0.01000 #> Loss at epoch 99: 0.075458, lr: 0.01000 #> Loss at epoch 100: 0.073320, lr: 0.01000 #> Loss at epoch 1: 1.029353, lr: 0.01000  #> Loss at epoch 2: 0.838056, lr: 0.01000 #> Loss at epoch 3: 0.736363, lr: 0.01000 #> Loss at epoch 4: 0.665682, lr: 0.01000 #> Loss at epoch 5: 0.596405, lr: 0.01000 #> Loss at epoch 6: 0.553778, lr: 0.01000 #> Loss at epoch 7: 0.517172, lr: 0.01000 #> Loss at epoch 8: 0.510965, lr: 0.01000 #> Loss at epoch 9: 0.454185, lr: 0.01000 #> Loss at epoch 10: 0.444283, lr: 0.01000 #> Loss at epoch 11: 0.410581, lr: 0.01000 #> Loss at epoch 12: 0.395968, lr: 0.01000 #> Loss at epoch 13: 0.385857, lr: 0.01000 #> Loss at epoch 14: 0.376048, lr: 0.01000 #> Loss at epoch 15: 0.352194, lr: 0.01000 #> Loss at epoch 16: 0.338680, lr: 0.01000 #> Loss at epoch 17: 0.325352, lr: 0.01000 #> Loss at epoch 18: 0.315521, lr: 0.01000 #> Loss at epoch 19: 0.312051, lr: 0.01000 #> Loss at epoch 20: 0.295578, lr: 0.01000 #> Loss at epoch 21: 0.284522, lr: 0.01000 #> Loss at epoch 22: 0.275860, lr: 0.01000 #> Loss at epoch 23: 0.281111, lr: 0.01000 #> Loss at epoch 24: 0.257511, lr: 0.01000 #> Loss at epoch 25: 0.272087, lr: 0.01000 #> Loss at epoch 26: 0.231601, lr: 0.01000 #> Loss at epoch 27: 0.221238, lr: 0.01000 #> Loss at epoch 28: 0.238053, lr: 0.01000 #> Loss at epoch 29: 0.246936, lr: 0.01000 #> Loss at epoch 30: 0.224995, lr: 0.01000 #> Loss at epoch 31: 0.210830, lr: 0.01000 #> Loss at epoch 32: 0.214294, lr: 0.01000 #> Loss at epoch 33: 0.216633, lr: 0.01000 #> Loss at epoch 34: 0.197873, lr: 0.01000 #> Loss at epoch 35: 0.185298, lr: 0.01000 #> Loss at epoch 36: 0.181255, lr: 0.01000 #> Loss at epoch 37: 0.181786, lr: 0.01000 #> Loss at epoch 38: 0.164843, lr: 0.01000 #> Loss at epoch 39: 0.180574, lr: 0.01000 #> Loss at epoch 40: 0.164188, lr: 0.01000 #> Loss at epoch 41: 0.155880, lr: 0.01000 #> Loss at epoch 42: 0.158921, lr: 0.01000 #> Loss at epoch 43: 0.149166, lr: 0.01000 #> Loss at epoch 44: 0.149103, lr: 0.01000 #> Loss at epoch 45: 0.150007, lr: 0.01000 #> Loss at epoch 46: 0.148908, lr: 0.01000 #> Loss at epoch 47: 0.137504, lr: 0.01000 #> Loss at epoch 48: 0.148899, lr: 0.01000 #> Loss at epoch 49: 0.138947, lr: 0.01000 #> Loss at epoch 50: 0.125745, lr: 0.01000 #> Loss at epoch 51: 0.129502, lr: 0.01000 #> Loss at epoch 52: 0.120199, lr: 0.01000 #> Loss at epoch 53: 0.121725, lr: 0.01000 #> Loss at epoch 54: 0.123944, lr: 0.01000 #> Loss at epoch 55: 0.118878, lr: 0.01000 #> Loss at epoch 56: 0.115712, lr: 0.01000 #> Loss at epoch 57: 0.114687, lr: 0.01000 #> Loss at epoch 58: 0.106719, lr: 0.01000 #> Loss at epoch 59: 0.112906, lr: 0.01000 #> Loss at epoch 60: 0.104644, lr: 0.01000 #> Loss at epoch 61: 0.116849, lr: 0.01000 #> Loss at epoch 62: 0.135903, lr: 0.01000 #> Loss at epoch 63: 0.112682, lr: 0.01000 #> Loss at epoch 64: 0.112904, lr: 0.01000 #> Loss at epoch 65: 0.102428, lr: 0.01000 #> Loss at epoch 66: 0.105639, lr: 0.01000 #> Loss at epoch 67: 0.096896, lr: 0.01000 #> Loss at epoch 68: 0.115266, lr: 0.01000 #> Loss at epoch 69: 0.101151, lr: 0.01000 #> Loss at epoch 70: 0.098566, lr: 0.01000 #> Loss at epoch 71: 0.096959, lr: 0.01000 #> Loss at epoch 72: 0.099351, lr: 0.01000 #> Loss at epoch 73: 0.105310, lr: 0.01000 #> Loss at epoch 74: 0.098299, lr: 0.01000 #> Loss at epoch 75: 0.099592, lr: 0.01000 #> Loss at epoch 76: 0.098473, lr: 0.01000 #> Loss at epoch 77: 0.096547, lr: 0.01000 #> Loss at epoch 78: 0.091812, lr: 0.01000 #> Loss at epoch 79: 0.088663, lr: 0.01000 #> Loss at epoch 80: 0.098265, lr: 0.01000 #> Loss at epoch 81: 0.097573, lr: 0.01000 #> Loss at epoch 82: 0.103566, lr: 0.01000 #> Loss at epoch 83: 0.083291, lr: 0.01000 #> Loss at epoch 84: 0.084916, lr: 0.01000 #> Loss at epoch 85: 0.083162, lr: 0.01000 #> Loss at epoch 86: 0.088358, lr: 0.01000 #> Loss at epoch 87: 0.076779, lr: 0.01000 #> Loss at epoch 88: 0.083051, lr: 0.01000 #> Loss at epoch 89: 0.074115, lr: 0.01000 #> Loss at epoch 90: 0.079659, lr: 0.01000 #> Loss at epoch 91: 0.082169, lr: 0.01000 #> Loss at epoch 92: 0.075564, lr: 0.01000 #> Loss at epoch 93: 0.084325, lr: 0.01000 #> Loss at epoch 94: 0.083941, lr: 0.01000 #> Loss at epoch 95: 0.074055, lr: 0.01000 #> Loss at epoch 96: 0.077409, lr: 0.01000 #> Loss at epoch 97: 0.078532, lr: 0.01000 #> Loss at epoch 98: 0.089807, lr: 0.01000 #> Loss at epoch 99: 0.081542, lr: 0.01000 #> Loss at epoch 100: 0.073402, lr: 0.01000 #> Loss at epoch 1: 4.050235, lr: 0.01000  #> Loss at epoch 2: 3.375148, lr: 0.01000 #> Loss at epoch 3: 3.329331, lr: 0.01000 #> Loss at epoch 4: 3.318493, lr: 0.01000 #> Loss at epoch 5: 3.312524, lr: 0.01000 #> Loss at epoch 6: 3.307514, lr: 0.01000 #> Loss at epoch 7: 3.295704, lr: 0.01000 #> Loss at epoch 8: 3.288458, lr: 0.01000 #> Loss at epoch 9: 3.289731, lr: 0.01000 #> Loss at epoch 10: 3.273467, lr: 0.01000 #> Loss at epoch 11: 3.277107, lr: 0.01000 #> Loss at epoch 12: 3.260709, lr: 0.01000 #> Loss at epoch 13: 3.250570, lr: 0.01000 #> Loss at epoch 14: 3.241755, lr: 0.01000 #> Loss at epoch 15: 3.232278, lr: 0.01000 #> Loss at epoch 16: 3.222933, lr: 0.01000 #> Loss at epoch 17: 3.214489, lr: 0.01000 #> Loss at epoch 18: 3.202994, lr: 0.01000 #> Loss at epoch 19: 3.194378, lr: 0.01000 #> Loss at epoch 20: 3.182967, lr: 0.01000 #> Loss at epoch 21: 3.170651, lr: 0.01000 #> Loss at epoch 22: 3.159124, lr: 0.01000 #> Loss at epoch 23: 3.144849, lr: 0.01000 #> Loss at epoch 24: 3.134571, lr: 0.01000 #> Loss at epoch 25: 3.119773, lr: 0.01000 #> Loss at epoch 26: 3.100516, lr: 0.01000 #> Loss at epoch 27: 3.086322, lr: 0.01000 #> Loss at epoch 28: 3.068383, lr: 0.01000 #> Loss at epoch 29: 3.041739, lr: 0.01000 #> Loss at epoch 30: 3.027909, lr: 0.01000 #> Loss at epoch 31: 3.007568, lr: 0.01000 #> Loss at epoch 32: 2.972370, lr: 0.01000 #> Loss at epoch 33: 2.950035, lr: 0.01000 #> Loss at epoch 34: 2.934669, lr: 0.01000 #> Loss at epoch 35: 2.903744, lr: 0.01000 #> Loss at epoch 36: 2.881857, lr: 0.01000 #> Loss at epoch 37: 2.855614, lr: 0.01000 #> Loss at epoch 38: 2.839620, lr: 0.01000 #> Loss at epoch 39: 2.804028, lr: 0.01000 #> Loss at epoch 40: 2.786639, lr: 0.01000 #> Loss at epoch 41: 2.756574, lr: 0.01000 #> Loss at epoch 42: 2.733724, lr: 0.01000 #> Loss at epoch 43: 2.705919, lr: 0.01000 #> Loss at epoch 44: 2.683190, lr: 0.01000 #> Loss at epoch 45: 2.661252, lr: 0.01000 #> Loss at epoch 46: 2.639226, lr: 0.01000 #> Loss at epoch 47: 2.623245, lr: 0.01000 #> Loss at epoch 48: 2.604573, lr: 0.01000 #> Loss at epoch 49: 2.581663, lr: 0.01000 #> Loss at epoch 50: 2.568873, lr: 0.01000 #> Loss at epoch 51: 2.546475, lr: 0.01000 #> Loss at epoch 52: 2.531580, lr: 0.01000 #> Loss at epoch 53: 2.523293, lr: 0.01000 #> Loss at epoch 54: 2.503576, lr: 0.01000 #> Loss at epoch 55: 2.493250, lr: 0.01000 #> Loss at epoch 56: 2.474042, lr: 0.01000 #> Loss at epoch 57: 2.461848, lr: 0.01000 #> Loss at epoch 58: 2.452574, lr: 0.01000 #> Loss at epoch 59: 2.434963, lr: 0.01000 #> Loss at epoch 60: 2.425406, lr: 0.01000 #> Loss at epoch 61: 2.412445, lr: 0.01000 #> Loss at epoch 62: 2.397073, lr: 0.01000 #> Loss at epoch 63: 2.392707, lr: 0.01000 #> Loss at epoch 64: 2.380811, lr: 0.01000 #> Loss at epoch 65: 2.372324, lr: 0.01000 #> Loss at epoch 66: 2.358699, lr: 0.01000 #> Loss at epoch 67: 2.350289, lr: 0.01000 #> Loss at epoch 68: 2.342029, lr: 0.01000 #> Loss at epoch 69: 2.334479, lr: 0.01000 #> Loss at epoch 70: 2.325935, lr: 0.01000 #> Loss at epoch 71: 2.319037, lr: 0.01000 #> Loss at epoch 72: 2.314725, lr: 0.01000 #> Loss at epoch 73: 2.306465, lr: 0.01000 #> Loss at epoch 74: 2.297722, lr: 0.01000 #> Loss at epoch 75: 2.297563, lr: 0.01000 #> Loss at epoch 76: 2.285706, lr: 0.01000 #> Loss at epoch 77: 2.282699, lr: 0.01000 #> Loss at epoch 78: 2.279500, lr: 0.01000 #> Loss at epoch 79: 2.275048, lr: 0.01000 #> Loss at epoch 80: 2.270183, lr: 0.01000 #> Loss at epoch 81: 2.266580, lr: 0.01000 #> Loss at epoch 82: 2.259874, lr: 0.01000 #> Loss at epoch 83: 2.256623, lr: 0.01000 #> Loss at epoch 84: 2.254239, lr: 0.01000 #> Loss at epoch 85: 2.248330, lr: 0.01000 #> Loss at epoch 86: 2.246702, lr: 0.01000 #> Loss at epoch 87: 2.244490, lr: 0.01000 #> Loss at epoch 88: 2.241368, lr: 0.01000 #> Loss at epoch 89: 2.236798, lr: 0.01000 #> Loss at epoch 90: 2.235200, lr: 0.01000 #> Loss at epoch 91: 2.231554, lr: 0.01000 #> Loss at epoch 92: 2.230841, lr: 0.01000 #> Loss at epoch 93: 2.230056, lr: 0.01000 #> Loss at epoch 94: 2.227161, lr: 0.01000 #> Loss at epoch 95: 2.223092, lr: 0.01000 #> Loss at epoch 96: 2.222676, lr: 0.01000 #> Loss at epoch 97: 2.218990, lr: 0.01000 #> Loss at epoch 98: 2.219755, lr: 0.01000 #> Loss at epoch 99: 2.216133, lr: 0.01000 #> Loss at epoch 100: 2.214781, lr: 0.01000 #>      [,1] [,2] #> [1,]    5    2 #> [2,]    4    2 #> [3,]   10    2 #> [4,]   15    2 #> Starting hyperparameter tuning... #> Fitting final model... #> # A tibble: 10 × 6 #>    steps  test train models hidden         lr #>    <int> <dbl> <dbl> <lgl>  <list>      <dbl> #>  1     1  53.8     0 NA     <dbl [2]> 0.0168  #>  2     2  60.5     0 NA     <dbl [2]> 0.0722  #>  3     3  26.1     0 NA     <dbl [2]> 0.0862  #>  4     4  57.5     0 NA     <dbl [2]> 0.0869  #>  5     5  31.9     0 NA     <dbl [2]> 0.0225  #>  6     6  29.4     0 NA     <dbl [2]> 0.0625  #>  7     7  30.5     0 NA     <dbl [2]> 0.0960  #>  8     8  43.0     0 NA     <dbl [2]> 0.0654  #>  9     9  45.9     0 NA     <dbl [2]> 0.0342  #> 10    10  83.4     0 NA     <dbl [2]> 0.00692   #>            [,1]       [,2]       [,3] #> [1,] 0.32808802 0.03195751 0.07836789 #> [2,] 0.03195751 0.15858485 0.02492121 #> [3,] 0.07836789 0.02492121 0.23315211 # }"},{"path":"/reference/cnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Train a Convolutional Neural Network (CNN) — cnn","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"function trains Convolutional Neural Network (CNN) provided input data X target data Y using specified architecture, loss function, optimizer.","code":""},{"path":"/reference/cnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"","code":"cnn(   X,   Y = NULL,   architecture,   loss = c(\"mse\", \"mae\", \"softmax\", \"cross-entropy\", \"gaussian\", \"binomial\", \"poisson\",     \"mvp\", \"nbinom\", \"multinomial\", \"clogit\"),   optimizer = c(\"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", \"rprop\"),   lr = 0.01,   alpha = 0.5,   lambda = 0,   validation = 0,   batchsize = 32L,   burnin = 30,   shuffle = TRUE,   epochs = 100,   early_stopping = NULL,   lr_scheduler = NULL,   custom_parameters = NULL,   device = c(\"cpu\", \"cuda\", \"mps\"),   plot = TRUE,   verbose = TRUE )"},{"path":"/reference/cnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"X array input data minimum 3 maximum 5 dimensions. first dimension represents samples, second dimension represents channels, third fifth dimensions represent input dimensions. Y target data. can factor, numeric vector, numeric logical matrix. architecture object class 'citoarchitecture'. See create_architecture information. loss loss function used. Options include \"mse\", \"mae\", \"softmax\", \"cross-entropy\", \"gaussian\", \"binomial\", \"poisson\", \"nbinom\", \"mvp\", \"multinomial\", \"clogit\". can also specify loss function. See Details information. Default \"mse\". optimizer optimizer used. Options include \"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", \"rprop\". See config_optimizer adjustments optimizer. Default \"sgd\". lr Learning rate optimizer. Default 0.01. alpha Alpha value L1/L2 regularization. Default 0.5. lambda Lambda value L1/L2 regularization. Default 0.0. validation Proportion data used validation. Default 0.0. batchsize Batch size training. Default 32. burnin Number epochs training stops loss still base loss. Default 30. shuffle Whether shuffle data epoch. Default TRUE. epochs Number epochs train model. Default 100. early_stopping Number epochs improvement training stopped. Default NULL. lr_scheduler Learning rate scheduler. See config_lr_scheduler creating learning rate scheduler. Default NULL. custom_parameters Parameters custom loss function. See vignette example. Default NULL. device Device used training. Options \"cpu\", \"cuda\", \"mps\". Default \"cpu\". plot Whether plot training progress. Default TRUE. verbose Whether print detailed training progress. Default TRUE.","code":""},{"path":"/reference/cnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"S3 object class \"citocnn\" returned. list containing everything know model training process. list consists following attributes: net object class \"nn_sequential\" \"nn_module\", originates torch package represents core object workflow. call original function call. loss list contains relevant information target variable used loss function. data Contains data used training model. base_loss loss intercept-model. weights List parameters (weights biases) models best last training epoch. buffers List buffers (e.g. running mean variance batch normalization layers) models best last training epoch. use_model_epoch Integer, defines whether model best (= 1) last (= 2) training epoch used prediction. loaded_model_epoch Integer, shows whether parameters buffers model best (= 1) last (= 2) training epoch currently loaded net. model_properties list properties, define architecture model. training_properties list training parameters used last time model trained. losses data.frame containing training validation losses epoch.","code":""},{"path":"/reference/cnn.html","id":"convolutional-neural-networks-","dir":"Reference","previous_headings":"","what":"Convolutional Neural Networks:","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"Convolutional Neural Networks (CNNs) specialized type neural network designed processing structured data, images. key components CNN convolutional layers, pooling layers fully-connected (linear) layers: Convolutional layers core building blocks CNNs. consist filters (also called kernels), small, learnable matrices. filters slide input data perform element-wise multiplication, producing feature maps capture local patterns features. Multiple filters used detect different features parallel. help network learn hierarchical representations input data capturing low-level features (edges, textures) gradually combining (subsequent convolutional layers) form higher-level features. Pooling layers reduce size feature maps created convolutional layers, retaining important information. common type max pooling, keeps highest value region, simplifying data preserving essential features. Fully-connected (linear) layers connect every neuron one layer every neuron next layer. layers found end network responsible combining high-level features make final predictions.","code":""},{"path":"/reference/cnn.html","id":"loss-functions-likelihoods","dir":"Reference","previous_headings":"","what":"Loss functions / Likelihoods","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"support loss functions likelihoods different tasks:","code":""},{"path":"/reference/cnn.html","id":"training-and-convergence-of-neural-networks","dir":"Reference","previous_headings":"","what":"Training and convergence of neural networks","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"Ensuring convergence can tricky training neural networks. training sensitive combination learning rate (much weights updated optimization step), batch size (random subset data used optimization step), number epochs (number optimization steps). Typically, learning rate decreased size neural networks (amount learnable parameters). provide baseline loss (intercept model) can give hints appropriate learning rate:  training loss model fall baseline loss, learning rate either high low. happens, try higher lower learning rates. common strategy try (manually) different learning rates see learning rate right scale. See troubleshooting vignette (vignette(\"B-Training_neural_networks\")) help training debugging neural networks.","code":""},{"path":"/reference/cnn.html","id":"finding-the-right-architecture","dir":"Reference","previous_headings":"","what":"Finding the right architecture","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"learning rate, definitive guide choosing right architecture right task. However, general rules/recommendations: general, wider, deeper neural networks can improve generalization - double-edged sword also increases risk overfitting. , increase width depth network, also add regularization (e.g., increasing lambda parameter, corresponds regularization strength). Furthermore, Pichler & Hartig, 2023, investigated effects hyperparameters prediction performance function data size. example, found selu activation function outperforms relu small data sizes (<100 observations). recommend starting moderate sizes (like defaults), model generalize/converge, try larger networks along regularization helps minimize risk overfitting (see vignette(\"B-Training_neural_networks\") ).","code":""},{"path":"/reference/cnn.html","id":"overfitting","dir":"Reference","previous_headings":"","what":"Overfitting","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"Overfitting means model fits training data well, generalizes poorly new observations. can use validation argument detect overfitting. validation loss starts increase certain point, often means models starting overfit training data:  Solutions: Re-train epochs = point model started overfit Early stopping, stop training model starts overfit, can specified using early_stopping=… argument Use regularization (dropout elastic-net, see next section)","code":""},{"path":"/reference/cnn.html","id":"regularization","dir":"Reference","previous_headings":"","what":"Regularization","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"Elastic Net regularization combines strengths L1 (Lasso) L2 (Ridge) regularization. introduces penalty term encourages sparse weight values maintaining overall weight shrinkage. controlling sparsity learned model, Elastic Net regularization helps avoid overfitting allowing meaningful feature selection. advise using elastic net (e.g. lambda = 0.001 alpha = 0.2). Dropout regularization helps prevent overfitting randomly disabling portion neurons training. technique encourages network learn robust generalized representations, prevents individual neurons relying heavily specific input patterns. Dropout widely adopted simple yet effective regularization method deep learning. utilizing regularization methods neural network training cito package, can improve generalization performance enhance network's ability handle unseen data. techniques act valuable tools mitigating overfitting promoting robust reliable model performance.","code":""},{"path":"/reference/cnn.html","id":"custom-optimizer-and-learning-rate-schedulers","dir":"Reference","previous_headings":"","what":"Custom Optimizer and Learning Rate Schedulers","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"training network, flexibility customize optimizer settings learning rate scheduler optimize learning process. cito package, can initialize configurations using config_lr_scheduler config_optimizer functions. config_lr_scheduler allows define specific learning rate scheduler controls learning rate changes time training. beneficial scenarios want adaptively adjust learning rate improve convergence avoid getting stuck local optima. Similarly, config_optimizer function enables specify optimizer network. Different optimizers, stochastic gradient descent (SGD), Adam, RMSprop, offer various strategies updating network's weights biases training. Choosing right optimizer can significantly impact training process final performance neural network.","code":""},{"path":"/reference/cnn.html","id":"training-on-graphic-cards","dir":"Reference","previous_headings":"","what":"Training on graphic cards","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"NVIDIA CUDA-enabled device installed CUDA toolkit version 11.3 cuDNN 8.4, can take advantage GPU acceleration training neural networks. crucial specific versions installed, versions may compatible. detailed installation instructions information utilizing GPUs training, please refer mlverse: 'torch' documentation. Note: GPU training optional, package can still used training CPU even without CUDA cuDNN installations.","code":""},{"path":[]},{"path":"/reference/cnn.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"Armin Schenk, Maximilian Pichler","code":""},{"path":"/reference/cnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Train a Convolutional Neural Network (CNN) — cnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Example workflow in cito  device <- ifelse(torch::cuda_is_available(), \"cuda\", \"cpu\")  ## Data ### We generate our own data: ### 320 images (3x50x50) of either rectangles or ellipsoids shapes <- cito:::simulate_shapes(n=320, size=50, channels=3) X <- shapes$data Y <- shapes$labels  ## Architecture ### Declare the architecture of the CNN ### Note that the output layer is added automatically by cnn() architecture <- create_architecture(conv(5), maxPool(), conv(5), maxPool(), linear(10))  ## Build and train network ### softmax is used for classification cnn.fit <- cnn(X, Y, architecture, loss = \"softmax\", epochs = 50, validation = 0.1, lr = 0.05, device=device)  ## The training loss is below the baseline loss but at the end of the ## training the loss was still decreasing, so continue training for another 50 ## epochs cnn.fit <- continue_training(cnn.fit, epochs = 50)  # Structure of Neural Network print(cnn.fit)  # Plot Neural Network plot(cnn.fit)  ## Convergence can be tested via the analyze_training function analyze_training(cnn.fit)  ## Transfer learning ### With the transfer() function we can use predefined architectures with pretrained weights transfer_architecture <- create_architecture(transfer(\"resnet18\")) resnet <- cnn(X, Y, transfer_architecture, loss = \"softmax\",               epochs = 10, validation = 0.1, lr = 0.05, device=device) print(resnet) plot(resnet) } #> Error in match.arg(tolower(optimizer), choices = c(\"sgd\", \"adam\", \"adadelta\",     \"adagrad\", \"rmsprop\", \"rprop\", \"ignite_adam\")): 'arg' must be of length 1 # }"},{"path":"/reference/coef.citocnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve parameters of a fitted CNN model — coef.citocnn","title":"Retrieve parameters of a fitted CNN model — coef.citocnn","text":"function returns list parameters (weights biases) buffers (e.g. running mean variance batch normalization layers) currently use neural network model created using cnn function.","code":""},{"path":"/reference/coef.citocnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve parameters of a fitted CNN model — coef.citocnn","text":"","code":"# S3 method for class 'citocnn' coef(object, ...)"},{"path":"/reference/coef.citocnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve parameters of a fitted CNN model — coef.citocnn","text":"object model created cnn. ... Additional arguments (currently used).","code":""},{"path":"/reference/coef.citocnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve parameters of a fitted CNN model — coef.citocnn","text":"list two components: parameters: list model's weights biases currently used model epoch. buffers: list buffers (e.g., running statistics) currently used model epoch.","code":""},{"path":"/reference/coef.citocnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve parameters of a fitted CNN model — coef.citocnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  device <- ifelse(torch::cuda_is_available(), \"cuda\", \"cpu\")  set.seed(222)  ## Data shapes <- cito:::simulate_shapes(320, 28) X <- shapes$data Y <- shapes$labels  ## Architecture architecture <- create_architecture(conv(5), maxPool(), conv(5), maxPool(), linear(10))  ## Build and train network cnn.fit <- cnn(X, Y, architecture, loss = \"softmax\", epochs = 50, validation = 0.1, lr = 0.05, device=device)  # Weights of neural network coef(cnn.fit) } #> Error in match.arg(tolower(optimizer), choices = c(\"sgd\", \"adam\", \"adadelta\",     \"adagrad\", \"rmsprop\", \"rprop\", \"ignite_adam\")): 'arg' must be of length 1 # }"},{"path":"/reference/coef.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns list of parameters the neural network model currently has in use — coef.citodnn","title":"Returns list of parameters the neural network model currently has in use — coef.citodnn","text":"Returns list parameters neural network model currently use","code":""},{"path":"/reference/coef.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns list of parameters the neural network model currently has in use — coef.citodnn","text":"","code":"# S3 method for class 'citodnn' coef(object, ...)  # S3 method for class 'citodnnBootstrap' coef(object, ...)"},{"path":"/reference/coef.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns list of parameters the neural network model currently has in use — coef.citodnn","text":"object model created dnn ... nothing implemented yet","code":""},{"path":"/reference/coef.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns list of parameters the neural network model currently has in use — coef.citodnn","text":"list weights neural network","code":""},{"path":"/reference/coef.citodnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns list of parameters the neural network model currently has in use — coef.citodnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222) validation_set<- sample(c(1:nrow(datasets::iris)),25)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,])  # Sturcture of Neural Network print(nn.fit)  #analyze weights of Neural Network coef(nn.fit) } #> Loss at epoch 1: 3.963883, lr: 0.01000  #> Loss at epoch 2: 0.197250, lr: 0.01000 #> Loss at epoch 3: 0.459870, lr: 0.01000 #> Loss at epoch 4: 0.447857, lr: 0.01000 #> Loss at epoch 5: 0.227505, lr: 0.01000 #> Loss at epoch 6: 0.288097, lr: 0.01000 #> Loss at epoch 7: 0.199268, lr: 0.01000 #> Loss at epoch 8: 0.284061, lr: 0.01000 #> Loss at epoch 9: 0.436366, lr: 0.01000 #> Loss at epoch 10: 0.165460, lr: 0.01000 #> Loss at epoch 11: 0.184338, lr: 0.01000 #> Loss at epoch 12: 0.136724, lr: 0.01000 #> Loss at epoch 13: 0.149914, lr: 0.01000 #> Loss at epoch 14: 0.152093, lr: 0.01000 #> Loss at epoch 15: 0.170458, lr: 0.01000 #> Loss at epoch 16: 0.176203, lr: 0.01000 #> Loss at epoch 17: 0.189944, lr: 0.01000 #> Loss at epoch 18: 0.161092, lr: 0.01000 #> Loss at epoch 19: 0.148210, lr: 0.01000 #> Loss at epoch 20: 0.164488, lr: 0.01000 #> Loss at epoch 21: 0.162436, lr: 0.01000 #> Loss at epoch 22: 0.163305, lr: 0.01000 #> Loss at epoch 23: 0.172168, lr: 0.01000 #> Loss at epoch 24: 0.243252, lr: 0.01000 #> Loss at epoch 25: 0.132562, lr: 0.01000 #> Loss at epoch 26: 0.546875, lr: 0.01000 #> Loss at epoch 27: 0.177578, lr: 0.01000 #> Loss at epoch 28: 0.192777, lr: 0.01000 #> Loss at epoch 29: 0.183818, lr: 0.01000 #> Loss at epoch 30: 0.154352, lr: 0.01000 #> Loss at epoch 31: 0.186305, lr: 0.01000 #> Loss at epoch 32: 0.135644, lr: 0.01000 #> Loss at epoch 33: 0.139553, lr: 0.01000 #> Loss at epoch 34: 0.160403, lr: 0.01000 #> Loss at epoch 35: 0.154453, lr: 0.01000 #> Loss at epoch 36: 0.169457, lr: 0.01000 #> Loss at epoch 37: 0.123535, lr: 0.01000 #> Loss at epoch 38: 0.180764, lr: 0.01000 #> Loss at epoch 39: 0.238997, lr: 0.01000 #> Loss at epoch 40: 0.174004, lr: 0.01000 #> Loss at epoch 41: 0.155138, lr: 0.01000 #> Loss at epoch 42: 0.173104, lr: 0.01000 #> Loss at epoch 43: 0.166610, lr: 0.01000 #> Loss at epoch 44: 0.166952, lr: 0.01000 #> Loss at epoch 45: 0.125737, lr: 0.01000 #> Loss at epoch 46: 0.132701, lr: 0.01000 #> Loss at epoch 47: 0.130678, lr: 0.01000 #> Loss at epoch 48: 0.428728, lr: 0.01000 #> Loss at epoch 49: 0.200900, lr: 0.01000 #> Loss at epoch 50: 0.109238, lr: 0.01000 #> Loss at epoch 51: 0.181168, lr: 0.01000 #> Loss at epoch 52: 0.157806, lr: 0.01000 #> Loss at epoch 53: 0.127271, lr: 0.01000 #> Loss at epoch 54: 0.214960, lr: 0.01000 #> Loss at epoch 55: 0.218292, lr: 0.01000 #> Loss at epoch 56: 0.485201, lr: 0.01000 #> Loss at epoch 57: 0.197565, lr: 0.01000 #> Loss at epoch 58: 0.162187, lr: 0.01000 #> Loss at epoch 59: 0.163314, lr: 0.01000 #> Loss at epoch 60: 0.127961, lr: 0.01000 #> Loss at epoch 61: 0.136617, lr: 0.01000 #> Loss at epoch 62: 0.133512, lr: 0.01000 #> Loss at epoch 63: 0.123569, lr: 0.01000 #> Loss at epoch 64: 0.148302, lr: 0.01000 #> Loss at epoch 65: 0.186050, lr: 0.01000 #> Loss at epoch 66: 0.146952, lr: 0.01000 #> Loss at epoch 67: 0.232022, lr: 0.01000 #> Loss at epoch 68: 0.100675, lr: 0.01000 #> Loss at epoch 69: 0.118698, lr: 0.01000 #> Loss at epoch 70: 0.120607, lr: 0.01000 #> Loss at epoch 71: 0.115503, lr: 0.01000 #> Loss at epoch 72: 0.143236, lr: 0.01000 #> Loss at epoch 73: 0.184907, lr: 0.01000 #> Loss at epoch 74: 0.109125, lr: 0.01000 #> Loss at epoch 75: 0.166606, lr: 0.01000 #> Loss at epoch 76: 0.123347, lr: 0.01000 #> Loss at epoch 77: 0.133271, lr: 0.01000 #> Loss at epoch 78: 0.338105, lr: 0.01000 #> Loss at epoch 79: 0.126170, lr: 0.01000 #> Loss at epoch 80: 0.131164, lr: 0.01000 #> Loss at epoch 81: 0.109315, lr: 0.01000 #> Loss at epoch 82: 0.113243, lr: 0.01000 #> Loss at epoch 83: 0.106264, lr: 0.01000 #> Loss at epoch 84: 0.129860, lr: 0.01000 #> Loss at epoch 85: 0.164180, lr: 0.01000 #> Loss at epoch 86: 0.111806, lr: 0.01000 #> Loss at epoch 87: 0.119878, lr: 0.01000 #> Loss at epoch 88: 0.139591, lr: 0.01000 #> Loss at epoch 89: 0.167658, lr: 0.01000 #> Loss at epoch 90: 0.371242, lr: 0.01000 #> Loss at epoch 91: 0.119417, lr: 0.01000 #> Loss at epoch 92: 0.211999, lr: 0.01000 #> Loss at epoch 93: 0.143504, lr: 0.01000 #> Loss at epoch 94: 0.167160, lr: 0.01000 #> Loss at epoch 95: 0.119966, lr: 0.01000 #> Loss at epoch 96: 0.113907, lr: 0.01000 #> Loss at epoch 97: 0.106057, lr: 0.01000 #> Loss at epoch 98: 0.119183, lr: 0.01000 #> Loss at epoch 99: 0.136681, lr: 0.01000 #> Loss at epoch 100: 0.147255, lr: 0.01000 #> dnn(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>     Species, data = datasets::iris[-validation_set, ]) #> An `nn_module` containing 2,901 parameters. #>  #> ── Modules ───────────────────────────────────────────────────────────────────── #> • 0: <nn_linear> #300 parameters #> • 1: <nn_selu> #0 parameters #> • 2: <nn_linear> #2,550 parameters #> • 3: <nn_selu> #0 parameters #> • 4: <nn_linear> #51 parameters #> [[1]] #> [[1]]$`0.weight` #>              [,1]        [,2]        [,3]        [,4]         [,5] #>  [1,]  0.02821273 -0.09766949 -0.18092735 -0.16975424 -0.182883278 #>  [2,]  0.37313789 -0.13063067  0.39677888  0.28128833 -0.307786852 #>  [3,]  0.43793079 -0.34236246  0.22320664  0.31025037 -0.043630816 #>  [4,]  0.05187014  0.14575090  0.28722295 -0.09104547 -0.299744099 #>  [5,]  0.37792626 -0.42140001  0.25444928  0.42741799 -0.134229958 #>  [6,] -0.35820341 -0.15572813  0.28246099  0.36435416  0.225304693 #>  [7,] -0.15930237 -0.18968064 -0.02983307 -0.29471001 -0.075564772 #>  [8,]  0.31538749  0.01958823 -0.12604739  0.15481624 -0.215723127 #>  [9,]  0.21171120 -0.26223636  0.17779307 -0.24811579 -0.076381318 #> [10,] -0.46241704  0.41887394  0.08752935 -0.26120150 -0.033559483 #> [11,] -0.21838488  0.11346281  0.33939558 -0.48017457  0.252175093 #> [12,]  0.43281373 -0.28118572 -0.42213181 -0.39477968 -0.118005946 #> [13,]  0.35252213 -0.06183217  0.33048895  0.04437319  0.244049743 #> [14,] -0.19759338 -0.20107803 -0.01464501 -0.10642845  0.421356171 #> [15,]  0.35548428  0.14817888 -0.12889412  0.41314980 -0.418882430 #> [16,] -0.23171426  0.27242166  0.11153195  0.31793207 -0.196398839 #> [17,]  0.05779293 -0.40961394 -0.22896557  0.14640327  0.393668264 #> [18,] -0.35597372 -0.17374350 -0.05497670 -0.11382874 -0.031735212 #> [19,]  0.43458617 -0.41503140 -0.28006837 -0.25688446 -0.059484746 #> [20,]  0.21407954 -0.20572042 -0.06008218 -0.03579978  0.216779426 #> [21,] -0.34120694  0.22656414 -0.18509074  0.35476208  0.375307888 #> [22,] -0.25031376  0.02786072 -0.08784506  0.42584372 -0.279356867 #> [23,]  0.04777586  0.21871713 -0.33908978  0.34386316 -0.220124289 #> [24,]  0.32653886 -0.06536060  0.24916871 -0.21062654 -0.328725845 #> [25,]  0.21486276 -0.31385505  0.10362542 -0.10929099 -0.242466286 #> [26,] -0.16288579 -0.39937598  0.01367304  0.29221147 -0.007761690 #> [27,]  0.39472455  0.38031024 -0.45995873  0.17657198 -0.109251395 #> [28,]  0.03763746 -0.40192339 -0.04377523  0.31690744 -0.077890910 #> [29,]  0.40970960 -0.36973840  0.26598755 -0.20255619 -0.213196427 #> [30,]  0.14219846 -0.07869642 -0.31284007 -0.42451233 -0.426880121 #> [31,] -0.19034685  0.13875313 -0.35645288 -0.39260343 -0.022118686 #> [32,]  0.39679229  0.04054641  0.29256237  0.12018039 -0.433970034 #> [33,]  0.18603049 -0.08427213 -0.23558570  0.25355381  0.310212433 #> [34,] -0.06631813 -0.20410290  0.01255431  0.16328990  0.012939663 #> [35,] -0.16351330  0.46739274  0.14078847  0.26340720  0.005314776 #> [36,]  0.17292726 -0.34507740  0.18852964  0.32286778 -0.011320028 #> [37,]  0.37217972  0.20029776  0.19840232 -0.18074988 -0.332367837 #> [38,] -0.38935658  0.37908778  0.04986158  0.15883133 -0.023041334 #> [39,] -0.24076077 -0.23893179 -0.01143725  0.07539030  0.042848743 #> [40,] -0.16771434 -0.16533716  0.45758235 -0.01876530 -0.281043321 #> [41,]  0.28487009 -0.30914477 -0.09393574  0.35810360  0.165068418 #> [42,] -0.41848531 -0.26654705  0.02237551  0.18209012 -0.190860853 #> [43,] -0.21239823  0.28370216 -0.34566891 -0.12751961  0.405156136 #> [44,]  0.22382830 -0.13100196 -0.02597948  0.17224690  0.091673635 #> [45,] -0.37234369 -0.20682049 -0.15571143  0.16767333  0.166776285 #> [46,] -0.27995640  0.33634573  0.10571044  0.24524325  0.019683564 #> [47,] -0.31265882 -0.10308161  0.26875937 -0.06155857 -0.339562863 #> [48,]  0.32080781 -0.38314244 -0.12843286 -0.10323165 -0.361847341 #> [49,]  0.12435094 -0.17283638  0.20452324 -0.20481674  0.228396922 #> [50,] -0.37998086  0.28467950  0.17901945  0.39703736 -0.274136305 #>  #> [[1]]$`0.bias` #>  [1]  0.00533016 -0.04988042 -0.15664671 -0.40173471  0.16407894 -0.04813331 #>  [7]  0.20250152  0.12942359  0.45438674 -0.14621304 -0.15354773 -0.22091813 #> [13] -0.08555809 -0.39929894  0.06971673  0.11664741 -0.31424704  0.43142998 #> [19] -0.14761274  0.40141696 -0.37807572  0.45529148  0.11176103 -0.07286517 #> [25] -0.29819652 -0.25869185  0.25182316 -0.42433017  0.24716289  0.15217760 #> [31]  0.38840964 -0.14837587  0.30273479 -0.38722882  0.06073029 -0.40318498 #> [37]  0.01257920  0.20429751 -0.21000467 -0.24431512  0.03180568  0.32501608 #> [43] -0.21340828 -0.22080919 -0.14068913  0.10158154  0.34027934 -0.07823776 #> [49] -0.04442006  0.06574810 #>  #> [[1]]$`2.weight` #>               [,1]         [,2]        [,3]         [,4]         [,5] #>  [1,]  0.068759434 -0.055653643  0.13127215 -0.083736919  0.081155494 #>  [2,]  0.015103221  0.025418211 -0.13239279  0.037507124  0.011691527 #>  [3,]  0.070879713 -0.017114697  0.13011163 -0.036259659  0.036915105 #>  [4,]  0.118228935  0.102634855 -0.06205759  0.082665659  0.006084518 #>  [5,] -0.120021895 -0.109604225 -0.09719285  0.105247535 -0.072678328 #>  [6,] -0.027615067  0.009865536 -0.02063719  0.042281445 -0.037398629 #>  [7,] -0.068307266 -0.018465882 -0.09704722  0.054336824 -0.164903045 #>  [8,]  0.002241752  0.075210914 -0.09475365 -0.143447071  0.123330809 #>  [9,]  0.040631376  0.064511575  0.11313005  0.004213009  0.025647914 #> [10,]  0.102888554 -0.121923931  0.01540508 -0.082706340  0.033630870 #> [11,] -0.083107628  0.123043410  0.05627503 -0.065909788  0.077314526 #> [12,]  0.069494560  0.129618570  0.07843996  0.053359460  0.081523433 #> [13,] -0.036201034  0.054104719 -0.04576296 -0.126973271 -0.064489722 #> [14,]  0.019219423  0.097511746  0.06509304 -0.071345292 -0.132923290 #> [15,]  0.062807560  0.123122543  0.01339193 -0.094688639 -0.132937312 #> [16,] -0.095881894  0.102968268 -0.03528845  0.050385453 -0.043144099 #> [17,]  0.044603802 -0.147493005 -0.04678638  0.140040308  0.086172715 #> [18,] -0.012735629  0.102520466  0.09284625  0.083390377 -0.060267340 #> [19,]  0.038639635  0.092046157 -0.11156211 -0.070931681  0.126052186 #> [20,]  0.096848831  0.119083919  0.05098573 -0.045692187 -0.084979393 #> [21,]  0.060227219  0.107925043  0.02304938 -0.119177960 -0.129513577 #> [22,]  0.006832776 -0.112202935  0.08775509  0.071952567  0.011964925 #> [23,]  0.073001944 -0.102476776 -0.07100038  0.086221971  0.086612120 #> [24,]  0.084986247  0.135008618 -0.12746805 -0.111974999 -0.093559861 #> [25,] -0.072600208 -0.081502855  0.01200140 -0.147877440  0.044789419 #> [26,]  0.137817830 -0.052802347 -0.10429634 -0.128663361 -0.047348976 #> [27,] -0.089484259 -0.040094990 -0.01512314 -0.117939889  0.111480385 #> [28,]  0.004594359 -0.093691729 -0.11971149  0.088319540 -0.097498015 #> [29,]  0.007375658  0.065713458 -0.09527375  0.105675511  0.059253231 #> [30,] -0.005761524 -0.047747176  0.13387851 -0.051837984 -0.023263182 #> [31,] -0.078709736 -0.084689789  0.02642665 -0.081502303 -0.075606547 #> [32,]  0.046943743  0.017592939  0.06205098 -0.031630576  0.008600088 #> [33,]  0.014162659  0.053233705  0.13659391  0.064382717  0.073870517 #> [34,]  0.031283144 -0.014638286  0.12748502 -0.016484693  0.109531365 #> [35,]  0.117912851 -0.019298811 -0.14973250 -0.052946221 -0.064675160 #> [36,]  0.083943434  0.036486484  0.04842848 -0.115521230 -0.088519394 #> [37,]  0.100873992 -0.082354352  0.06684704 -0.088490047 -0.066592515 #> [38,] -0.137833208 -0.109085463 -0.06853301 -0.042536546  0.030451978 #> [39,]  0.041371919  0.106306612 -0.06917422  0.095649876 -0.034698017 #> [40,]  0.101291195  0.095451429 -0.13716528  0.087978221 -0.106612824 #> [41,]  0.012910417 -0.138703123 -0.09065744  0.011411448 -0.024953101 #> [42,] -0.131085277 -0.052961197  0.04614984 -0.043076716  0.090767182 #> [43,] -0.009334031  0.012469309  0.04004399  0.042780548 -0.070633695 #> [44,] -0.087452613  0.057754558 -0.12888405 -0.115460873 -0.088467188 #> [45,]  0.076641925 -0.023814457  0.06379900 -0.052856069  0.064885050 #> [46,] -0.006548622  0.011495606 -0.07657813  0.148551941  0.111246631 #> [47,] -0.124990016 -0.052416071  0.08033766 -0.147432908  0.119693823 #> [48,]  0.067064963  0.047535595  0.04083582  0.108685628 -0.096882194 #> [49,] -0.006552578 -0.020336557 -0.03285928  0.093765683 -0.021844672 #> [50,]  0.064743504 -0.128411829  0.05414264  0.010670396 -0.075430103 #>               [,6]         [,7]         [,8]         [,9]        [,10] #>  [1,]  0.090951048  0.099378422 -0.077938415 -0.026519278  0.069202319 #>  [2,]  0.039511569 -0.017101631 -0.105978407  0.042948801  0.004838264 #>  [3,] -0.067756958 -0.044616267 -0.141450748  0.047300603  0.032749828 #>  [4,] -0.076878048 -0.084882952  0.039473310  0.067886777 -0.031170163 #>  [5,] -0.020320393  0.112704381  0.113188006 -0.112555444  0.054632094 #>  [6,] -0.116094008 -0.032760821  0.120439693 -0.139319509  0.070780404 #>  [7,] -0.040343169 -0.018021766  0.060547657 -0.146771774  0.118655428 #>  [8,] -0.068794861  0.023936221  0.053614862  0.088697113  0.046680279 #>  [9,] -0.139021918  0.008183935  0.134090170  0.125044331  0.114336513 #> [10,] -0.065643050 -0.141380906 -0.102956377  0.132279813  0.068944953 #> [11,]  0.029308561 -0.019430103 -0.120896831  0.013249804  0.010687857 #> [12,] -0.072478317 -0.107569665  0.045987833  0.117879786 -0.115007482 #> [13,]  0.084554583  0.047769114 -0.080229528 -0.026405796 -0.049363818 #> [14,] -0.120645076  0.065432914  0.140806600 -0.073865980 -0.125562936 #> [15,]  0.041800436  0.105216078 -0.075418249 -0.061062936  0.133372337 #> [16,] -0.123603545  0.040009961 -0.087628998  0.113461912 -0.081279755 #> [17,] -0.087426640 -0.128962487  0.133491457 -0.131037399 -0.014415073 #> [18,]  0.084688127  0.131093487  0.071599960  0.022551939  0.098308988 #> [19,] -0.135941029  0.059771590 -0.070277788  0.022834875 -0.012911819 #> [20,]  0.012453954 -0.062261023  0.006600829  0.024609674  0.043615110 #> [21,] -0.053622410 -0.065430574 -0.013486738  0.069948412  0.038314961 #> [22,] -0.036585011  0.071867429 -0.012634493  0.136808425  0.088487089 #> [23,]  0.054373581 -0.038594577 -0.112994820  0.121435203  0.110072069 #> [24,] -0.036300592  0.061875422 -0.026401961  0.066365436 -0.120361455 #> [25,]  0.017842773 -0.091620676 -0.077412307  0.143710583 -0.036434509 #> [26,]  0.154872671  0.102746941 -0.103568405 -0.126807064  0.022322150 #> [27,]  0.123995051  0.146534726  0.081021085 -0.076169424  0.005322657 #> [28,] -0.106449649  0.067998856 -0.029912641 -0.120729662 -0.081782043 #> [29,] -0.098454848  0.105675377  0.059420217  0.129364654 -0.005284840 #> [30,]  0.027621202 -0.119625539  0.108334772 -0.084118649 -0.039549559 #> [31,] -0.112938613  0.125775382  0.098324724  0.006804349  0.178220183 #> [32,] -0.126174733 -0.089498624  0.044190791  0.065699995 -0.112705089 #> [33,] -0.065900706 -0.097349674  0.110043101 -0.103239618  0.040434029 #> [34,] -0.075904071 -0.077017561 -0.075880386 -0.064740844 -0.093576171 #> [35,] -0.046065688 -0.021949874 -0.070707068 -0.137084350 -0.082988322 #> [36,]  0.045814142 -0.131318435 -0.024888610  0.112490155 -0.126079649 #> [37,] -0.072154492  0.066906467 -0.099195525  0.028269904  0.060576573 #> [38,] -0.092879429 -0.043200761 -0.034818035 -0.099907719  0.129056737 #> [39,] -0.083555683 -0.016617997 -0.014417388  0.124724247  0.125968143 #> [40,] -0.077530473 -0.127919242 -0.130156040 -0.049238961  0.074689493 #> [41,] -0.069073632  0.104026303  0.071950100  0.120579228  0.108396828 #> [42,]  0.135779575 -0.141746312  0.060779050  0.067782901 -0.033744358 #> [43,]  0.080813631 -0.150592878  0.102250628 -0.009122408  0.002728733 #> [44,] -0.054698247  0.120174460  0.150649384 -0.040346097  0.036719766 #> [45,]  0.006802146  0.110747091  0.124973021  0.125947371  0.090006404 #> [46,]  0.089337885  0.068212725  0.048462294 -0.107296199 -0.065945767 #> [47,] -0.054617096 -0.079761468  0.034512911 -0.104678251  0.010731074 #> [48,]  0.112117581  0.083100192  0.037675966 -0.131747797 -0.091930084 #> [49,] -0.031247033 -0.069815807 -0.012720966  0.071511053 -0.056774735 #> [50,]  0.037507668 -0.121904403  0.121022850  0.079416834 -0.122559398 #>               [,11]        [,12]        [,13]        [,14]        [,15] #>  [1,]  0.0059945961 -0.141903564  0.024012178  0.061100166  0.060573325 #>  [2,]  0.1078277454  0.027956819  0.110487022 -0.019409273 -0.073306568 #>  [3,] -0.1083637178 -0.038568303 -0.062464297  0.135589987  0.074443527 #>  [4,] -0.0944627300  0.123593591 -0.003405301  0.044821732 -0.021542126 #>  [5,] -0.0989809036  0.032199677  0.029973730  0.009259977 -0.094728507 #>  [6,] -0.0007449014  0.089228190  0.157622203  0.079918347 -0.024139708 #>  [7,]  0.0666992739  0.033823106 -0.108695760 -0.105975524  0.122049242 #>  [8,]  0.1326883584  0.075756907  0.047064893 -0.041108508  0.012971370 #>  [9,]  0.1302397251  0.142499194  0.097992569 -0.065841906 -0.040786922 #> [10,]  0.0563862994  0.094523460 -0.107041471 -0.085402675  0.150557414 #> [11,] -0.1310421824 -0.082536548  0.083463565  0.104996122 -0.011900973 #> [12,]  0.0570066758 -0.000550641 -0.068150729 -0.011445903  0.023289710 #> [13,] -0.0208771527 -0.041719113  0.140581399  0.029771846  0.050045993 #> [14,] -0.0334681645 -0.090099908 -0.104596674 -0.123482108 -0.034823235 #> [15,]  0.0626730546 -0.103013322 -0.109782726  0.080091514 -0.059517290 #> [16,] -0.0471131839 -0.055735052  0.100678906 -0.062781774  0.017386826 #> [17,]  0.1016594842  0.010347592 -0.046385113  0.132022142  0.118122861 #> [18,] -0.0943164155 -0.101747528 -0.084980398 -0.068524428 -0.104202256 #> [19,] -0.0146751283  0.072229363  0.010317530  0.022800755  0.120512508 #> [20,] -0.0843548775  0.016302148 -0.001901701  0.032321427 -0.065568097 #> [21,]  0.1366385520  0.003647164 -0.001345553  0.083725467 -0.053769253 #> [22,] -0.0217561722 -0.098765589  0.047473237  0.007093970 -0.035072859 #> [23,] -0.1145025268 -0.026944079 -0.048657455 -0.138296261  0.065718435 #> [24,] -0.1356333196  0.047891270  0.143169597 -0.053309105 -0.023744842 #> [25,]  0.0653917342 -0.045916561 -0.079983301  0.066314206 -0.138054058 #> [26,] -0.0931894928 -0.053616229 -0.122766078  0.043746788 -0.047987845 #> [27,] -0.0164107755  0.096892595  0.043007944  0.047650069  0.064111754 #> [28,]  0.0363456793 -0.071937256  0.004790144  0.039790291 -0.108842537 #> [29,] -0.0633541942  0.071094535 -0.051242292 -0.077095568 -0.027909137 #> [30,]  0.1343730986  0.095663533 -0.047914360  0.049632769 -0.153118387 #> [31,]  0.1156587228  0.006676617  0.042236306 -0.145681232 -0.116146177 #> [32,] -0.0216278080 -0.057599049  0.098440796  0.009827133  0.146250844 #> [33,] -0.1172342971  0.042445041 -0.065153211 -0.035459731  0.029693441 #> [34,]  0.1055058241 -0.085340202  0.032057762 -0.016911929 -0.027810123 #> [35,]  0.0011281763  0.092709236  0.074141957 -0.154394731  0.081738017 #> [36,] -0.1222889498  0.030833295 -0.046923809 -0.103827022  0.129099339 #> [37,] -0.0907100588  0.038345441 -0.121127374  0.002844171 -0.058344826 #> [38,] -0.0791366324  0.114378810  0.007205241  0.009844759  0.085728787 #> [39,]  0.1064446345 -0.093771480 -0.074725479 -0.052528691 -0.042755619 #> [40,]  0.0538260080 -0.130174056 -0.071643144 -0.082799859  0.077954084 #> [41,]  0.1396699995 -0.005942751 -0.110828750  0.037100770 -0.113638707 #> [42,] -0.1086161062 -0.133961529 -0.066725142  0.056486949  0.115139566 #> [43,] -0.0913409144 -0.141121238  0.110583387 -0.117256723  0.015414543 #> [44,]  0.1132824495 -0.011747191  0.022119138  0.022020729  0.136276767 #> [45,]  0.1331149787  0.101392381  0.068835653 -0.136613145  0.083466984 #> [46,]  0.0567380488  0.041233718  0.085128397  0.101224564  0.135497034 #> [47,] -0.0690046847  0.103785902 -0.093117326 -0.039000854 -0.097356848 #> [48,]  0.0085934103 -0.035103884 -0.110269293  0.033790927  0.093133532 #> [49,]  0.0651579052  0.090798095  0.096697882  0.091795377  0.004588578 #> [50,]  0.0751488730  0.089454532  0.096401356 -0.002685400 -0.072660491 #>              [,16]        [,17]         [,18]        [,19]        [,20] #>  [1,] -0.122852713  0.031804990  0.1524937153  0.074904926 -0.099561743 #>  [2,]  0.001404232 -0.078127764 -0.0032436224  0.122400686  0.137198240 #>  [3,]  0.130419761  0.092567585 -0.1128355637 -0.034869421 -0.047344688 #>  [4,]  0.143154085  0.114597879 -0.0027069142  0.024869932 -0.006494372 #>  [5,]  0.074179389  0.096365891  0.1597245336  0.045334682 -0.097423755 #>  [6,] -0.040659696 -0.067340977 -0.0663306564 -0.027401149 -0.080487378 #>  [7,] -0.086518295 -0.095233209  0.0035193081  0.025499323  0.037784886 #>  [8,] -0.009746766 -0.033767395  0.0575100705 -0.146675602 -0.117594495 #>  [9,] -0.051835280  0.011669148 -0.0257936623 -0.076410905 -0.024123143 #> [10,] -0.102045283  0.004939172 -0.0445864946  0.096539691  0.107773408 #> [11,]  0.005289819  0.039907631 -0.0009705217  0.012587754  0.091469087 #> [12,]  0.081984729  0.082797401 -0.0903512016  0.070525169 -0.100818709 #> [13,]  0.092978492 -0.040767889 -0.1110868528  0.110773355 -0.026559006 #> [14,] -0.012576969 -0.003723549  0.0274280217 -0.103268176  0.032477140 #> [15,] -0.124418423 -0.064280294  0.0067288573 -0.039403431  0.051562082 #> [16,] -0.017791241  0.085774720 -0.0276563950 -0.026218195 -0.075024858 #> [17,] -0.078355551 -0.064103901  0.0705825463  0.138838619  0.064457051 #> [18,] -0.029039873  0.028031161  0.1027072966 -0.108233459  0.076175012 #> [19,]  0.062170323  0.022979883  0.1422405839 -0.103355460 -0.018812958 #> [20,]  0.127793476 -0.098771743 -0.1090437919 -0.071146145 -0.089728795 #> [21,] -0.007590264 -0.114704765  0.0506566279  0.002584781  0.032102764 #> [22,]  0.083719894 -0.068358555 -0.0756927282 -0.067319356 -0.114663042 #> [23,]  0.003300540  0.006500857 -0.1451042295  0.129399657  0.042682957 #> [24,]  0.105618805 -0.009413453 -0.0053432789 -0.148936644 -0.111780658 #> [25,]  0.032821529 -0.018497413  0.0088173738 -0.074933879  0.077202246 #> [26,]  0.117434576  0.043467660  0.0488761067 -0.048880730  0.030190282 #> [27,]  0.139798880  0.021517215  0.0942761078  0.040407933 -0.010128933 #> [28,]  0.002917594  0.125081465 -0.0917461440 -0.003617894 -0.081623212 #> [29,]  0.039927512 -0.118887477  0.0538244657 -0.128812671 -0.027905930 #> [30,] -0.062036131 -0.001845858  0.1049299389 -0.066980131  0.093929105 #> [31,]  0.109170377  0.057254095  0.0024364269 -0.023725068  0.084711447 #> [32,] -0.100050010 -0.129244700 -0.0147105306 -0.035887588 -0.063081130 #> [33,] -0.022652684 -0.030616593  0.0906210989 -0.053603180 -0.111869864 #> [34,] -0.005786609  0.086864427 -0.0015815772 -0.001795249  0.132252261 #> [35,] -0.026711496 -0.064439602 -0.0328089669  0.153401211 -0.144178286 #> [36,]  0.092265636  0.050051384 -0.0168058388 -0.096102148 -0.071505390 #> [37,] -0.021009771  0.104318134  0.0819685385 -0.134144634 -0.048746124 #> [38,] -0.030823410  0.021518350 -0.0807992145 -0.061807513  0.090968899 #> [39,]  0.105280459  0.080902264  0.0322234891 -0.014272035 -0.007166401 #> [40,] -0.095397979  0.078061618  0.0943254754  0.018924408 -0.070301048 #> [41,] -0.088062197 -0.072548695  0.0118727731  0.105544932  0.021095674 #> [42,] -0.002078721  0.004231561 -0.0302449483 -0.015020830  0.111013889 #> [43,]  0.003426603  0.090242788  0.1137839034 -0.001918016 -0.009818121 #> [44,]  0.050515506 -0.038562343  0.1225838810  0.152407527 -0.117724344 #> [45,]  0.016437959  0.063890636  0.0479912274  0.081709646 -0.042619709 #> [46,] -0.042885248  0.064371720  0.0873267353  0.002272284 -0.090937778 #> [47,] -0.127741382  0.006972344  0.0665225685  0.004793677 -0.083153993 #> [48,]  0.060222197 -0.150914595 -0.0583827756  0.140934676  0.098355427 #> [49,]  0.030201374  0.129705608  0.0025786785 -0.080594085 -0.010019292 #> [50,] -0.037309226  0.132071555  0.0250740293  0.034073200  0.137327135 #>              [,21]        [,22]        [,23]        [,24]        [,25] #>  [1,]  0.099135906  0.141942129 -0.015232882 -0.022261556 -0.057953201 #>  [2,] -0.071156181  0.038877022 -0.017470017  0.012821424 -0.064173602 #>  [3,] -0.039672028 -0.085065395 -0.070572414  0.130438164  0.008338650 #>  [4,]  0.079629339 -0.131023630  0.126498342  0.015148900  0.037876375 #>  [5,] -0.060007993 -0.049809076 -0.110414416 -0.155701786 -0.006427377 #>  [6,]  0.051456060 -0.104441062  0.133628085 -0.084962726  0.048276722 #>  [7,] -0.041283235 -0.081745572 -0.080511764 -0.009057125 -0.035692580 #>  [8,] -0.118229710  0.112136655 -0.121285871 -0.108802542  0.126266226 #>  [9,]  0.035640169 -0.009553835 -0.045779355 -0.009664916 -0.076216280 #> [10,] -0.038770657  0.002749808 -0.084802203  0.113370791  0.014464824 #> [11,]  0.056159433 -0.044147823  0.092545532 -0.068187557 -0.104058504 #> [12,] -0.019762479 -0.089007333  0.069706507 -0.121914968  0.097524792 #> [13,] -0.105174512  0.008609690  0.077638112  0.146296412  0.107887417 #> [14,]  0.063378960 -0.066254385  0.116934344  0.094843231 -0.046509303 #> [15,] -0.130664423 -0.117337719  0.009860865  0.114508681 -0.085877322 #> [16,]  0.133399099  0.124252699 -0.016256314  0.066867717 -0.107604094 #> [17,] -0.048388511  0.015258445 -0.044463798 -0.104722425 -0.094350465 #> [18,] -0.029945573  0.099254869  0.042359877  0.051626805  0.112924591 #> [19,] -0.071747690 -0.027329989 -0.042372700  0.071975559 -0.028030874 #> [20,]  0.036443152 -0.107532218 -0.103836901  0.095486112  0.012295685 #> [21,]  0.128378004 -0.050861601  0.075987041  0.036148019  0.115040906 #> [22,]  0.110340275 -0.001549855  0.051472902  0.132439032 -0.085911036 #> [23,]  0.036565844 -0.022889169 -0.034838218  0.070461102 -0.096357040 #> [24,]  0.009432677 -0.026564553  0.001180235 -0.129904062  0.071805634 #> [25,]  0.073596671 -0.086307667 -0.142905921  0.026560251 -0.080706775 #> [26,]  0.070910625 -0.090225041  0.058102053 -0.013007069  0.113939583 #> [27,] -0.008955827 -0.087340005  0.048845913 -0.107838966 -0.126903921 #> [28,] -0.128361657 -0.111816518  0.055421889 -0.125967860 -0.051188804 #> [29,] -0.086646184 -0.061753415 -0.066177279  0.021084059 -0.147347212 #> [30,]  0.110505566 -0.075228021 -0.030608917  0.022815546  0.026076606 #> [31,]  0.131679147 -0.147869766  0.093211696  0.039899372  0.058823213 #> [32,]  0.047090299  0.120715633  0.031384647 -0.028456904  0.006682916 #> [33,]  0.089352787 -0.112444602  0.037184134  0.062044177  0.055193510 #> [34,] -0.091159001 -0.059149437  0.105568163  0.065287881  0.133957654 #> [35,]  0.054056123 -0.144417375 -0.092635497 -0.032006547  0.136611581 #> [36,]  0.021147661  0.084366553  0.131483555 -0.142214417 -0.137098715 #> [37,] -0.123087116 -0.055882819  0.105631404  0.046223644 -0.013053422 #> [38,] -0.006977696  0.028711619 -0.068395339  0.058497671 -0.009837735 #> [39,] -0.040225580 -0.125904053  0.095669270  0.031622622 -0.129407212 #> [40,] -0.035916295  0.043518804 -0.102717392 -0.053536393  0.010370282 #> [41,] -0.012565280  0.034715954 -0.094833508 -0.108414985  0.047069784 #> [42,]  0.029884167  0.130463749 -0.098426610  0.088014796 -0.100969598 #> [43,]  0.031038733 -0.113503769  0.060537852  0.038394079 -0.092414036 #> [44,] -0.103598744 -0.041816063  0.135136470  0.027531503 -0.046532173 #> [45,]  0.080048658  0.023226310 -0.096045747 -0.088977061 -0.099025518 #> [46,]  0.135956332 -0.120122083  0.015385824  0.135459170 -0.056027748 #> [47,]  0.086742811 -0.049780499 -0.144732609 -0.135629520 -0.036687195 #> [48,] -0.012724394  0.069838300  0.063459508 -0.042513762 -0.128821075 #> [49,]  0.015237276  0.059945989  0.026978711 -0.010367204 -0.008877747 #> [50,] -0.067747779  0.106872678 -0.116226405 -0.108618468  0.120551899 #>              [,26]         [,27]        [,28]        [,29]        [,30] #>  [1,]  0.085735179 -0.1273957491 -0.122693285 -0.026005292 -0.074029930 #>  [2,] -0.084231839 -0.1058820114  0.002600911 -0.094430134 -0.122879945 #>  [3,] -0.112715669  0.0745895356  0.076955475  0.073645651  0.050824262 #>  [4,]  0.055520590  0.0969079882  0.072570316 -0.083298959 -0.122638896 #>  [5,] -0.014451557 -0.1301954687  0.104485393 -0.011373728 -0.097186841 #>  [6,] -0.087975070  0.0426594727 -0.100330070 -0.010169626  0.146564201 #>  [7,] -0.066526435 -0.0179689229 -0.116109960 -0.103094190  0.054786470 #>  [8,]  0.061000869  0.0554107465  0.137550503  0.111106344  0.071089819 #>  [9,]  0.035505734  0.0744461343  0.114738852  0.068769872  0.019699419 #> [10,] -0.014525063  0.0019518128  0.090523757  0.108753406  0.093868949 #> [11,]  0.108345933 -0.0550206862  0.055746276 -0.113413461  0.057664245 #> [12,]  0.050496083 -0.1001359895  0.093009800  0.116640754  0.103876449 #> [13,] -0.139984176  0.0689605922 -0.138611823 -0.115222000 -0.080629759 #> [14,]  0.085554406  0.1159004271  0.115462452 -0.037783608  0.125416026 #> [15,] -0.125333250 -0.0169885214  0.025883062 -0.075041831  0.003709604 #> [16,] -0.062018443 -0.0008176563 -0.012345795 -0.064908810 -0.050929721 #> [17,]  0.003529374  0.0840748399 -0.106177695 -0.150659710 -0.084027812 #> [18,]  0.145334512 -0.1485771984 -0.113727167  0.115440778  0.034040943 #> [19,] -0.071529634  0.0722202733 -0.096097022  0.056898955  0.019080127 #> [20,] -0.055782601 -0.1142284796  0.051963251  0.087357901 -0.039485201 #> [21,]  0.005480875  0.1442164928  0.028041653  0.076849766 -0.022184160 #> [22,]  0.020206099 -0.0992432535 -0.050080411  0.074024849  0.071546122 #> [23,] -0.135373771 -0.0660370141 -0.118687376  0.117105968 -0.116251931 #> [24,]  0.104586855  0.1151576862 -0.010946294 -0.064406060  0.032164838 #> [25,] -0.092664406 -0.0898153111 -0.051266331 -0.103442632 -0.129803121 #> [26,]  0.135257542 -0.1052879840 -0.074123070  0.102774985 -0.108928591 #> [27,]  0.034695383  0.0821848288  0.124750495  0.094188340  0.038857512 #> [28,]  0.072538927 -0.0255367663 -0.109772213 -0.006397027 -0.088290937 #> [29,]  0.104265273 -0.1411093771 -0.092560187 -0.120506547 -0.131378368 #> [30,]  0.056120198 -0.2027920336 -0.104164518 -0.033077572 -0.128470480 #> [31,]  0.045189351  0.1437864304 -0.002425706 -0.004300907 -0.002161167 #> [32,] -0.118799180 -0.0992590636  0.029212713 -0.025647571  0.015220115 #> [33,]  0.033514362  0.0703266114 -0.011682604 -0.099544354  0.078294620 #> [34,]  0.091168791 -0.0727845356 -0.121815950 -0.107827373 -0.001601558 #> [35,] -0.099778555 -0.0592558533 -0.020148972 -0.016525384 -0.080421500 #> [36,] -0.049400020 -0.1503769755 -0.082293309 -0.056144390 -0.105262563 #> [37,]  0.058589004  0.1281658709 -0.115690745  0.035187218  0.016825026 #> [38,] -0.130156249 -0.0107134003 -0.081074901 -0.098314293  0.127453744 #> [39,]  0.143691540  0.1240538582 -0.018762106 -0.047088403 -0.097626969 #> [40,]  0.097799279 -0.0439736322 -0.046146948  0.134857401 -0.040910199 #> [41,]  0.016436808 -0.0245162081 -0.070416830 -0.059488244 -0.064525507 #> [42,] -0.116753675 -0.0213743839  0.107183620  0.017004529  0.099238209 #> [43,]  0.057508025 -0.1165541336  0.051225498  0.033788498 -0.034928456 #> [44,] -0.110389575  0.0272850227  0.118252084 -0.119017817  0.040095635 #> [45,] -0.026428465 -0.0541369133 -0.123990625  0.099804245  0.038057663 #> [46,]  0.122764617  0.1294782311 -0.103666089  0.066747673  0.005982033 #> [47,]  0.105603874 -0.1486830264 -0.100312226  0.037585799  0.046380050 #> [48,] -0.053253826  0.0184361953  0.044104569  0.093740821  0.129444420 #> [49,] -0.039677434  0.0650875717 -0.065799244  0.063922897 -0.090164587 #> [50,]  0.048382357 -0.1038958728 -0.100735992 -0.046183407 -0.147571370 #>               [,31]        [,32]       [,33]         [,34]         [,35] #>  [1,]  0.0106779085  0.024475008  0.09699180  0.0110866297 -0.0848347992 #>  [2,]  0.0487198010  0.149434224 -0.07174749 -0.0287825037 -0.0032382540 #>  [3,] -0.0177143868 -0.010623307  0.07152755 -0.0184327718 -0.1193331704 #>  [4,] -0.0379295908 -0.068334840  0.12091201 -0.1182951257 -0.0540515520 #>  [5,]  0.1064844579 -0.011079120  0.07575870  0.1495233178 -0.1188545376 #>  [6,]  0.0983471274  0.055434190 -0.04030747 -0.0646886230 -0.0519870967 #>  [7,]  0.1298181266 -0.040257920  0.10574399  0.0510391816  0.1371484548 #>  [8,]  0.0350119174 -0.070945226 -0.08769661  0.0293517578 -0.0006509951 #>  [9,] -0.0726408288 -0.121357732  0.08646120  0.0793362930  0.1321047544 #> [10,] -0.0763415694  0.119215868 -0.12090161  0.0752205700 -0.0166009534 #> [11,]  0.1156965867 -0.009506037 -0.12415989  0.0001903050 -0.1447089165 #> [12,]  0.0775586143  0.149697706 -0.07166814  0.0244162232  0.0910253748 #> [13,]  0.1010272428  0.001167544 -0.05659541 -0.0348816998  0.1041972339 #> [14,]  0.0081017576  0.086158276 -0.06852555  0.0194286406  0.0214958321 #> [15,] -0.0160469580  0.107247718  0.04436842 -0.0709381327 -0.1116273180 #> [16,]  0.0676463842  0.093053155 -0.14693029 -0.0008000224 -0.0472133085 #> [17,]  0.0717724860 -0.015496683 -0.06382641 -0.0849403664 -0.0479673073 #> [18,]  0.0993545204 -0.122209139  0.08938139  0.0662220642  0.0389109701 #> [19,]  0.0293738134 -0.082108930  0.10806946  0.1000814065  0.0969628692 #> [20,] -0.1310534328  0.097682342 -0.10688554  0.0325732827 -0.0985158831 #> [21,] -0.0003320145  0.130392224  0.06345520  0.0094967121 -0.0381095111 #> [22,] -0.1091389656 -0.041318789 -0.05303389 -0.0223577358 -0.0961365625 #> [23,]  0.1428716332 -0.009135732  0.01885987 -0.1193005443  0.0384297669 #> [24,]  0.0883051082 -0.117821507  0.11252356  0.0673809350 -0.0609572530 #> [25,] -0.0718711242 -0.102462456  0.09719982  0.0833012760 -0.1355295628 #> [26,] -0.1001915783  0.025028411  0.03466081 -0.1099819839 -0.1036773846 #> [27,] -0.1127397716 -0.115565069 -0.14343289  0.1289543509 -0.0214469638 #> [28,]  0.1074470282 -0.008689602  0.06766119  0.0288375895  0.0705460981 #> [29,] -0.1164469346  0.011246148  0.06181634  0.0079874787 -0.0881858319 #> [30,] -0.1067572087  0.003242143  0.10466241  0.0719037801  0.0850128680 #> [31,] -0.0996040776  0.116838649  0.02559543 -0.0154204387 -0.0102977436 #> [32,]  0.1042537019  0.054398552 -0.03393151  0.0080623263 -0.0320658460 #> [33,] -0.0133142695 -0.095615260 -0.08686466  0.1227862984  0.1079156697 #> [34,]  0.1253893375  0.073438965  0.11763989 -0.1100978628  0.0855740979 #> [35,] -0.1318624318  0.132695854  0.08271397 -0.1555254310  0.1663098037 #> [36,]  0.1054882929 -0.104036167  0.04441472 -0.0222384874 -0.0329127274 #> [37,]  0.0268427804  0.056966282 -0.05248468 -0.0336911157 -0.0915516391 #> [38,]  0.0881533325 -0.008069911 -0.13228844  0.0033840996 -0.0260472577 #> [39,] -0.1179498732 -0.014558799 -0.06915918  0.1082832962  0.1355227828 #> [40,] -0.0135735925  0.060105223  0.01624768  0.0877586380  0.0841421112 #> [41,]  0.0432553552 -0.112936124  0.09888441  0.0382642895 -0.1250685006 #> [42,] -0.1160841584 -0.007786768 -0.08253849 -0.0077919499  0.0284137186 #> [43,] -0.0332385674  0.034075797 -0.01930752 -0.0737981200 -0.0883201659 #> [44,] -0.0114227049  0.015458468  0.03240534 -0.0102441711  0.0365411639 #> [45,]  0.0156916119  0.091288373 -0.05007744  0.0598449372  0.1404899210 #> [46,] -0.1274066865  0.023915308  0.02680273 -0.0962072164  0.0725392923 #> [47,] -0.0809433386 -0.074061878 -0.02203673 -0.0136149507 -0.0306977704 #> [48,]  0.0043211048 -0.021300510  0.05778455  0.1139517576  0.0637988672 #> [49,] -0.0057574273 -0.135175750 -0.14116506  0.0950994939 -0.0208524242 #> [50,] -0.1342798173 -0.142894670 -0.12481199  0.1101616248  0.0713964999 #>              [,36]         [,37]         [,38]        [,39]       [,40] #>  [1,] -0.041172631 -0.0547198430  0.0575384386 -0.098449387 -0.05806578 #>  [2,] -0.088393807 -0.0515719689 -0.1042624116 -0.031537347 -0.02383056 #>  [3,] -0.028230710  0.0395925678  0.0186076369  0.107329540 -0.08203968 #>  [4,] -0.077916712  0.1290581375 -0.1248873994 -0.014998086  0.11824017 #>  [5,]  0.071696855 -0.0487571023 -0.1194426343  0.144893259  0.02111492 #>  [6,]  0.044639152  0.1357884407  0.0585785024 -0.124576196  0.01658342 #>  [7,]  0.134475186  0.1278871000 -0.0006328419  0.057211548 -0.12499478 #>  [8,]  0.003847317 -0.0973734111 -0.0583374575 -0.047016989  0.01764959 #>  [9,]  0.016111050  0.1371005327  0.0671140403  0.123278193 -0.10425772 #> [10,] -0.102071382 -0.0365624167  0.1150172725 -0.025551215 -0.06945861 #> [11,]  0.006112823  0.0692780241  0.1349028647 -0.026771169  0.12384638 #> [12,]  0.098422885  0.1606004238  0.0877616629  0.103945658 -0.06513206 #> [13,]  0.026075562 -0.0727115646  0.0167083368 -0.005170587  0.06930169 #> [14,]  0.022619298  0.0143314097  0.0843280032  0.063093871  0.11629108 #> [15,]  0.116954178  0.0423428565 -0.1306157112  0.124039754 -0.13567367 #> [16,] -0.084920838  0.0924915373 -0.0073370989 -0.063710511 -0.07318708 #> [17,] -0.085835397  0.1384791136  0.1105471402  0.042329870 -0.13812572 #> [18,]  0.041823938 -0.1295802444 -0.1098553315 -0.093675621  0.07176834 #> [19,]  0.041154820 -0.0671224445 -0.0731560662  0.130682155  0.10717837 #> [20,]  0.123849839 -0.1078581512  0.1506527662  0.086055718 -0.11351684 #> [21,]  0.086227521  0.0974726081  0.1160667092  0.026136393  0.02844784 #> [22,] -0.036208101 -0.0996467397  0.0880257264  0.133298323  0.09397997 #> [23,]  0.081543624  0.1063572541  0.0169083960  0.100854456  0.12022367 #> [24,]  0.035125777 -0.1123572886  0.0680660307 -0.148124546  0.10095648 #> [25,]  0.117258765 -0.1146806926  0.0839971155  0.003121589  0.10774419 #> [26,]  0.099266902 -0.0884288624  0.0852161944  0.088233404 -0.07835868 #> [27,]  0.127038792 -0.1018833145 -0.0357913300  0.055550020  0.09315314 #> [28,]  0.044304464  0.0045999843  0.0316581801 -0.020325886 -0.07631103 #> [29,]  0.095934868 -0.1376862675 -0.0638888255 -0.038803112  0.06988897 #> [30,] -0.016714089 -0.1511448175  0.0522520281  0.121085100 -0.03711996 #> [31,]  0.001160616 -0.0051098606  0.0605112128 -0.134892240 -0.04966463 #> [32,] -0.047556028 -0.0786079764 -0.0586292297  0.095139064 -0.11150108 #> [33,]  0.012942952 -0.1343152523  0.1270583421 -0.061386000 -0.04123912 #> [34,] -0.013187192  0.1378284991  0.0053556026 -0.122853503 -0.08932425 #> [35,]  0.111891575  0.1585681140 -0.1027669758 -0.044346128 -0.04770175 #> [36,]  0.080016345  0.0507452339 -0.0980612785  0.036273357 -0.10822628 #> [37,] -0.116314173  0.0147425169  0.0131473830  0.067677170  0.02241044 #> [38,] -0.020972848 -0.0816880390 -0.0766549483  0.029822962 -0.07773350 #> [39,]  0.097963385 -0.1449795514  0.0416061990  0.057261679  0.02191812 #> [40,]  0.088600963  0.0653282776  0.0463929474 -0.113531314  0.09713919 #> [41,]  0.017004512 -0.0003296842  0.0287651662  0.140963987  0.06221011 #> [42,]  0.009212591 -0.0409058332  0.0038744786 -0.101313360  0.12176792 #> [43,]  0.068068594 -0.1165620983 -0.0996375531  0.017948451  0.10321824 #> [44,] -0.033694543 -0.0085163116 -0.0895669684 -0.128456488 -0.07441292 #> [45,]  0.125418678 -0.0072541866 -0.1173439920 -0.033417732  0.06552261 #> [46,] -0.017852223  0.1495918334  0.1330813468 -0.068470940  0.10460777 #> [47,] -0.072040386 -0.0325713642  0.0362028740  0.094823875  0.05754381 #> [48,]  0.010966767  0.0794581398  0.0301280301  0.112371199 -0.01689831 #> [49,]  0.018486243  0.0436255671  0.0910510644 -0.096812449  0.02436861 #> [50,]  0.101745397 -0.0459725000  0.0256153941 -0.099580161  0.14007112 #>             [,41]        [,42]        [,43]        [,44]         [,45] #>  [1,] -0.05260745  0.128276691  0.020030001  0.110681869  0.1453216523 #>  [2,]  0.02427641  0.112488940  0.067220122 -0.069944218  0.0917136148 #>  [3,] -0.10606741 -0.012488733 -0.028313220  0.009612573  0.1205242723 #>  [4,] -0.05122170 -0.071084671  0.123257242 -0.022467867 -0.0141215371 #>  [5,] -0.08962467 -0.101641983 -0.134931803 -0.072388321  0.0004853813 #>  [6,] -0.04414520 -0.025216939 -0.057992447 -0.089332148 -0.1309960335 #>  [7,]  0.12770653 -0.066036336 -0.090108402 -0.043150581 -0.0605517328 #>  [8,] -0.07737590  0.057610974 -0.014614968  0.082428046 -0.0242972355 #>  [9,]  0.07830426  0.029198056  0.013228453  0.040447868 -0.0702943355 #> [10,] -0.14457931 -0.071432009  0.132958308 -0.068980262 -0.0341689177 #> [11,] -0.07835276  0.001286724 -0.095030516  0.024052409  0.0889848098 #> [12,] -0.05789265 -0.137344912 -0.007504211 -0.111185901  0.1128635034 #> [13,] -0.01089239  0.128550947  0.003086356 -0.061059684  0.0725193620 #> [14,]  0.08010203  0.104728706 -0.067952231 -0.075572327  0.0656088740 #> [15,]  0.10923624  0.093256719 -0.006060059 -0.035711329  0.0896727890 #> [16,] -0.01120018  0.003997414  0.044406507 -0.016411394  0.1180815399 #> [17,] -0.09591020 -0.028705379  0.164902031  0.046895351  0.0294993278 #> [18,] -0.05567490  0.096930407 -0.010381357 -0.055948604 -0.1022565514 #> [19,]  0.13343923  0.032658018  0.101199552 -0.080526948 -0.1161182821 #> [20,] -0.08400440  0.055515625  0.096304163  0.055457901 -0.1469601989 #> [21,] -0.00710720 -0.155067325  0.128224745 -0.037122320  0.1054093912 #> [22,]  0.09499403  0.008562048  0.028980622 -0.061314188  0.0283356644 #> [23,] -0.12307228  0.078202821 -0.090679601  0.123724267 -0.0376583785 #> [24,] -0.04680118 -0.052798998  0.008094339  0.093427598 -0.0447971188 #> [25,]  0.02804015  0.075826615  0.123700075  0.015506223 -0.0960907266 #> [26,]  0.07035081 -0.043604657 -0.141687468 -0.069190845  0.1115838438 #> [27,]  0.10466002 -0.056812610  0.126253590  0.048242852  0.1300705671 #> [28,]  0.04051592  0.084079355 -0.116610222  0.056385078 -0.0339112766 #> [29,]  0.09520999  0.145866171  0.057205379 -0.053243566  0.1156123579 #> [30,]  0.12451631  0.130691782 -0.048827291 -0.012411234  0.0279339589 #> [31,]  0.08071060 -0.054748546  0.126441687 -0.060074240 -0.0290048793 #> [32,]  0.12908526  0.078606017  0.138223723 -0.076078750 -0.1107538119 #> [33,] -0.12401638  0.149236545 -0.054658677 -0.087893426 -0.0829779580 #> [34,] -0.07144479  0.134489268  0.068188943 -0.007650624  0.1251196563 #> [35,]  0.04704859  0.029950850 -0.005114792  0.077474214  0.0143991932 #> [36,]  0.05274035 -0.116128080 -0.063183397  0.102115348  0.1330512762 #> [37,] -0.09508681 -0.008660422 -0.004668995  0.047465105 -0.0316373929 #> [38,] -0.03232348 -0.081638716 -0.127102390 -0.113417014 -0.0629339144 #> [39,] -0.06236517 -0.027772423  0.147646189 -0.106859587 -0.0527716577 #> [40,]  0.01153466  0.071630329 -0.128683135 -0.081777304  0.0246438328 #> [41,] -0.01277521  0.059640981  0.040707365  0.023685850 -0.1088358611 #> [42,]  0.06984573  0.133701846  0.122353882 -0.085542910 -0.0006516274 #> [43,] -0.09213099  0.006450280  0.001430262 -0.049509142  0.0534866899 #> [44,]  0.02941865  0.093390986  0.152380839 -0.044017378 -0.0217056014 #> [45,] -0.12462183 -0.021784933 -0.047892697  0.001339103 -0.1341559440 #> [46,]  0.07621544 -0.032743149 -0.076039448 -0.024020314  0.0070238016 #> [47,]  0.13135064 -0.112438060  0.057864036  0.033948507  0.0585581064 #> [48,]  0.04085736  0.092914544 -0.049418349  0.014683452 -0.0873639658 #> [49,]  0.12361114 -0.065175891 -0.095782995  0.078717269  0.0022920519 #> [50,]  0.05323596  0.046727970  0.106257044  0.002605934  0.0654238760 #>              [,46]         [,47]        [,48]        [,49]         [,50] #>  [1,]  0.017125310  0.0006209364 -0.072409518 -0.015613370 -0.1320961416 #>  [2,] -0.059815392 -0.1271884292 -0.074876472 -0.133625224  0.1240178347 #>  [3,] -0.042083349  0.0453653485  0.087971248 -0.112984873  0.0363652036 #>  [4,]  0.040942237 -0.1195585579 -0.089918494  0.056627449 -0.0237246957 #>  [5,]  0.040562853 -0.1169025376  0.106682047  0.083191007  0.0819439292 #>  [6,] -0.007504613 -0.0471671969  0.043532055  0.119514205 -0.1092547551 #>  [7,]  0.082757860  0.0421532840  0.049986802 -0.136438519 -0.0894430727 #>  [8,]  0.087397277  0.1194051653 -0.141512230 -0.049238235 -0.0804629102 #>  [9,]  0.043511659 -0.0934548005  0.044513129  0.002305205 -0.1235322058 #> [10,] -0.081331141  0.0172439851  0.112866707 -0.087308079 -0.1198915541 #> [11,] -0.065504387  0.1465473771  0.011222612 -0.034383696 -0.0071304129 #> [12,]  0.066388831 -0.0447960123  0.038350202  0.086044326 -0.0750544220 #> [13,]  0.084940650  0.0107083730  0.068364486 -0.145840302  0.1158358082 #> [14,] -0.019313898  0.0337686799  0.106303528 -0.033014476 -0.0453482494 #> [15,] -0.014309187  0.0906390101  0.018335149 -0.053853035  0.0952335447 #> [16,] -0.057874750  0.0286304988  0.019245028  0.051061243  0.0713576600 #> [17,] -0.050763249  0.0503810309 -0.093825452 -0.081170298 -0.0030015230 #> [18,]  0.001323643  0.0726418421  0.040029932 -0.121948563  0.1309206635 #> [19,]  0.014528212  0.1199376062 -0.099829614  0.135784984  0.0840750113 #> [20,] -0.046474591  0.0244041383  0.126963869 -0.100330874  0.1401328593 #> [21,]  0.101244621 -0.0348910801  0.056760240 -0.101561800 -0.1069760621 #> [22,]  0.032045323 -0.0599723645  0.032910522  0.036810413 -0.1452645510 #> [23,]  0.150237933 -0.0965439081 -0.003936510 -0.095468886 -0.1188665628 #> [24,] -0.022066562  0.0102432724 -0.081241496 -0.020487377  0.0567061864 #> [25,]  0.121200562 -0.0294806436  0.105805546  0.021516595 -0.1019662619 #> [26,]  0.087318882  0.1123670489  0.121324383 -0.097014792  0.0024950919 #> [27,] -0.036924142 -0.0984558910 -0.006701123 -0.102401391 -0.0750640929 #> [28,] -0.041761030  0.0722247437 -0.127274513  0.074315883  0.0561521873 #> [29,] -0.004786180  0.0075531905 -0.037355982  0.129485235  0.0061366563 #> [30,] -0.094688147  0.1185596362 -0.046303611 -0.119477965  0.0936245024 #> [31,] -0.040409558 -0.1442087293  0.119214535  0.025982624  0.1383348256 #> [32,] -0.102084324  0.0209327936 -0.133878037 -0.089119643  0.1417264789 #> [33,] -0.098368950  0.0562144145 -0.056612156  0.135265678  0.0123350089 #> [34,]  0.028472088 -0.0051434124 -0.016958067 -0.109453999 -0.1186649650 #> [35,] -0.014442943 -0.0773283318  0.043913744 -0.118158497  0.0510012843 #> [36,] -0.075589858 -0.0251652133 -0.124063641 -0.108287200 -0.1252036989 #> [37,] -0.017534520  0.0979118943 -0.100522108  0.042041995 -0.0497770496 #> [38,]  0.133399829 -0.0145399561  0.055988766 -0.034031775 -0.0004736667 #> [39,]  0.111111581  0.0719786808  0.078929625 -0.044686079  0.0983740538 #> [40,] -0.050442319 -0.1025434956  0.068404771 -0.091861837 -0.0528250523 #> [41,]  0.064321525  0.0271488521 -0.114794455  0.034399714 -0.1270416826 #> [42,] -0.095492922 -0.0794738084  0.108824864 -0.072882287 -0.0069536623 #> [43,] -0.055926912  0.0972751901 -0.007682343  0.075649939  0.0219721682 #> [44,]  0.143748358 -0.0857400820  0.065436147  0.063653260  0.1151135862 #> [45,] -0.121196441 -0.1199730858 -0.038613122 -0.113981217 -0.0762016848 #> [46,]  0.008297200 -0.0702569708  0.133842513  0.074419782  0.0334905870 #> [47,]  0.121736668 -0.0555050597 -0.105964422 -0.130005002  0.0543809682 #> [48,]  0.120862104 -0.0540726744  0.045944825  0.000799371 -0.1077982783 #> [49,] -0.059175905 -0.0011382885  0.139593959 -0.066294871 -0.0299039353 #> [50,]  0.134032175  0.1106929854  0.023042113  0.114560261  0.1053758040 #>  #> [[1]]$`2.bias` #>  [1]  0.101042405 -0.106865503  0.125243694 -0.130647853  0.012762768 #>  [6]  0.136598557 -0.049118467 -0.071585990  0.090344541 -0.051313184 #> [11] -0.037872903 -0.062319309  0.096095473  0.018142670  0.057532310 #> [16] -0.057569593 -0.026404919 -0.054481298 -0.035676062  0.099709965 #> [21]  0.107368305 -0.054898351  0.070901051 -0.047197863  0.037443403 #> [26]  0.007482094 -0.038871527  0.128501356 -0.047779974 -0.004871946 #> [31]  0.125409141  0.063802585  0.038505673 -0.146786571 -0.131999075 #> [36] -0.018448893 -0.041058492 -0.083152585 -0.143644631 -0.010284307 #> [41]  0.126048714  0.131669834 -0.050029080  0.073924795 -0.097713910 #> [46]  0.019017348  0.122138269  0.127857611 -0.027352143 -0.071730159 #>  #> [[1]]$`4.weight` #>            [,1]        [,2]         [,3] [,4]       [,5]     [,6]      [,7] #> [1,] -0.2509254 -0.01873828 -0.003425301 0.11 -0.2380965 0.225369 0.1674028 #>            [,8]      [,9]      [,10]      [,11]      [,12]    [,13]      [,14] #> [1,] -0.1063567 0.1304545 0.02736623 -0.1498004 0.04441846 0.105053 0.01240779 #>            [,15]      [,16]     [,17]      [,18]       [,19]       [,20] #> [1,] -0.07187423 0.08430326 0.1379596 -0.2405567 -0.01478522 0.007920717 #>          [,21]     [,22]     [,23]       [,24]     [,25]      [,26]      [,27] #> [1,] 0.1271616 -0.086798 0.0981639 -0.01783963 -0.264604 -0.3114285 -0.1440371 #>            [,28]      [,29]      [,30]     [,31]      [,32]      [,33] #> [1,] -0.01309788 -0.1576957 -0.3085491 0.2063282 0.02083832 0.02892408 #>           [,34]     [,35]       [,36]       [,37]    [,38]    [,39] #> [1,] 0.05064648 0.1582949 -0.08512452 -0.02793183 0.074639 0.106357 #>             [,40]      [,41]       [,42]      [,43]    [,44]      [,45] #> [1,] -0.001338765 -0.1824349 -0.05036336 -0.1013086 0.156791 0.03049869 #>          [,46]      [,47]      [,48]        [,49]      [,50] #> [1,] 0.1569561 -0.1464819 0.04302794 -0.003403831 -0.2390229 #>  #> [[1]]$`4.bias` #> [1] 0.1296245 #>  #>  # }"},{"path":"/reference/conditionalEffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate average conditional effects — conditionalEffects","title":"Calculate average conditional effects — conditionalEffects","text":"Average conditional effects calculate local derivatives observation feature. similar marginal effects. average conditional effects approximation linear effects (see Pichler Hartig, 2023 details). can use function either calculate main effects (diagonal, take look example) interaction effects (-diagonals) features. obtain uncertainties effects, enable bootstrapping option dnn(..) function (see example).","code":""},{"path":"/reference/conditionalEffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate average conditional effects — conditionalEffects","text":"","code":"conditionalEffects(   object,   interactions = FALSE,   epsilon = 0.1,   device = c(\"cpu\", \"cuda\", \"mps\"),   indices = NULL,   data = NULL,   type = \"response\",   ... )  # S3 method for class 'citodnn' conditionalEffects(   object,   interactions = FALSE,   epsilon = 0.1,   device = c(\"cpu\", \"cuda\", \"mps\"),   indices = NULL,   data = NULL,   type = \"response\",   ... )  # S3 method for class 'citodnnBootstrap' conditionalEffects(   object,   interactions = FALSE,   epsilon = 0.1,   device = c(\"cpu\", \"cuda\", \"mps\"),   indices = NULL,   data = NULL,   type = \"response\",   ... )"},{"path":"/reference/conditionalEffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate average conditional effects — conditionalEffects","text":"object object class citodnn interactions calculate interactions (computationally expensive) epsilon difference used calculate derivatives device device indices variables ACE calculated data data used calculate ACE type ACE scale (response link) ... additional arguments passed predict function","code":""},{"path":"/reference/conditionalEffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate average conditional effects — conditionalEffects","text":"S3 object class \"conditionalEffects\" returned. list consists following attributes: result 3-dimensional array raw results mean Matrix, average conditional effects abs Matrix, summed absolute conditional effects sd Matrix, standard deviation conditional effects","code":""},{"path":"/reference/conditionalEffects.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate average conditional effects — conditionalEffects","text":"Scholbeck, C. ., Casalicchio, G., Molnar, C., Bischl, B., & Heumann, C. (2022). Marginal effects non-linear prediction functions. arXiv preprint arXiv:2201.08837. Pichler, M., & Hartig, F. (2023). Can predictive models used causal inference?. arXiv preprint arXiv:2306.10551.","code":""},{"path":"/reference/conditionalEffects.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate average conditional effects — conditionalEffects","text":"Maximilian Pichler","code":""},{"path":"/reference/conditionalEffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate average conditional effects — conditionalEffects","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Build and train  Network nn.fit = dnn(Sepal.Length~., data = datasets::iris)  # Calculate average conditional effects ACE = conditionalEffects(nn.fit)  ## Main effects (categorical features are not supported) ACE  ## With interaction effects: ACE = conditionalEffects(nn.fit, interactions = TRUE) ## The off diagonal elements are the interaction effects ACE[[1]]$mean ## ACE is a list, elements correspond to the number of response classes ## Sepal.length == 1 Response so we have only one ## list element in the ACE object  # Re-train NN with bootstrapping to obtain standard errors nn.fit = dnn(Sepal.Length~., data = datasets::iris, bootstrap = 30L) ## The summary method calculates also the conditional effects, and if ## bootstrapping was used, it will also report standard errors and p-values: summary(nn.fit)   } #> Loss at epoch 1: 4.363048, lr: 0.01000  #> Loss at epoch 2: 0.272192, lr: 0.01000 #> Loss at epoch 3: 0.374940, lr: 0.01000 #> Loss at epoch 4: 0.276003, lr: 0.01000 #> Loss at epoch 5: 0.176003, lr: 0.01000 #> Loss at epoch 6: 0.162379, lr: 0.01000 #> Loss at epoch 7: 0.162826, lr: 0.01000 #> Loss at epoch 8: 0.218452, lr: 0.01000 #> Loss at epoch 9: 0.153501, lr: 0.01000 #> Loss at epoch 10: 0.159021, lr: 0.01000 #> Loss at epoch 11: 0.199770, lr: 0.01000 #> Loss at epoch 12: 0.276008, lr: 0.01000 #> Loss at epoch 13: 0.136575, lr: 0.01000 #> Loss at epoch 14: 0.134161, lr: 0.01000 #> Loss at epoch 15: 0.140879, lr: 0.01000 #> Loss at epoch 16: 0.154157, lr: 0.01000 #> Loss at epoch 17: 0.137692, lr: 0.01000 #> Loss at epoch 18: 0.280078, lr: 0.01000 #> Loss at epoch 19: 0.152508, lr: 0.01000 #> Loss at epoch 20: 0.201336, lr: 0.01000 #> Loss at epoch 21: 0.176678, lr: 0.01000 #> Loss at epoch 22: 0.168723, lr: 0.01000 #> Loss at epoch 23: 0.217394, lr: 0.01000 #> Loss at epoch 24: 0.126510, lr: 0.01000 #> Loss at epoch 25: 0.142637, lr: 0.01000 #> Loss at epoch 26: 0.159910, lr: 0.01000 #> Loss at epoch 27: 0.129799, lr: 0.01000 #> Loss at epoch 28: 0.119393, lr: 0.01000 #> Loss at epoch 29: 0.128175, lr: 0.01000 #> Loss at epoch 30: 0.139445, lr: 0.01000 #> Loss at epoch 31: 0.120286, lr: 0.01000 #> Loss at epoch 32: 0.153908, lr: 0.01000 #> Loss at epoch 33: 0.139932, lr: 0.01000 #> Loss at epoch 34: 0.196470, lr: 0.01000 #> Loss at epoch 35: 0.222016, lr: 0.01000 #> Loss at epoch 36: 0.115350, lr: 0.01000 #> Loss at epoch 37: 0.130246, lr: 0.01000 #> Loss at epoch 38: 0.128341, lr: 0.01000 #> Loss at epoch 39: 0.139921, lr: 0.01000 #> Loss at epoch 40: 0.133473, lr: 0.01000 #> Loss at epoch 41: 0.190675, lr: 0.01000 #> Loss at epoch 42: 0.152598, lr: 0.01000 #> Loss at epoch 43: 0.127298, lr: 0.01000 #> Loss at epoch 44: 0.143021, lr: 0.01000 #> Loss at epoch 45: 0.176637, lr: 0.01000 #> Loss at epoch 46: 0.227017, lr: 0.01000 #> Loss at epoch 47: 0.116094, lr: 0.01000 #> Loss at epoch 48: 0.169703, lr: 0.01000 #> Loss at epoch 49: 0.115200, lr: 0.01000 #> Loss at epoch 50: 0.194225, lr: 0.01000 #> Loss at epoch 51: 0.121132, lr: 0.01000 #> Loss at epoch 52: 0.140460, lr: 0.01000 #> Loss at epoch 53: 0.128924, lr: 0.01000 #> Loss at epoch 54: 0.188344, lr: 0.01000 #> Loss at epoch 55: 0.114714, lr: 0.01000 #> Loss at epoch 56: 0.136857, lr: 0.01000 #> Loss at epoch 57: 0.224927, lr: 0.01000 #> Loss at epoch 58: 0.151434, lr: 0.01000 #> Loss at epoch 59: 0.121373, lr: 0.01000 #> Loss at epoch 60: 0.196071, lr: 0.01000 #> Loss at epoch 61: 0.142148, lr: 0.01000 #> Loss at epoch 62: 0.112751, lr: 0.01000 #> Loss at epoch 63: 0.120279, lr: 0.01000 #> Loss at epoch 64: 0.124868, lr: 0.01000 #> Loss at epoch 65: 0.122346, lr: 0.01000 #> Loss at epoch 66: 0.151730, lr: 0.01000 #> Loss at epoch 67: 0.136396, lr: 0.01000 #> Loss at epoch 68: 0.134735, lr: 0.01000 #> Loss at epoch 69: 0.145546, lr: 0.01000 #> Loss at epoch 70: 0.112017, lr: 0.01000 #> Loss at epoch 71: 0.127638, lr: 0.01000 #> Loss at epoch 72: 0.178938, lr: 0.01000 #> Loss at epoch 73: 0.224137, lr: 0.01000 #> Loss at epoch 74: 0.241549, lr: 0.01000 #> Loss at epoch 75: 0.176176, lr: 0.01000 #> Loss at epoch 76: 0.119769, lr: 0.01000 #> Loss at epoch 77: 0.138289, lr: 0.01000 #> Loss at epoch 78: 0.149200, lr: 0.01000 #> Loss at epoch 79: 0.129378, lr: 0.01000 #> Loss at epoch 80: 0.153158, lr: 0.01000 #> Loss at epoch 81: 0.140047, lr: 0.01000 #> Loss at epoch 82: 0.115352, lr: 0.01000 #> Loss at epoch 83: 0.111738, lr: 0.01000 #> Loss at epoch 84: 0.136471, lr: 0.01000 #> Loss at epoch 85: 0.226092, lr: 0.01000 #> Loss at epoch 86: 0.141407, lr: 0.01000 #> Loss at epoch 87: 0.116782, lr: 0.01000 #> Loss at epoch 88: 0.112259, lr: 0.01000 #> Loss at epoch 89: 0.114547, lr: 0.01000 #> Loss at epoch 90: 0.126242, lr: 0.01000 #> Loss at epoch 91: 0.120716, lr: 0.01000 #> Loss at epoch 92: 0.102394, lr: 0.01000 #> Loss at epoch 93: 0.180366, lr: 0.01000 #> Loss at epoch 94: 0.117197, lr: 0.01000 #> Loss at epoch 95: 0.113679, lr: 0.01000 #> Loss at epoch 96: 0.121416, lr: 0.01000 #> Loss at epoch 97: 0.196279, lr: 0.01000 #> Loss at epoch 98: 0.137671, lr: 0.01000 #> Loss at epoch 99: 0.118519, lr: 0.01000 #> Loss at epoch 100: 0.235122, lr: 0.01000 #> Summary of Deep Neural Network Model #>  #>  #> ── Feature Importance  #>   #>                 Importance Std.Err Z value Pr(>|z|)   #> Sepal.Width →        0.886   0.388    2.29    0.022 * #> Petal.Length →      20.581   9.271    2.22    0.026 * #> Petal.Width →        1.038   1.369    0.76    0.448   #> Species →            0.239   0.190    1.26    0.208   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>  #>  #> ── Average Conditional Effects  #>                     ACE Std.Err Z value Pr(>|z|)     #> Sepal.Width →    0.4800  0.0627    7.65    2e-14 *** #> Petal.Length →   0.6290  0.0653    9.64   <2e-16 *** #> Petal.Width →   -0.2654  0.1537   -1.73    0.084 .   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #>  #>  #> ── Standard Deviation of Conditional Effects  #>   #>                    ACE Std.Err Z value Pr(>|z|)     #> Sepal.Width →   0.0768  0.0229    3.35   0.0008 *** #> Petal.Length →  0.0425  0.0140    3.03   0.0024 **  #> Petal.Width →   0.0431  0.0188    2.30   0.0217 *   #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # }"},{"path":"/reference/config_lr_scheduler.html","id":null,"dir":"Reference","previous_headings":"","what":"Creation of customized learning rate scheduler objects — config_lr_scheduler","title":"Creation of customized learning rate scheduler objects — config_lr_scheduler","text":"Helps create custom learning rate schedulers dnn.","code":""},{"path":"/reference/config_lr_scheduler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creation of customized learning rate scheduler objects — config_lr_scheduler","text":"","code":"config_lr_scheduler(   type = c(\"lambda\", \"multiplicative\", \"reduce_on_plateau\", \"one_cycle\", \"step\"),   verbose = FALSE,   ... )"},{"path":"/reference/config_lr_scheduler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creation of customized learning rate scheduler objects — config_lr_scheduler","text":"type String defining type scheduler used. See Details. verbose TRUE, additional information scheduler printed console. ... additional arguments passed scheduler. See Details.","code":""},{"path":"/reference/config_lr_scheduler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creation of customized learning rate scheduler objects — config_lr_scheduler","text":"object class cito_lr_scheduler give dnn","code":""},{"path":"/reference/config_lr_scheduler.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creation of customized learning rate scheduler objects — config_lr_scheduler","text":"different learning rate scheduler need different variables, functions tell variables can set: lambda: lr_lambda multiplicative: lr_multiplicative reduce_on_plateau: lr_reduce_on_plateau one_cycle: lr_one_cycle step: lr_step","code":""},{"path":"/reference/config_lr_scheduler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creation of customized learning rate scheduler objects — config_lr_scheduler","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # create learning rate scheduler object scheduler <- config_lr_scheduler(type = \"step\",                         step_size = 30,                         gamma = 0.15,                         verbose = TRUE)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris, lr_scheduler = scheduler)  } #> Learning rate Scheduler step #> step_size: [30] #> gamma: [0.15]  #> last_epoch: [-1]  #> Loss at epoch 1: 3.954713, lr: 0.01000  #> Loss at epoch 2: 0.231113, lr: 0.01000 #> Loss at epoch 3: 0.231350, lr: 0.01000 #> Loss at epoch 4: 0.269389, lr: 0.01000 #> Loss at epoch 5: 0.169243, lr: 0.01000 #> Loss at epoch 6: 0.141261, lr: 0.01000 #> Loss at epoch 7: 0.185906, lr: 0.01000 #> Loss at epoch 8: 0.143617, lr: 0.01000 #> Loss at epoch 9: 0.140730, lr: 0.01000 #> Loss at epoch 10: 0.129844, lr: 0.01000 #> Loss at epoch 11: 0.136042, lr: 0.01000 #> Loss at epoch 12: 0.436134, lr: 0.01000 #> Loss at epoch 13: 0.318335, lr: 0.01000 #> Loss at epoch 14: 0.138690, lr: 0.01000 #> Loss at epoch 15: 0.246074, lr: 0.01000 #> Loss at epoch 16: 0.157595, lr: 0.01000 #> Loss at epoch 17: 0.294319, lr: 0.01000 #> Loss at epoch 18: 0.168762, lr: 0.01000 #> Loss at epoch 19: 0.176419, lr: 0.01000 #> Loss at epoch 20: 0.161251, lr: 0.01000 #> Loss at epoch 21: 0.166288, lr: 0.01000 #> Loss at epoch 22: 0.207131, lr: 0.01000 #> Loss at epoch 23: 0.141381, lr: 0.01000 #> Loss at epoch 24: 0.153455, lr: 0.01000 #> Loss at epoch 25: 0.143479, lr: 0.01000 #> Loss at epoch 26: 0.258239, lr: 0.01000 #> Loss at epoch 27: 0.197407, lr: 0.01000 #> Loss at epoch 28: 0.216296, lr: 0.01000 #> Loss at epoch 29: 0.185858, lr: 0.01000 #> Loss at epoch 30: 0.213892, lr: 0.00150 #> Loss at epoch 31: 0.123207, lr: 0.00150 #> Loss at epoch 32: 0.115316, lr: 0.00150 #> Loss at epoch 33: 0.114999, lr: 0.00150 #> Loss at epoch 34: 0.116099, lr: 0.00150 #> Loss at epoch 35: 0.116590, lr: 0.00150 #> Loss at epoch 36: 0.117337, lr: 0.00150 #> Loss at epoch 37: 0.114886, lr: 0.00150 #> Loss at epoch 38: 0.115280, lr: 0.00150 #> Loss at epoch 39: 0.115999, lr: 0.00150 #> Loss at epoch 40: 0.113874, lr: 0.00150 #> Loss at epoch 41: 0.114967, lr: 0.00150 #> Loss at epoch 42: 0.113593, lr: 0.00150 #> Loss at epoch 43: 0.113893, lr: 0.00150 #> Loss at epoch 44: 0.113710, lr: 0.00150 #> Loss at epoch 45: 0.115073, lr: 0.00150 #> Loss at epoch 46: 0.113688, lr: 0.00150 #> Loss at epoch 47: 0.115372, lr: 0.00150 #> Loss at epoch 48: 0.113541, lr: 0.00150 #> Loss at epoch 49: 0.112336, lr: 0.00150 #> Loss at epoch 50: 0.115721, lr: 0.00150 #> Loss at epoch 51: 0.113674, lr: 0.00150 #> Loss at epoch 52: 0.111781, lr: 0.00150 #> Loss at epoch 53: 0.113932, lr: 0.00150 #> Loss at epoch 54: 0.113738, lr: 0.00150 #> Loss at epoch 55: 0.112622, lr: 0.00150 #> Loss at epoch 56: 0.111825, lr: 0.00150 #> Loss at epoch 57: 0.112605, lr: 0.00150 #> Loss at epoch 58: 0.112345, lr: 0.00150 #> Loss at epoch 59: 0.111780, lr: 0.00150 #> Loss at epoch 60: 0.112041, lr: 0.00022 #> Loss at epoch 61: 0.111289, lr: 0.00022 #> Loss at epoch 62: 0.111016, lr: 0.00022 #> Loss at epoch 63: 0.111133, lr: 0.00022 #> Loss at epoch 64: 0.111072, lr: 0.00022 #> Loss at epoch 65: 0.111458, lr: 0.00022 #> Loss at epoch 66: 0.110895, lr: 0.00022 #> Loss at epoch 67: 0.111030, lr: 0.00022 #> Loss at epoch 68: 0.110732, lr: 0.00022 #> Loss at epoch 69: 0.111241, lr: 0.00022 #> Loss at epoch 70: 0.110739, lr: 0.00022 #> Loss at epoch 71: 0.110904, lr: 0.00022 #> Loss at epoch 72: 0.110879, lr: 0.00022 #> Loss at epoch 73: 0.110861, lr: 0.00022 #> Loss at epoch 74: 0.110837, lr: 0.00022 #> Loss at epoch 75: 0.110749, lr: 0.00022 #> Loss at epoch 76: 0.110807, lr: 0.00022 #> Loss at epoch 77: 0.110753, lr: 0.00022 #> Loss at epoch 78: 0.110695, lr: 0.00022 #> Loss at epoch 79: 0.110736, lr: 0.00022 #> Loss at epoch 80: 0.110750, lr: 0.00022 #> Loss at epoch 81: 0.110722, lr: 0.00022 #> Loss at epoch 82: 0.110700, lr: 0.00022 #> Loss at epoch 83: 0.110605, lr: 0.00022 #> Loss at epoch 84: 0.110559, lr: 0.00022 #> Loss at epoch 85: 0.110594, lr: 0.00022 #> Loss at epoch 86: 0.110858, lr: 0.00022 #> Loss at epoch 87: 0.110748, lr: 0.00022 #> Loss at epoch 88: 0.110585, lr: 0.00022 #> Loss at epoch 89: 0.110702, lr: 0.00022 #> Loss at epoch 90: 0.110729, lr: 0.00003 #> Loss at epoch 91: 0.110313, lr: 0.00003 #> Loss at epoch 92: 0.110357, lr: 0.00003 #> Loss at epoch 93: 0.110332, lr: 0.00003 #> Loss at epoch 94: 0.110322, lr: 0.00003 #> Loss at epoch 95: 0.110314, lr: 0.00003 #> Loss at epoch 96: 0.110295, lr: 0.00003 #> Loss at epoch 97: 0.110314, lr: 0.00003 #> Loss at epoch 98: 0.110305, lr: 0.00003 #> Loss at epoch 99: 0.110290, lr: 0.00003 #> Loss at epoch 100: 0.110298, lr: 0.00003 # }"},{"path":"/reference/config_optimizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Creation of customized optimizer objects — config_optimizer","title":"Creation of customized optimizer objects — config_optimizer","text":"Helps create custom optimizer dnn. recommended set learning rate dnn.","code":""},{"path":"/reference/config_optimizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creation of customized optimizer objects — config_optimizer","text":"","code":"config_optimizer(   type = c(\"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", \"rprop\", \"sgd\"),   verbose = FALSE,   ... )"},{"path":"/reference/config_optimizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creation of customized optimizer objects — config_optimizer","text":"type character string defining optimizer used. See Details. verbose TRUE, additional information scheduler printed console ... additional arguments passed optimizer. See Details.","code":""},{"path":"/reference/config_optimizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creation of customized optimizer objects — config_optimizer","text":"object class cito_optim give dnn","code":""},{"path":"/reference/config_optimizer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creation of customized optimizer objects — config_optimizer","text":"different optimizer need different variables, function tell variables set. information see corresponding functions: adam: optim_adam adadelta: optim_adadelta adagrad: optim_adagrad rmsprop: optim_rmsprop rprop: optim_rprop sgd: optim_sgd","code":""},{"path":"/reference/config_optimizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creation of customized optimizer objects — config_optimizer","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # create optimizer object opt <- config_optimizer(type = \"adagrad\",                         lr_decay = 1e-04,                         weight_decay = 0.1,                         verbose = TRUE)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris, optimizer = opt)  } #> set adagrad optimizer with following values  #> lr_decay: [1e-04]  #> weight_decay: [0.1]  #> initial_accumulator_value: [0]  #> eps: [1e-10]  #> Loss at epoch 1: 5.434706, lr: 0.01000  #> Loss at epoch 2: 0.147970, lr: 0.01000 #> Loss at epoch 3: 0.135986, lr: 0.01000 #> Loss at epoch 4: 0.135486, lr: 0.01000 #> Loss at epoch 5: 0.131027, lr: 0.01000 #> Loss at epoch 6: 0.126657, lr: 0.01000 #> Loss at epoch 7: 0.125437, lr: 0.01000 #> Loss at epoch 8: 0.124690, lr: 0.01000 #> Loss at epoch 9: 0.124437, lr: 0.01000 #> Loss at epoch 10: 0.124501, lr: 0.01000 #> Loss at epoch 11: 0.127424, lr: 0.01000 #> Loss at epoch 12: 0.121171, lr: 0.01000 #> Loss at epoch 13: 0.122711, lr: 0.01000 #> Loss at epoch 14: 0.121640, lr: 0.01000 #> Loss at epoch 15: 0.118683, lr: 0.01000 #> Loss at epoch 16: 0.125965, lr: 0.01000 #> Loss at epoch 17: 0.121460, lr: 0.01000 #> Loss at epoch 18: 0.121079, lr: 0.01000 #> Loss at epoch 19: 0.119068, lr: 0.01000 #> Loss at epoch 20: 0.115174, lr: 0.01000 #> Loss at epoch 21: 0.119830, lr: 0.01000 #> Loss at epoch 22: 0.119216, lr: 0.01000 #> Loss at epoch 23: 0.124864, lr: 0.01000 #> Loss at epoch 24: 0.116221, lr: 0.01000 #> Loss at epoch 25: 0.113975, lr: 0.01000 #> Loss at epoch 26: 0.118420, lr: 0.01000 #> Loss at epoch 27: 0.113949, lr: 0.01000 #> Loss at epoch 28: 0.116257, lr: 0.01000 #> Loss at epoch 29: 0.113590, lr: 0.01000 #> Loss at epoch 30: 0.115900, lr: 0.01000 #> Loss at epoch 31: 0.115285, lr: 0.01000 #> Loss at epoch 32: 0.113506, lr: 0.01000 #> Loss at epoch 33: 0.114386, lr: 0.01000 #> Loss at epoch 34: 0.113213, lr: 0.01000 #> Loss at epoch 35: 0.119462, lr: 0.01000 #> Loss at epoch 36: 0.113817, lr: 0.01000 #> Loss at epoch 37: 0.117121, lr: 0.01000 #> Loss at epoch 38: 0.111578, lr: 0.01000 #> Loss at epoch 39: 0.114151, lr: 0.01000 #> Loss at epoch 40: 0.112557, lr: 0.01000 #> Loss at epoch 41: 0.113448, lr: 0.01000 #> Loss at epoch 42: 0.114760, lr: 0.01000 #> Loss at epoch 43: 0.118541, lr: 0.01000 #> Loss at epoch 44: 0.113428, lr: 0.01000 #> Loss at epoch 45: 0.114449, lr: 0.01000 #> Loss at epoch 46: 0.111930, lr: 0.01000 #> Loss at epoch 47: 0.110264, lr: 0.01000 #> Loss at epoch 48: 0.115660, lr: 0.01000 #> Loss at epoch 49: 0.112935, lr: 0.01000 #> Loss at epoch 50: 0.112793, lr: 0.01000 #> Loss at epoch 51: 0.111559, lr: 0.01000 #> Loss at epoch 52: 0.117571, lr: 0.01000 #> Loss at epoch 53: 0.113916, lr: 0.01000 #> Loss at epoch 54: 0.110999, lr: 0.01000 #> Loss at epoch 55: 0.112905, lr: 0.01000 #> Loss at epoch 56: 0.111579, lr: 0.01000 #> Loss at epoch 57: 0.111584, lr: 0.01000 #> Loss at epoch 58: 0.109349, lr: 0.01000 #> Loss at epoch 59: 0.110725, lr: 0.01000 #> Loss at epoch 60: 0.112281, lr: 0.01000 #> Loss at epoch 61: 0.112364, lr: 0.01000 #> Loss at epoch 62: 0.111839, lr: 0.01000 #> Loss at epoch 63: 0.109593, lr: 0.01000 #> Loss at epoch 64: 0.109720, lr: 0.01000 #> Loss at epoch 65: 0.110415, lr: 0.01000 #> Loss at epoch 66: 0.109808, lr: 0.01000 #> Loss at epoch 67: 0.114200, lr: 0.01000 #> Loss at epoch 68: 0.111774, lr: 0.01000 #> Loss at epoch 69: 0.112833, lr: 0.01000 #> Loss at epoch 70: 0.112160, lr: 0.01000 #> Loss at epoch 71: 0.111173, lr: 0.01000 #> Loss at epoch 72: 0.113472, lr: 0.01000 #> Loss at epoch 73: 0.109752, lr: 0.01000 #> Loss at epoch 74: 0.112768, lr: 0.01000 #> Loss at epoch 75: 0.110691, lr: 0.01000 #> Loss at epoch 76: 0.112001, lr: 0.01000 #> Loss at epoch 77: 0.109820, lr: 0.01000 #> Loss at epoch 78: 0.110821, lr: 0.01000 #> Loss at epoch 79: 0.112135, lr: 0.01000 #> Loss at epoch 80: 0.114343, lr: 0.01000 #> Loss at epoch 81: 0.111323, lr: 0.01000 #> Loss at epoch 82: 0.112789, lr: 0.01000 #> Loss at epoch 83: 0.114382, lr: 0.01000 #> Loss at epoch 84: 0.108308, lr: 0.01000 #> Loss at epoch 85: 0.112346, lr: 0.01000 #> Loss at epoch 86: 0.111382, lr: 0.01000 #> Loss at epoch 87: 0.108837, lr: 0.01000 #> Loss at epoch 88: 0.110568, lr: 0.01000 #> Loss at epoch 89: 0.107535, lr: 0.01000 #> Loss at epoch 90: 0.108457, lr: 0.01000 #> Loss at epoch 91: 0.111533, lr: 0.01000 #> Loss at epoch 92: 0.111983, lr: 0.01000 #> Loss at epoch 93: 0.109763, lr: 0.01000 #> Loss at epoch 94: 0.109996, lr: 0.01000 #> Loss at epoch 95: 0.109777, lr: 0.01000 #> Loss at epoch 96: 0.110851, lr: 0.01000 #> Loss at epoch 97: 0.109567, lr: 0.01000 #> Loss at epoch 98: 0.111678, lr: 0.01000 #> Loss at epoch 99: 0.109224, lr: 0.01000 #> Loss at epoch 100: 0.107545, lr: 0.01000 # }"},{"path":"/reference/config_tuning.html","id":null,"dir":"Reference","previous_headings":"","what":"Config hyperparameter tuning — config_tuning","title":"Config hyperparameter tuning — config_tuning","text":"Config hyperparameter tuning","code":""},{"path":"/reference/config_tuning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Config hyperparameter tuning — config_tuning","text":"","code":"config_tuning(   CV = 5,   steps = 10,   parallel = FALSE,   NGPU = 1,   cancel = TRUE,   bootstrap_final = NULL,   bootstrap_parallel = FALSE,   return_models = FALSE )"},{"path":"/reference/config_tuning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Config hyperparameter tuning — config_tuning","text":"CV numeric, specifies k-folded cross validation steps numeric, number random tuning steps parallel numeric, number parallel cores (tuning steps parallelized) NGPU numeric, set one GPU available, tuning parallelized CPU cores GPUs, works NCPU > 1 cancel CV/tuning specific hyperparameter set model reduce loss baseline burnin returns NA loss bootstrap_final bootstrap final model, models boostrapped must set globally via bootstrap argument dnn() function bootstrap_parallel bootstrapping parallelized return_models return individual models","code":""},{"path":"/reference/config_tuning.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Config hyperparameter tuning — config_tuning","text":"Note hyperparameter tuning can expensive. implemented option parallelize hyperparameter tuning, including parallelization one GPUs (hyperparameter evaluation parallelized, CV). can especially useful small models. example, 4 GPUs, 20 CPU cores, 20 steps (random samples random search), run `dnn(..., device=\"cuda\",lr = tune(), batchsize=tune(), tuning=config_tuning(parallel=20, NGPU=4)', distribute 20 model fits across 4 GPUs, GPU process 5 models (parallel).","code":""},{"path":"/reference/continue_training.html","id":null,"dir":"Reference","previous_headings":"","what":"Continues training of a model generated with dnn or cnn for additional epochs. — continue_training","title":"Continues training of a model generated with dnn or cnn for additional epochs. — continue_training","text":"training/validation loss still decreasing end training, often sign NN yet converged. can use function continue training instead re-training entire model.","code":""},{"path":"/reference/continue_training.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Continues training of a model generated with dnn or cnn for additional epochs. — continue_training","text":"","code":"continue_training(model, ...)  # S3 method for class 'citodnn' continue_training(   model,   epochs = 32,   data = NULL,   device = NULL,   verbose = TRUE,   changed_params = NULL,   init_optimizer = TRUE,   ... )  # S3 method for class 'citodnnBootstrap' continue_training(   model,   epochs = 32,   data = NULL,   device = NULL,   verbose = TRUE,   changed_params = NULL,   parallel = FALSE,   init_optimizer = TRUE,   ... )  # S3 method for class 'citocnn' continue_training(   model,   epochs = 32,   X = NULL,   Y = NULL,   device = NULL,   verbose = TRUE,   changed_params = NULL,   init_optimizer = TRUE,   ... )"},{"path":"/reference/continue_training.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Continues training of a model generated with dnn or cnn for additional epochs. — continue_training","text":"model model created dnn cnn ... class-specific arguments epochs additional epochs training continue data matrix data.frame. provided data original training used device can used overwrite device used previous training verbose print training validation loss epochs changed_params list arguments change compared original training setup, see dnn parameter can changed init_optimizer re-initialize optimizer parallel train bootstrapped model parallel X array. provided X original training used Y vector, factor, numerical matrix logical matrix. provided Y original training used","code":""},{"path":"/reference/continue_training.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Continues training of a model generated with dnn or cnn for additional epochs. — continue_training","text":"model class citodnn, citodnnBootstrap citocnn created dnn cnn","code":""},{"path":"/reference/continue_training.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Continues training of a model generated with dnn or cnn for additional epochs. — continue_training","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222) validation_set<- sample(c(1:nrow(datasets::iris)),25)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,], epochs = 32)  # continue training for another 32 epochs nn.fit<- continue_training(nn.fit,epochs = 32)  # Use model on validation set predictions <- predict(nn.fit, iris[validation_set,]) } #> Loss at epoch 1: 8.499764, lr: 0.01000  #> Loss at epoch 2: 0.155589, lr: 0.01000 #> Loss at epoch 3: 0.157004, lr: 0.01000 #> Loss at epoch 4: 0.143644, lr: 0.01000 #> Loss at epoch 5: 0.231614, lr: 0.01000 #> Loss at epoch 6: 0.158015, lr: 0.01000 #> Loss at epoch 7: 0.164213, lr: 0.01000 #> Loss at epoch 8: 0.210553, lr: 0.01000 #> Loss at epoch 9: 0.196251, lr: 0.01000 #> Loss at epoch 10: 0.155395, lr: 0.01000 #> Loss at epoch 11: 0.170208, lr: 0.01000 #> Loss at epoch 12: 0.157750, lr: 0.01000 #> Loss at epoch 13: 0.144073, lr: 0.01000 #> Loss at epoch 14: 0.158020, lr: 0.01000 #> Loss at epoch 15: 0.235408, lr: 0.01000 #> Loss at epoch 16: 0.154042, lr: 0.01000 #> Loss at epoch 17: 0.283179, lr: 0.01000 #> Loss at epoch 18: 0.137547, lr: 0.01000 #> Loss at epoch 19: 0.152476, lr: 0.01000 #> Loss at epoch 20: 0.204473, lr: 0.01000 #> Loss at epoch 21: 0.142053, lr: 0.01000 #> Loss at epoch 22: 0.228056, lr: 0.01000 #> Loss at epoch 23: 0.168625, lr: 0.01000 #> Loss at epoch 24: 0.282815, lr: 0.01000 #> Loss at epoch 25: 0.201953, lr: 0.01000 #> Loss at epoch 26: 0.190323, lr: 0.01000 #> Loss at epoch 27: 0.127644, lr: 0.01000 #> Loss at epoch 28: 0.184540, lr: 0.01000 #> Loss at epoch 29: 0.167853, lr: 0.01000 #> Loss at epoch 30: 0.138815, lr: 0.01000 #> Loss at epoch 31: 0.155092, lr: 0.01000 #> Loss at epoch 32: 0.165073, lr: 0.01000 #> Loss at epoch 33: 0.185073, lr: 0.01000  #> Loss at epoch 34: 0.133962, lr: 0.01000 #> Loss at epoch 35: 0.171664, lr: 0.01000 #> Loss at epoch 36: 0.163689, lr: 0.01000 #> Loss at epoch 37: 0.152154, lr: 0.01000 #> Loss at epoch 38: 0.169949, lr: 0.01000 #> Loss at epoch 39: 0.125309, lr: 0.01000 #> Loss at epoch 40: 0.167960, lr: 0.01000 #> Loss at epoch 41: 0.144890, lr: 0.01000 #> Loss at epoch 42: 0.205447, lr: 0.01000 #> Loss at epoch 43: 0.133132, lr: 0.01000 #> Loss at epoch 44: 0.149254, lr: 0.01000 #> Loss at epoch 45: 0.166839, lr: 0.01000 #> Loss at epoch 46: 0.132563, lr: 0.01000 #> Loss at epoch 47: 0.130921, lr: 0.01000 #> Loss at epoch 48: 0.133465, lr: 0.01000 #> Loss at epoch 49: 0.128637, lr: 0.01000 #> Loss at epoch 50: 0.207680, lr: 0.01000 #> Loss at epoch 51: 0.172898, lr: 0.01000 #> Loss at epoch 52: 0.256572, lr: 0.01000 #> Loss at epoch 53: 0.126001, lr: 0.01000 #> Loss at epoch 54: 0.204715, lr: 0.01000 #> Loss at epoch 55: 0.130464, lr: 0.01000 #> Loss at epoch 56: 0.125086, lr: 0.01000 #> Loss at epoch 57: 0.194425, lr: 0.01000 #> Loss at epoch 58: 0.174518, lr: 0.01000 #> Loss at epoch 59: 0.135576, lr: 0.01000 #> Loss at epoch 60: 0.145873, lr: 0.01000 #> Loss at epoch 61: 0.173474, lr: 0.01000 #> Loss at epoch 62: 0.115937, lr: 0.01000 #> Loss at epoch 63: 0.294653, lr: 0.01000 #> Loss at epoch 64: 0.153009, lr: 0.01000 # }"},{"path":"/reference/conv.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Convolutional Layer for a CNN Architecture — conv","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"function creates conv layer object class citolayer use constructing Convolutional Neural Network (CNN) architecture. resulting layer object can passed create_architecture function define structure network.","code":""},{"path":"/reference/conv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"","code":"conv(   n_kernels = NULL,   kernel_size = NULL,   stride = NULL,   padding = NULL,   dilation = NULL,   bias = NULL,   activation = NULL,   normalization = NULL,   dropout = NULL )"},{"path":"/reference/conv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"n_kernels (integer) number kernels (filters) layer. kernel_size (integer tuple) size kernels layer. Use tuple kernel size different dimension. stride (integer tuple) stride kernels layer. NULL, stride set kernel size. Use tuple stride different dimension. padding (integer tuple) amount zero-padding added input sides. Use tuple padding different dimension. dilation (integer tuple) dilation kernels layer. Use tuple dilation different dimension. bias (boolean) TRUE, learnable bias added kernels layer. activation (character) activation function applied layer. Supported activation functions include \"relu\", \"leaky_relu\", \"tanh\", \"elu\", \"rrelu\", \"prelu\", \"softplus\", \"celu\", \"selu\", \"gelu\", \"relu6\", \"sigmoid\", \"softsign\", \"hardtanh\", \"tanhshrink\", \"softshrink\", \"hardshrink\", \"log_sigmoid\". normalization (boolean) TRUE, batch normalization applied layer. dropout (numeric) dropout rate layer. Set 0 disable dropout.","code":""},{"path":"/reference/conv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"S3 object class \"conv\" \"citolayer\", representing convolutional layer CNN architecture.","code":""},{"path":"/reference/conv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"function creates conv layer object, used define convolutional layer CNN architecture. Parameters specified (thus set NULL) filled default values provided create_architecture function.","code":""},{"path":[]},{"path":"/reference/conv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"Armin Schenk","code":""},{"path":"/reference/conv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Convolutional Layer for a CNN Architecture — conv","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # A convolutional layer where all available parameters are assigned # No value will be overwritten by 'create_architecture()' layer1 <- conv(10, 3, 1, 0, 1, TRUE, \"relu\", FALSE, 0.5)  # A convolutional layer where only the activation function is assigned # n_kernels, kernel_size, stride, padding, dilation, bias, # normalization and dropout are filled with the defaults # passed to the 'create_architecture()' function layer2 <- conv(activation=\"selu\") } # }"},{"path":"/reference/create_architecture.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a CNN Architecture — create_architecture","title":"Create a CNN Architecture — create_architecture","text":"function constructs citoarchitecture object defines architecture Convolutional Neural Network (CNN). citoarchitecture object can used cnn function specify structure network, including layer types, parameters, default values.","code":""},{"path":"/reference/create_architecture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a CNN Architecture — create_architecture","text":"","code":"create_architecture(   ...,   default_n_neurons = 10,   default_n_kernels = 10,   default_kernel_size = list(conv = 3, maxPool = 2, avgPool = 2),   default_stride = list(conv = 1, maxPool = NULL, avgPool = NULL),   default_padding = list(conv = 0, maxPool = 0, avgPool = 0),   default_dilation = list(conv = 1, maxPool = 1),   default_bias = list(conv = TRUE, linear = TRUE),   default_activation = list(conv = \"relu\", linear = \"relu\"),   default_normalization = list(conv = FALSE, linear = FALSE),   default_dropout = list(conv = 0, linear = 0) )"},{"path":"/reference/create_architecture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a CNN Architecture — create_architecture","text":"... Objects class citolayer created linear, conv, maxPool, avgPool, transfer. layers define architecture CNN. default_n_neurons (integer) Default number neurons linear layer. Default 10. default_n_kernels (integer) Default number kernels convolutional layer. Default 10. default_kernel_size (integer tuple) Default size kernels convolutional pooling layers. Can single integer tuple sizes differ across dimensions. Default list(conv = 3, maxPool = 2, avgPool = 2). default_stride (integer tuple) Default stride kernels convolutional pooling layers. Can single integer, tuple strides differ across dimensions, NULL use kernel size. Default list(conv = 1, maxPool = NULL, avgPool = NULL). default_padding (integer tuple) Default zero-padding added sides input. Can single integer tuple padding differs across dimensions. Default list(conv = 0, maxPool = 0, avgPool = 0). default_dilation (integer tuple) Default dilation kernels convolutional max pooling layers. Can single integer tuple dilation differs across dimensions. Default list(conv = 1, maxPool = 1). default_bias (boolean) Default value indicating learnable bias added neurons linear layers kernels convolutional layers. Default list(conv = TRUE, linear = TRUE). default_activation (character) Default activation function used linear convolutional layers. Supported activation functions include \"relu\", \"leaky_relu\", \"tanh\", \"elu\", \"rrelu\", \"prelu\", \"softplus\", \"celu\", \"selu\", \"gelu\", \"relu6\", \"sigmoid\", \"softsign\", \"hardtanh\", \"tanhshrink\", \"softshrink\", \"hardshrink\", \"log_sigmoid\". Default list(conv = \"relu\", linear = \"relu\"). default_normalization (boolean) Default value indicating batch normalization applied linear convolutional layers. Default list(conv = FALSE, linear = FALSE). default_dropout (numeric) Default dropout rate linear convolutional layers. Set 0 dropout. Default list(conv = 0.0, linear = 0.0).","code":""},{"path":"/reference/create_architecture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a CNN Architecture — create_architecture","text":"S3 object class \"citoarchitecture\" encapsulates architecture CNN.","code":""},{"path":"/reference/create_architecture.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a CNN Architecture — create_architecture","text":"function creates citoarchitecture object outlines CNN's architecture based provided layers default parameters. final architecture consists layers order provided. unspecified parameters citolayer objects filled provided default values respective layer types. Defaults can specified layer type individually layers .","code":""},{"path":[]},{"path":"/reference/create_architecture.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a CNN Architecture — create_architecture","text":"Armin Schenk","code":""},{"path":"/reference/create_architecture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a CNN Architecture — create_architecture","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Convolutional layers with different n_kernels and kernel_sizes c1 <- conv(n_kernels = 8, kernel_size = 5) c2 <- conv(n_kernels = 16, kernel_size = 3)  # Linear layer l <- linear(n_neurons = 100)  # MaxPooling layer mP <- maxPool(kernel_size = 2)  # Create the architecture by using the created layers # Change the defaults with which the not assigned layer parameters will be filled e.g. # change default dropout to different values for linear and convolutional layer # only change the default normalization for linear layers # change default activation of both linear and convolutional layers to 'selu' architecture <- create_architecture(c1, c1, mP, c2, c2, mP, l,                                     default_dropout = list(linear=0.6, conv=0.4),                                     default_normalization = list(linear=TRUE),                                     default_activation = \"selu\")  # See how the finished CNN would look like for specific input and output shapes print(architecture, c(3,128,128), 10)  # To use predefined architectures  use the transfer() layer alexnet <- transfer(\"alexnet\")  # No other linear layers are used after the transfer layer: # The cnn() function will only replace the last linear layer of the architecture # to match the output dimensions of the data architecture <- create_architecture(alexnet) print(architecture, c(3,128,128), 10)  # Some linear layers are used after the transfer layer: # The cnn() function will replace the whole \"classifier\" part of the architecture # with the specified linear layers + an output layer that matches the output dimensions architecture <- create_architecture(alexnet, linear(300), linear(100)) print(architecture, c(3,128,128), 10) } #> ------------------------------------------------------------------------------- #> Convolution|Input: 3x128x128 #>            |Output: 8x124x124 #>            |Kernel: 5x5 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> Convolution|Input: 8x124x124 #>            |Output: 8x120x120 #>            |Kernel: 5x5 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> MaxPool    |Input: 8x120x120 #>            |Output: 8x60x60 #>            |Kernel: 2x2 (stride=2x2, padding=0x0, dilation=1x1) #> ------------------------------------------------------------------------------- #> Convolution|Input: 8x60x60 #>            |Output: 16x58x58 #>            |Kernel: 3x3 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> Convolution|Input: 16x58x58 #>            |Output: 16x56x56 #>            |Kernel: 3x3 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> MaxPool    |Input: 16x56x56 #>            |Output: 16x28x28 #>            |Kernel: 2x2 (stride=2x2, padding=0x0, dilation=1x1) #> ------------------------------------------------------------------------------- #> Linear     |Input: 12544 #>            |Output: 100 #>            |Bias: TRUE #>            |Batch normalization #>            |Activation: selu #>            |Dropout: rate=0.6 #> ------------------------------------------------------------------------------- #> Linear     |Input: 100 #>            |Output: 10 #>            |Bias: TRUE #>            |Activation: Depends on loss #> ------------------------------------------------------------------------------- #> ------------------------------------------------------------------------------- #> Transfer   |Input: 3x128x128 #>            |Output: 256x6x6 #>            |Network: alexnet #>            |Pretrained: TRUE #>            |Weights frozen: TRUE #> ------------------------------------------------------------------------------- #> Linear     |Input: 9216 #>            |Output: 10 #>            |Bias: TRUE #>            |Activation: Depends on loss #> ------------------------------------------------------------------------------- #> ------------------------------------------------------------------------------- #> Transfer   |Input: 3x128x128 #>            |Output: 256x6x6 #>            |Network: alexnet #>            |Pretrained: TRUE #>            |Weights frozen: TRUE #> ------------------------------------------------------------------------------- #> Linear     |Input: 9216 #>            |Output: 300 #>            |Bias: TRUE #>            |Activation: relu #> ------------------------------------------------------------------------------- #> Linear     |Input: 300 #>            |Output: 100 #>            |Bias: TRUE #>            |Activation: relu #> ------------------------------------------------------------------------------- #> Linear     |Input: 100 #>            |Output: 10 #>            |Bias: TRUE #>            |Activation: Depends on loss #> ------------------------------------------------------------------------------- # }"},{"path":"/reference/dnn.html","id":null,"dir":"Reference","previous_headings":"","what":"DNN — dnn","title":"DNN — dnn","text":"fits custom deep neural network using Multilayer Perceptron architecture. dnn() supports formula syntax allows customize neural network maximal degree.","code":""},{"path":"/reference/dnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DNN — dnn","text":"","code":"dnn(   formula = NULL,   data = NULL,   hidden = c(50L, 50L),   activation = \"selu\",   bias = TRUE,   dropout = 0,   loss = c(\"mse\", \"mae\", \"softmax\", \"cross-entropy\", \"gaussian\", \"binomial\", \"poisson\",     \"mvp\", \"nbinom\", \"multinomial\", \"clogit\"),   validation = 0,   lambda = 0,   alpha = 0.5,   optimizer = c(\"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", \"rprop\"),   lr = 0.01,   batchsize = NULL,   burnin = Inf,   baseloss = NULL,   shuffle = TRUE,   epochs = 100,   bootstrap = NULL,   bootstrap_parallel = FALSE,   plot = TRUE,   verbose = TRUE,   lr_scheduler = NULL,   custom_parameters = NULL,   device = c(\"cpu\", \"cuda\", \"mps\"),   early_stopping = FALSE,   tuning = config_tuning(),   hooks = NULL,   X = NULL,   Y = NULL )"},{"path":"/reference/dnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DNN — dnn","text":"formula object class \"formula\": description model fitted data matrix data.frame features/predictors response variable hidden hidden units layers, length hidden corresponds number layers activation activation functions, can length one, vector different activation functions layer bias whether use biases layers, can length one, vector (number hidden layers + 1 (last layer)) logicals layer. dropout dropout rate, probability node getting left training (see nn_dropout) loss loss network optimized. Can also distribution stats package function, see details validation percentage data set taken validation set (chosen randomly) lambda strength regularization: lambda penalty, \\(\\lambda * (L1 + L2)\\) (see alpha) alpha add L1/L2 regularization training  \\((1 - \\alpha) * |weights| + \\alpha ||weights||^2\\) get added layer. Must 0 1 optimizer optimizer used training network, adjustments optimizer see config_optimizer lr learning rate given optimizer batchsize number samples used calculate one learning rate step, default 10% training data burnin training aborted trainings loss baseline loss burnin epochs baseloss baseloss, null baseloss corresponds intercept models shuffle TRUE, data batch gets reshuffled every epoch epochs epochs training goes bootstrap bootstrap neural network , numeric corresponds number bootstrap samples bootstrap_parallel parallelize (CPU) bootstrapping plot plot training loss verbose print training validation loss epochs lr_scheduler learning rate scheduler created config_lr_scheduler custom_parameters List parameters/variables optimized. Can used custom loss function. See Vignette example. device device network trained . mps correspond M1/M2 GPU devices. early_stopping set integer, training stop loss gotten higher defined number epochs row, use validation loss available. tuning tuning options created config_tuning X Feature matrix data.frame, alternative data interface Y Response vector, factor, matrix data.frame, alternative data interface","code":""},{"path":"/reference/dnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DNN — dnn","text":"S3 object class \"citodnn\" returned. list containing everything know model training process. list consists following attributes: net object class \"nn_sequential\" \"nn_module\", originates torch package represents core object workflow. call original function call loss list contains relevant information target variable used loss function data Contains data used training model weights List weights training epoch use_model_epoch Integer, defines model training epoch used prediction. 1 = best model, 2 = last model loaded_model_epoch Integer, shows model epoch loaded currently model$net. model_properties list properties neural network, contains number input nodes, number output nodes, size hidden layers, activation functions, whether bias included dropout layers included. training_properties list training parameters used last time model trained. consists learning rate, information learning rate scheduler, information optimizer, number epochs, whether early stopping used, plot active, lambda alpha L1/L2 regularization, batchsize, shuffle, data set split validation training, formula used training epoch training stop. losses data.frame containing training validation losses epoch","code":""},{"path":"/reference/dnn.html","id":"activation-functions","dir":"Reference","previous_headings":"","what":"Activation functions","title":"DNN — dnn","text":"Supported activation functions:  \"relu\", \"leaky_relu\", \"tanh\", \"elu\", \"rrelu\", \"prelu\", \"softplus\", \"celu\", \"selu\", \"gelu\", \"relu6\", \"sigmoid\", \"softsign\", \"hardtanh\", \"tanhshrink\", \"softshrink\", \"hardshrink\", \"log_sigmoid\"","code":""},{"path":"/reference/dnn.html","id":"loss-functions-likelihoods","dir":"Reference","previous_headings":"","what":"Loss functions / Likelihoods","title":"DNN — dnn","text":"support loss functions likelihoods different tasks:","code":""},{"path":"/reference/dnn.html","id":"training-and-convergence-of-neural-networks","dir":"Reference","previous_headings":"","what":"Training and convergence of neural networks","title":"DNN — dnn","text":"Ensuring convergence can tricky training neural networks. training sensitive combination learning rate (much weights updated optimization step), batch size (random subset data used optimization step), number epochs (number optimization steps). Typically, learning rate decreased size neural networks (depth network width hidden layers). provide baseline loss (intercept model) can give hints appropriate learning rate:  training loss model fall baseline loss, learning rate either high low. happens, try higher lower learning rates. common strategy try (manually) different learning rates see learning rate right scale. See troubleshooting vignette (vignette(\"B-Training_neural_networks\")) help training debugging neural networks.","code":""},{"path":"/reference/dnn.html","id":"finding-the-right-architecture","dir":"Reference","previous_headings":"","what":"Finding the right architecture","title":"DNN — dnn","text":"learning rate, definitive guide choosing right architecture right task. However, general rules/recommendations: general, wider, deeper neural networks can improve generalization - double-edged sword also increases risk overfitting. , increase width depth network, also add regularization (e.g., increasing lambda parameter, corresponds regularization strength). Furthermore, Pichler & Hartig, 2023, investigated effects hyperparameters prediction performance function data size. example, found selu activation function outperforms relu small data sizes (<100 observations). recommend starting moderate sizes (like defaults), model generalize/converge, try larger networks along regularization helps minimize risk overfitting (see vignette(\"B-Training_neural_networks\") ).","code":""},{"path":"/reference/dnn.html","id":"overfitting","dir":"Reference","previous_headings":"","what":"Overfitting","title":"DNN — dnn","text":"Overfitting means model fits training data well, generalizes poorly new observations. can use validation argument detect overfitting. validation loss starts increase certain point, often means models starting overfit training data:  Solutions: Re-train epochs = point model started overfit Early stopping, stop training model starts overfit, can specified using early_stopping=… argument Use regularization (dropout elastic-net, see next section)","code":""},{"path":"/reference/dnn.html","id":"regularization","dir":"Reference","previous_headings":"","what":"Regularization","title":"DNN — dnn","text":"Elastic Net regularization combines strengths L1 (Lasso) L2 (Ridge) regularization. introduces penalty term encourages sparse weight values maintaining overall weight shrinkage. controlling sparsity learned model, Elastic Net regularization helps avoid overfitting allowing meaningful feature selection. advise using elastic net (e.g. lambda = 0.001 alpha = 0.2). Dropout regularization helps prevent overfitting randomly disabling portion neurons training. technique encourages network learn robust generalized representations, prevents individual neurons relying heavily specific input patterns. Dropout widely adopted simple yet effective regularization method deep learning. utilizing regularization methods neural network training cito package, can improve generalization performance enhance network's ability handle unseen data. techniques act valuable tools mitigating overfitting promoting robust reliable model performance.","code":""},{"path":"/reference/dnn.html","id":"uncertainty","dir":"Reference","previous_headings":"","what":"Uncertainty","title":"DNN — dnn","text":"can use bootstrapping generate uncertainties outputs. Bootstrapping can enabled setting bootstrap = ... number bootstrap samples used. Note, however, computational cost can excessive. cases may worthwhile parallelize bootstrapping, example GPU neural network small. Parallelization bootstrapping can enabled setting bootstrap_parallel = ... argument desired number calls run parallel.","code":""},{"path":"/reference/dnn.html","id":"custom-optimizer-and-learning-rate-schedulers","dir":"Reference","previous_headings":"","what":"Custom Optimizer and Learning Rate Schedulers","title":"DNN — dnn","text":"training network, flexibility customize optimizer settings learning rate scheduler optimize learning process. cito package, can initialize configurations using config_lr_scheduler config_optimizer functions. config_lr_scheduler allows define specific learning rate scheduler controls learning rate changes time training. beneficial scenarios want adaptively adjust learning rate improve convergence avoid getting stuck local optima. Similarly, config_optimizer function enables specify optimizer network. Different optimizers, stochastic gradient descent (SGD), Adam, RMSprop, offer various strategies updating network's weights biases training. Choosing right optimizer can significantly impact training process final performance neural network.","code":""},{"path":"/reference/dnn.html","id":"hyperparameter-tuning","dir":"Reference","previous_headings":"","what":"Hyperparameter tuning","title":"DNN — dnn","text":"implemented experimental support hyperparameter tuning. can mark hyperparameters tuned cito setting values tune(), example dnn (..., lr = tune(). tune() function creates range random values given hyperparameter. can change maximum minimum range potential hyperparameters pass custom values tune(values = c(....)) function. following table lists hyperparameters can currently tuned: hyperparameters tuned random search (.e., random values hyperparameters within specified range) cross-validation. exact tuning regime can specified config_tuning. Note hyperparameter tuning can expensive. implemented option parallelize hyperparameter tuning, including parallelization one GPUs (hyperparameter evaluation parallelized, CV). can especially useful small models. example, 4 GPUs, 20 CPU cores, 20 steps (random samples random search), run dnn(..., device=\"cuda\",lr = tune(), batchsize=tune(), tuning=config_tuning(parallel=20, NGPU=4), distribute 20 model fits across 4 GPUs, GPU process 5 models (parallel). experimental feature, welcome feature requests bug reports github site. custom values, hyperparameters except hidden layers require vector values. Hidden layers expect two-column matrix first column number hidden nodes second column corresponds number hidden layers.","code":""},{"path":"/reference/dnn.html","id":"how-neural-networks-work","dir":"Reference","previous_headings":"","what":"How neural networks work","title":"DNN — dnn","text":"Multilayer Perceptron (MLP) networks, neuron connected every neuron previous layer every neuron subsequent layer. value neuron computed using weighted sum outputs previous layer, followed application activation function. Specifically, value neuron calculated weighted sum outputs neurons previous layer, combined bias term. sum passed activation function, introduces non-linearity network. calculated value neuron becomes input neurons next layer, process continues output layer reached. choice activation function specific weight values determine network's ability learn approximate complex relationships inputs outputs. Therefore value neuron can calculated using: \\( (\\sum_j{ w_j * a_j})\\). \\(w_j\\) weight \\(a_j\\) value neuron j current one. () activation function, e.g. \\( relu(x) = max(0,x)\\)","code":""},{"path":"/reference/dnn.html","id":"training-on-graphic-cards","dir":"Reference","previous_headings":"","what":"Training on graphic cards","title":"DNN — dnn","text":"NVIDIA CUDA-enabled device installed CUDA toolkit version 11.3 cuDNN 8.4, can take advantage GPU acceleration training neural networks. crucial specific versions installed, versions may compatible. detailed installation instructions information utilizing GPUs training, please refer mlverse: 'torch' documentation. Note: GPU training optional, package can still used training CPU even without CUDA cuDNN installations.","code":""},{"path":[]},{"path":"/reference/dnn.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"DNN — dnn","text":"Christian Amesoeder, Maximilian Pichler","code":""},{"path":"/reference/dnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DNN — dnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Example workflow in cito  ## Build and train  Network ### softmax is used for multi-class responses (e.g., Species) nn.fit<- dnn(Species~., data = datasets::iris, loss = \"softmax\")  ## The training loss is below the baseline loss but at the end of the ## training the loss was still decreasing, so continue training for another 50 ## epochs nn.fit <- continue_training(nn.fit, epochs = 50L)  # Sturcture of Neural Network print(nn.fit)  # Plot Neural Network plot(nn.fit) ## 4 Input nodes (first layer) because of 4 features ## 3 Output nodes (last layer) because of 3 response species (one node for each ## level in the response variable). ## The layers between the input and output layer are called hidden layers (two ## of them)  ## We now want to understand how the predictions are made, what are the ## important features? The summary function automatically calculates feature ## importance (the interpretation is similar to an anova) and calculates ## average conditional effects that are similar to linear effects: summary(nn.fit)  ## To visualize the effect (response-feature effect), we can use the ALE and ## PDP functions  # Partial dependencies PDP(nn.fit, variable = \"Petal.Length\")  # Accumulated local effect plots ALE(nn.fit, variable = \"Petal.Length\")    # Per se, it is difficult to get confidence intervals for our xAI metrics (or # for the predictions). But we can use bootstrapping to obtain uncertainties # for all cito outputs: ## Re-fit the neural network with bootstrapping nn.fit<- dnn(Species~.,              data = datasets::iris,              loss = \"softmax\",              epochs = 150L,              verbose = FALSE,              bootstrap = 20L) ## convergence can be tested via the analyze_training function analyze_training(nn.fit)  ## Summary for xAI metrics (can take some time): summary(nn.fit) ## Now with standard errors and p-values ## Note: Take the p-values with a grain of salt! We do not know yet if they are ## correct (e.g. if you use regularization, they are likely conservative == too ## large)  ## Predictions with bootstrapping: dim(predict(nn.fit)) ## predictions are by default averaged (over the bootstrap samples)  ## Multinomial and conditional logit regression m = dnn(Species~., data = iris, loss = \"clogit\", lr = 0.01) m = dnn(Species~., data = iris, loss = \"multinomial\", lr = 0.01)  Y = t(stats::rmultinom(100, 10, prob = c(0.2, 0.2, 0.5))) m = dnn(cbind(X1, X2, X3)~., data = data.frame(Y, A = as.factor(runif(100))), loss = \"multinomial\", lr = 0.01) ## conditional logit for size > 1 is not supported yet   # Hyperparameter tuning (experimental feature) hidden_values = matrix(c(5, 2,                          4, 2,                          10,2,                          15,2), 4, 2, byrow = TRUE) ## Potential architectures we want to test, first column == number of nodes print(hidden_values)  nn.fit = dnn(Species~.,              data = iris,              epochs = 30L,              loss = \"softmax\",              hidden = tune(values = hidden_values),              lr = tune(0.00001, 0.1) # tune lr between range 0.00001 and 0.1              ) ## Tuning results: print(nn.fit$tuning)  # test = Inf means that tuning was cancelled after only one fit (within the CV)   # Advanced: Custom loss functions and additional parameters ## Normal Likelihood with sd parameter: custom_loss = function(pred, true) {   logLik = torch::distr_normal(pred,                                scale = torch::nnf_relu(scale)+                                  0.001)$log_prob(true)   return(-logLik$mean()) }  nn.fit<- dnn(Sepal.Length~.,              data = datasets::iris,              loss = custom_loss,              verbose = FALSE,              custom_parameters = list(scale = 1.0) ) nn.fit$parameter$scale  ## Multivariate normal likelihood with parametrized covariance matrix ## Sigma = L*L^t + D ## Helper function to build covariance matrix create_cov = function(LU, Diag) {   return(torch::torch_matmul(LU, LU$t()) + torch::torch_diag(Diag$exp()+0.01)) }  custom_loss_MVN = function(true, pred) {   Sigma = create_cov(SigmaPar, SigmaDiag)   logLik = torch::distr_multivariate_normal(pred,                                             covariance_matrix = Sigma)$     log_prob(true)   return(-logLik$mean()) }   nn.fit<- dnn(cbind(Sepal.Length, Sepal.Width, Petal.Length)~.,              data = datasets::iris,              lr = 0.01,              verbose = FALSE,              loss = custom_loss_MVN,              custom_parameters =                list(SigmaDiag =  rep(0, 3),                     SigmaPar = matrix(rnorm(6, sd = 0.001), 3, 2)) ) as.matrix(create_cov(nn.fit$loss$parameter$SigmaPar,                      nn.fit$loss$parameter$SigmaDiag))  } #> Loss at epoch 1: 1.122883, lr: 0.01000  #> Loss at epoch 2: 0.939408, lr: 0.01000 #> Loss at epoch 3: 0.805962, lr: 0.01000 #> Loss at epoch 4: 0.700783, lr: 0.01000 #> Loss at epoch 5: 0.635470, lr: 0.01000 #> Loss at epoch 6: 0.570248, lr: 0.01000 #> Loss at epoch 7: 0.520989, lr: 0.01000 #> Loss at epoch 8: 0.491538, lr: 0.01000 #> Loss at epoch 9: 0.470051, lr: 0.01000 #> Loss at epoch 10: 0.434126, lr: 0.01000 #> Loss at epoch 11: 0.404641, lr: 0.01000 #> Loss at epoch 12: 0.382035, lr: 0.01000 #> Loss at epoch 13: 0.363658, lr: 0.01000 #> Loss at epoch 14: 0.348712, lr: 0.01000 #> Loss at epoch 15: 0.325178, lr: 0.01000 #> Loss at epoch 16: 0.316422, lr: 0.01000 #> Loss at epoch 17: 0.294118, lr: 0.01000 #> Loss at epoch 18: 0.300825, lr: 0.01000 #> Loss at epoch 19: 0.273868, lr: 0.01000 #> Loss at epoch 20: 0.268420, lr: 0.01000 #> Loss at epoch 21: 0.258743, lr: 0.01000 #> Loss at epoch 22: 0.251251, lr: 0.01000 #> Loss at epoch 23: 0.241765, lr: 0.01000 #> Loss at epoch 24: 0.224810, lr: 0.01000 #> Loss at epoch 25: 0.215337, lr: 0.01000 #> Loss at epoch 26: 0.214214, lr: 0.01000 #> Loss at epoch 27: 0.215144, lr: 0.01000 #> Loss at epoch 28: 0.200791, lr: 0.01000 #> Loss at epoch 29: 0.191077, lr: 0.01000 #> Loss at epoch 30: 0.180039, lr: 0.01000 #> Loss at epoch 31: 0.191212, lr: 0.01000 #> Loss at epoch 32: 0.180171, lr: 0.01000 #> Loss at epoch 33: 0.166964, lr: 0.01000 #> Loss at epoch 34: 0.176963, lr: 0.01000 #> Loss at epoch 35: 0.159958, lr: 0.01000 #> Loss at epoch 36: 0.171904, lr: 0.01000 #> Loss at epoch 37: 0.162911, lr: 0.01000 #> Loss at epoch 38: 0.143172, lr: 0.01000 #> Loss at epoch 39: 0.144486, lr: 0.01000 #> Loss at epoch 40: 0.147660, lr: 0.01000 #> Loss at epoch 41: 0.140176, lr: 0.01000 #> Loss at epoch 42: 0.145586, lr: 0.01000 #> Loss at epoch 43: 0.137137, lr: 0.01000 #> Loss at epoch 44: 0.128878, lr: 0.01000 #> Loss at epoch 45: 0.131917, lr: 0.01000 #> Loss at epoch 46: 0.126327, lr: 0.01000 #> Loss at epoch 47: 0.128138, lr: 0.01000 #> Loss at epoch 48: 0.123225, lr: 0.01000 #> Loss at epoch 49: 0.123541, lr: 0.01000 #> Loss at epoch 50: 0.115989, lr: 0.01000 #> Loss at epoch 51: 0.132032, lr: 0.01000 #> Loss at epoch 52: 0.119388, lr: 0.01000 #> Loss at epoch 53: 0.111416, lr: 0.01000 #> Loss at epoch 54: 0.117665, lr: 0.01000 #> Loss at epoch 55: 0.106307, lr: 0.01000 #> Loss at epoch 56: 0.124540, lr: 0.01000 #> Loss at epoch 57: 0.118285, lr: 0.01000 #> Loss at epoch 58: 0.111521, lr: 0.01000 #> Loss at epoch 59: 0.100682, lr: 0.01000 #> Loss at epoch 60: 0.106777, lr: 0.01000 #> Loss at epoch 61: 0.104414, lr: 0.01000 #> Loss at epoch 62: 0.098554, lr: 0.01000 #> Loss at epoch 63: 0.106682, lr: 0.01000 #> Loss at epoch 64: 0.102592, lr: 0.01000 #> Loss at epoch 65: 0.103393, lr: 0.01000 #> Loss at epoch 66: 0.094509, lr: 0.01000 #> Loss at epoch 67: 0.101544, lr: 0.01000 #> Loss at epoch 68: 0.089308, lr: 0.01000 #> Loss at epoch 69: 0.086096, lr: 0.01000 #> Loss at epoch 70: 0.090955, lr: 0.01000 #> Loss at epoch 71: 0.101453, lr: 0.01000 #> Loss at epoch 72: 0.090777, lr: 0.01000 #> Loss at epoch 73: 0.096065, lr: 0.01000 #> Loss at epoch 74: 0.087671, lr: 0.01000 #> Loss at epoch 75: 0.085364, lr: 0.01000 #> Loss at epoch 76: 0.092898, lr: 0.01000 #> Loss at epoch 77: 0.099216, lr: 0.01000 #> Loss at epoch 78: 0.113096, lr: 0.01000 #> Loss at epoch 79: 0.087467, lr: 0.01000 #> Loss at epoch 80: 0.110578, lr: 0.01000 #> Loss at epoch 81: 0.097965, lr: 0.01000 #> Loss at epoch 82: 0.086167, lr: 0.01000 #> Loss at epoch 83: 0.104936, lr: 0.01000 #> Loss at epoch 84: 0.083683, lr: 0.01000 #> Loss at epoch 85: 0.092008, lr: 0.01000 #> Loss at epoch 86: 0.079450, lr: 0.01000 #> Loss at epoch 87: 0.160431, lr: 0.01000 #> Loss at epoch 88: 0.159892, lr: 0.01000 #> Loss at epoch 89: 0.083055, lr: 0.01000 #> Loss at epoch 90: 0.080187, lr: 0.01000 #> Loss at epoch 91: 0.089905, lr: 0.01000 #> Loss at epoch 92: 0.069938, lr: 0.01000 #> Loss at epoch 93: 0.103553, lr: 0.01000 #> Loss at epoch 94: 0.075622, lr: 0.01000 #> Loss at epoch 95: 0.081060, lr: 0.01000 #> Loss at epoch 96: 0.080786, lr: 0.01000 #> Loss at epoch 97: 0.079348, lr: 0.01000 #> Loss at epoch 98: 0.086677, lr: 0.01000 #> Loss at epoch 99: 0.081812, lr: 0.01000 #> Loss at epoch 100: 0.091377, lr: 0.01000 #> Loss at epoch 101: 0.074764, lr: 0.01000  #> Loss at epoch 102: 0.067267, lr: 0.01000 #> Loss at epoch 103: 0.103423, lr: 0.01000 #> Loss at epoch 104: 0.092478, lr: 0.01000 #> Loss at epoch 105: 0.081089, lr: 0.01000 #> Loss at epoch 106: 0.064284, lr: 0.01000 #> Loss at epoch 107: 0.068101, lr: 0.01000 #> Loss at epoch 108: 0.072496, lr: 0.01000 #> Loss at epoch 109: 0.071757, lr: 0.01000 #> Loss at epoch 110: 0.077805, lr: 0.01000 #> Loss at epoch 111: 0.076026, lr: 0.01000 #> Loss at epoch 112: 0.069836, lr: 0.01000 #> Loss at epoch 113: 0.081460, lr: 0.01000 #> Loss at epoch 114: 0.066927, lr: 0.01000 #> Loss at epoch 115: 0.076848, lr: 0.01000 #> Loss at epoch 116: 0.064451, lr: 0.01000 #> Loss at epoch 117: 0.068426, lr: 0.01000 #> Loss at epoch 118: 0.075841, lr: 0.01000 #> Loss at epoch 119: 0.072744, lr: 0.01000 #> Loss at epoch 120: 0.086062, lr: 0.01000 #> Loss at epoch 121: 0.074982, lr: 0.01000 #> Loss at epoch 122: 0.075559, lr: 0.01000 #> Loss at epoch 123: 0.063803, lr: 0.01000 #> Loss at epoch 124: 0.077047, lr: 0.01000 #> Loss at epoch 125: 0.085156, lr: 0.01000 #> Loss at epoch 126: 0.071627, lr: 0.01000 #> Loss at epoch 127: 0.076577, lr: 0.01000 #> Loss at epoch 128: 0.073260, lr: 0.01000 #> Loss at epoch 129: 0.080519, lr: 0.01000 #> Loss at epoch 130: 0.068600, lr: 0.01000 #> Loss at epoch 131: 0.071613, lr: 0.01000 #> Loss at epoch 132: 0.090010, lr: 0.01000 #> Loss at epoch 133: 0.075034, lr: 0.01000 #> Loss at epoch 134: 0.065622, lr: 0.01000 #> Loss at epoch 135: 0.065883, lr: 0.01000 #> Loss at epoch 136: 0.066783, lr: 0.01000 #> Loss at epoch 137: 0.063999, lr: 0.01000 #> Loss at epoch 138: 0.075011, lr: 0.01000 #> Loss at epoch 139: 0.073635, lr: 0.01000 #> Loss at epoch 140: 0.086393, lr: 0.01000 #> Loss at epoch 141: 0.088661, lr: 0.01000 #> Loss at epoch 142: 0.080406, lr: 0.01000 #> Loss at epoch 143: 0.063072, lr: 0.01000 #> Loss at epoch 144: 0.072055, lr: 0.01000 #> Loss at epoch 145: 0.071915, lr: 0.01000 #> Loss at epoch 146: 0.074514, lr: 0.01000 #> Loss at epoch 147: 0.063698, lr: 0.01000 #> Loss at epoch 148: 0.069009, lr: 0.01000 #> Loss at epoch 149: 0.075835, lr: 0.01000 #> Loss at epoch 150: 0.065982, lr: 0.01000 #> dnn(formula = Species ~ Sepal.Length + Sepal.Width + Petal.Length +  #>     Petal.Width, data = datasets::iris, loss = \"softmax\") #> An `nn_module` containing 2,953 parameters. #>  #> ── Modules ───────────────────────────────────────────────────────────────────── #> • 0: <nn_linear> #250 parameters #> • 1: <nn_selu> #0 parameters #> • 2: <nn_linear> #2,550 parameters #> • 3: <nn_selu> #0 parameters #> • 4: <nn_linear> #153 parameters   #> Number of Neighborhoods reduced to 8 #> Number of Neighborhoods reduced to 8 #> Number of Neighborhoods reduced to 8  #> Loss at epoch 1: 0.601621, lr: 0.01000  #> Loss at epoch 2: 0.527020, lr: 0.01000 #> Loss at epoch 3: 0.482529, lr: 0.01000 #> Loss at epoch 4: 0.442351, lr: 0.01000 #> Loss at epoch 5: 0.416154, lr: 0.01000 #> Loss at epoch 6: 0.388134, lr: 0.01000 #> Loss at epoch 7: 0.366647, lr: 0.01000 #> Loss at epoch 8: 0.355607, lr: 0.01000 #> Loss at epoch 9: 0.336405, lr: 0.01000 #> Loss at epoch 10: 0.319753, lr: 0.01000 #> Loss at epoch 11: 0.308047, lr: 0.01000 #> Loss at epoch 12: 0.304148, lr: 0.01000 #> Loss at epoch 13: 0.286538, lr: 0.01000 #> Loss at epoch 14: 0.281094, lr: 0.01000 #> Loss at epoch 15: 0.265741, lr: 0.01000 #> Loss at epoch 16: 0.257500, lr: 0.01000 #> Loss at epoch 17: 0.247748, lr: 0.01000 #> Loss at epoch 18: 0.244144, lr: 0.01000 #> Loss at epoch 19: 0.236366, lr: 0.01000 #> Loss at epoch 20: 0.225660, lr: 0.01000 #> Loss at epoch 21: 0.220222, lr: 0.01000 #> Loss at epoch 22: 0.215510, lr: 0.01000 #> Loss at epoch 23: 0.208355, lr: 0.01000 #> Loss at epoch 24: 0.218105, lr: 0.01000 #> Loss at epoch 25: 0.196464, lr: 0.01000 #> Loss at epoch 26: 0.194430, lr: 0.01000 #> Loss at epoch 27: 0.181971, lr: 0.01000 #> Loss at epoch 28: 0.181993, lr: 0.01000 #> Loss at epoch 29: 0.178608, lr: 0.01000 #> Loss at epoch 30: 0.173065, lr: 0.01000 #> Loss at epoch 31: 0.167747, lr: 0.01000 #> Loss at epoch 32: 0.159985, lr: 0.01000 #> Loss at epoch 33: 0.158465, lr: 0.01000 #> Loss at epoch 34: 0.149841, lr: 0.01000 #> Loss at epoch 35: 0.146935, lr: 0.01000 #> Loss at epoch 36: 0.142092, lr: 0.01000 #> Loss at epoch 37: 0.139657, lr: 0.01000 #> Loss at epoch 38: 0.137810, lr: 0.01000 #> Loss at epoch 39: 0.131381, lr: 0.01000 #> Loss at epoch 40: 0.131064, lr: 0.01000 #> Loss at epoch 41: 0.123916, lr: 0.01000 #> Loss at epoch 42: 0.125249, lr: 0.01000 #> Loss at epoch 43: 0.120735, lr: 0.01000 #> Loss at epoch 44: 0.122068, lr: 0.01000 #> Loss at epoch 45: 0.116491, lr: 0.01000 #> Loss at epoch 46: 0.111433, lr: 0.01000 #> Loss at epoch 47: 0.114211, lr: 0.01000 #> Loss at epoch 48: 0.107359, lr: 0.01000 #> Loss at epoch 49: 0.107689, lr: 0.01000 #> Loss at epoch 50: 0.113173, lr: 0.01000 #> Loss at epoch 51: 0.103488, lr: 0.01000 #> Loss at epoch 52: 0.101193, lr: 0.01000 #> Loss at epoch 53: 0.098770, lr: 0.01000 #> Loss at epoch 54: 0.098003, lr: 0.01000 #> Loss at epoch 55: 0.093003, lr: 0.01000 #> Loss at epoch 56: 0.093533, lr: 0.01000 #> Loss at epoch 57: 0.091959, lr: 0.01000 #> Loss at epoch 58: 0.090286, lr: 0.01000 #> Loss at epoch 59: 0.084182, lr: 0.01000 #> Loss at epoch 60: 0.089599, lr: 0.01000 #> Loss at epoch 61: 0.088411, lr: 0.01000 #> Loss at epoch 62: 0.085659, lr: 0.01000 #> Loss at epoch 63: 0.086118, lr: 0.01000 #> Loss at epoch 64: 0.081835, lr: 0.01000 #> Loss at epoch 65: 0.086713, lr: 0.01000 #> Loss at epoch 66: 0.080826, lr: 0.01000 #> Loss at epoch 67: 0.078375, lr: 0.01000 #> Loss at epoch 68: 0.073323, lr: 0.01000 #> Loss at epoch 69: 0.076566, lr: 0.01000 #> Loss at epoch 70: 0.074961, lr: 0.01000 #> Loss at epoch 71: 0.078304, lr: 0.01000 #> Loss at epoch 72: 0.077540, lr: 0.01000 #> Loss at epoch 73: 0.079322, lr: 0.01000 #> Loss at epoch 74: 0.073114, lr: 0.01000 #> Loss at epoch 75: 0.072321, lr: 0.01000 #> Loss at epoch 76: 0.070515, lr: 0.01000 #> Loss at epoch 77: 0.068053, lr: 0.01000 #> Loss at epoch 78: 0.071502, lr: 0.01000 #> Loss at epoch 79: 0.069582, lr: 0.01000 #> Loss at epoch 80: 0.069650, lr: 0.01000 #> Loss at epoch 81: 0.069487, lr: 0.01000 #> Loss at epoch 82: 0.068888, lr: 0.01000 #> Loss at epoch 83: 0.068813, lr: 0.01000 #> Loss at epoch 84: 0.064974, lr: 0.01000 #> Loss at epoch 85: 0.065338, lr: 0.01000 #> Loss at epoch 86: 0.066665, lr: 0.01000 #> Loss at epoch 87: 0.065803, lr: 0.01000 #> Loss at epoch 88: 0.061202, lr: 0.01000 #> Loss at epoch 89: 0.062329, lr: 0.01000 #> Loss at epoch 90: 0.064357, lr: 0.01000 #> Loss at epoch 91: 0.062041, lr: 0.01000 #> Loss at epoch 92: 0.059282, lr: 0.01000 #> Loss at epoch 93: 0.063019, lr: 0.01000 #> Loss at epoch 94: 0.062858, lr: 0.01000 #> Loss at epoch 95: 0.062765, lr: 0.01000 #> Loss at epoch 96: 0.058870, lr: 0.01000 #> Loss at epoch 97: 0.057647, lr: 0.01000 #> Loss at epoch 98: 0.063779, lr: 0.01000 #> Loss at epoch 99: 0.068420, lr: 0.01000 #> Loss at epoch 100: 0.059893, lr: 0.01000 #> Loss at epoch 1: 1.049376, lr: 0.01000  #> Loss at epoch 2: 0.854018, lr: 0.01000 #> Loss at epoch 3: 0.760081, lr: 0.01000 #> Loss at epoch 4: 0.680631, lr: 0.01000 #> Loss at epoch 5: 0.603664, lr: 0.01000 #> Loss at epoch 6: 0.571285, lr: 0.01000 #> Loss at epoch 7: 0.522103, lr: 0.01000 #> Loss at epoch 8: 0.492490, lr: 0.01000 #> Loss at epoch 9: 0.471385, lr: 0.01000 #> Loss at epoch 10: 0.447510, lr: 0.01000 #> Loss at epoch 11: 0.425259, lr: 0.01000 #> Loss at epoch 12: 0.400507, lr: 0.01000 #> Loss at epoch 13: 0.394950, lr: 0.01000 #> Loss at epoch 14: 0.368494, lr: 0.01000 #> Loss at epoch 15: 0.369700, lr: 0.01000 #> Loss at epoch 16: 0.350458, lr: 0.01000 #> Loss at epoch 17: 0.336985, lr: 0.01000 #> Loss at epoch 18: 0.323236, lr: 0.01000 #> Loss at epoch 19: 0.304475, lr: 0.01000 #> Loss at epoch 20: 0.290913, lr: 0.01000 #> Loss at epoch 21: 0.297108, lr: 0.01000 #> Loss at epoch 22: 0.280417, lr: 0.01000 #> Loss at epoch 23: 0.256421, lr: 0.01000 #> Loss at epoch 24: 0.244953, lr: 0.01000 #> Loss at epoch 25: 0.244835, lr: 0.01000 #> Loss at epoch 26: 0.232594, lr: 0.01000 #> Loss at epoch 27: 0.229202, lr: 0.01000 #> Loss at epoch 28: 0.214360, lr: 0.01000 #> Loss at epoch 29: 0.212492, lr: 0.01000 #> Loss at epoch 30: 0.219175, lr: 0.01000 #> Loss at epoch 31: 0.194153, lr: 0.01000 #> Loss at epoch 32: 0.194438, lr: 0.01000 #> Loss at epoch 33: 0.188413, lr: 0.01000 #> Loss at epoch 34: 0.191631, lr: 0.01000 #> Loss at epoch 35: 0.177538, lr: 0.01000 #> Loss at epoch 36: 0.166582, lr: 0.01000 #> Loss at epoch 37: 0.170072, lr: 0.01000 #> Loss at epoch 38: 0.193429, lr: 0.01000 #> Loss at epoch 39: 0.160113, lr: 0.01000 #> Loss at epoch 40: 0.153373, lr: 0.01000 #> Loss at epoch 41: 0.152776, lr: 0.01000 #> Loss at epoch 42: 0.157244, lr: 0.01000 #> Loss at epoch 43: 0.154730, lr: 0.01000 #> Loss at epoch 44: 0.157798, lr: 0.01000 #> Loss at epoch 45: 0.151893, lr: 0.01000 #> Loss at epoch 46: 0.137553, lr: 0.01000 #> Loss at epoch 47: 0.131623, lr: 0.01000 #> Loss at epoch 48: 0.140020, lr: 0.01000 #> Loss at epoch 49: 0.125532, lr: 0.01000 #> Loss at epoch 50: 0.145807, lr: 0.01000 #> Loss at epoch 51: 0.141335, lr: 0.01000 #> Loss at epoch 52: 0.119975, lr: 0.01000 #> Loss at epoch 53: 0.135336, lr: 0.01000 #> Loss at epoch 54: 0.124408, lr: 0.01000 #> Loss at epoch 55: 0.127828, lr: 0.01000 #> Loss at epoch 56: 0.117936, lr: 0.01000 #> Loss at epoch 57: 0.119951, lr: 0.01000 #> Loss at epoch 58: 0.113324, lr: 0.01000 #> Loss at epoch 59: 0.110688, lr: 0.01000 #> Loss at epoch 60: 0.113019, lr: 0.01000 #> Loss at epoch 61: 0.109198, lr: 0.01000 #> Loss at epoch 62: 0.115576, lr: 0.01000 #> Loss at epoch 63: 0.101509, lr: 0.01000 #> Loss at epoch 64: 0.106491, lr: 0.01000 #> Loss at epoch 65: 0.105197, lr: 0.01000 #> Loss at epoch 66: 0.099187, lr: 0.01000 #> Loss at epoch 67: 0.100820, lr: 0.01000 #> Loss at epoch 68: 0.103384, lr: 0.01000 #> Loss at epoch 69: 0.092852, lr: 0.01000 #> Loss at epoch 70: 0.103932, lr: 0.01000 #> Loss at epoch 71: 0.109047, lr: 0.01000 #> Loss at epoch 72: 0.092890, lr: 0.01000 #> Loss at epoch 73: 0.102648, lr: 0.01000 #> Loss at epoch 74: 0.115875, lr: 0.01000 #> Loss at epoch 75: 0.089873, lr: 0.01000 #> Loss at epoch 76: 0.092550, lr: 0.01000 #> Loss at epoch 77: 0.098603, lr: 0.01000 #> Loss at epoch 78: 0.090885, lr: 0.01000 #> Loss at epoch 79: 0.087177, lr: 0.01000 #> Loss at epoch 80: 0.115214, lr: 0.01000 #> Loss at epoch 81: 0.091414, lr: 0.01000 #> Loss at epoch 82: 0.106223, lr: 0.01000 #> Loss at epoch 83: 0.088888, lr: 0.01000 #> Loss at epoch 84: 0.081500, lr: 0.01000 #> Loss at epoch 85: 0.087106, lr: 0.01000 #> Loss at epoch 86: 0.090019, lr: 0.01000 #> Loss at epoch 87: 0.082456, lr: 0.01000 #> Loss at epoch 88: 0.085815, lr: 0.01000 #> Loss at epoch 89: 0.086994, lr: 0.01000 #> Loss at epoch 90: 0.084518, lr: 0.01000 #> Loss at epoch 91: 0.084101, lr: 0.01000 #> Loss at epoch 92: 0.095540, lr: 0.01000 #> Loss at epoch 93: 0.079930, lr: 0.01000 #> Loss at epoch 94: 0.102735, lr: 0.01000 #> Loss at epoch 95: 0.099556, lr: 0.01000 #> Loss at epoch 96: 0.093528, lr: 0.01000 #> Loss at epoch 97: 0.081843, lr: 0.01000 #> Loss at epoch 98: 0.089272, lr: 0.01000 #> Loss at epoch 99: 0.077286, lr: 0.01000 #> Loss at epoch 100: 0.091239, lr: 0.01000 #> Loss at epoch 1: 3.992303, lr: 0.01000  #> Loss at epoch 2: 3.443521, lr: 0.01000 #> Loss at epoch 3: 3.412122, lr: 0.01000 #> Loss at epoch 4: 3.403807, lr: 0.01000 #> Loss at epoch 5: 3.382572, lr: 0.01000 #> Loss at epoch 6: 3.379379, lr: 0.01000 #> Loss at epoch 7: 3.372216, lr: 0.01000 #> Loss at epoch 8: 3.363098, lr: 0.01000 #> Loss at epoch 9: 3.353826, lr: 0.01000 #> Loss at epoch 10: 3.347643, lr: 0.01000 #> Loss at epoch 11: 3.336297, lr: 0.01000 #> Loss at epoch 12: 3.323684, lr: 0.01000 #> Loss at epoch 13: 3.316515, lr: 0.01000 #> Loss at epoch 14: 3.306178, lr: 0.01000 #> Loss at epoch 15: 3.297047, lr: 0.01000 #> Loss at epoch 16: 3.288667, lr: 0.01000 #> Loss at epoch 17: 3.273517, lr: 0.01000 #> Loss at epoch 18: 3.255925, lr: 0.01000 #> Loss at epoch 19: 3.250206, lr: 0.01000 #> Loss at epoch 20: 3.223473, lr: 0.01000 #> Loss at epoch 21: 3.211311, lr: 0.01000 #> Loss at epoch 22: 3.198291, lr: 0.01000 #> Loss at epoch 23: 3.177080, lr: 0.01000 #> Loss at epoch 24: 3.159677, lr: 0.01000 #> Loss at epoch 25: 3.136800, lr: 0.01000 #> Loss at epoch 26: 3.117822, lr: 0.01000 #> Loss at epoch 27: 3.092546, lr: 0.01000 #> Loss at epoch 28: 3.069404, lr: 0.01000 #> Loss at epoch 29: 3.038474, lr: 0.01000 #> Loss at epoch 30: 3.015352, lr: 0.01000 #> Loss at epoch 31: 2.992323, lr: 0.01000 #> Loss at epoch 32: 2.963254, lr: 0.01000 #> Loss at epoch 33: 2.927048, lr: 0.01000 #> Loss at epoch 34: 2.912457, lr: 0.01000 #> Loss at epoch 35: 2.877573, lr: 0.01000 #> Loss at epoch 36: 2.849750, lr: 0.01000 #> Loss at epoch 37: 2.823297, lr: 0.01000 #> Loss at epoch 38: 2.798708, lr: 0.01000 #> Loss at epoch 39: 2.774173, lr: 0.01000 #> Loss at epoch 40: 2.755432, lr: 0.01000 #> Loss at epoch 41: 2.728382, lr: 0.01000 #> Loss at epoch 42: 2.703559, lr: 0.01000 #> Loss at epoch 43: 2.685270, lr: 0.01000 #> Loss at epoch 44: 2.675339, lr: 0.01000 #> Loss at epoch 45: 2.646701, lr: 0.01000 #> Loss at epoch 46: 2.633486, lr: 0.01000 #> Loss at epoch 47: 2.616056, lr: 0.01000 #> Loss at epoch 48: 2.596277, lr: 0.01000 #> Loss at epoch 49: 2.580026, lr: 0.01000 #> Loss at epoch 50: 2.566535, lr: 0.01000 #> Loss at epoch 51: 2.547462, lr: 0.01000 #> Loss at epoch 52: 2.533624, lr: 0.01000 #> Loss at epoch 53: 2.518617, lr: 0.01000 #> Loss at epoch 54: 2.495553, lr: 0.01000 #> Loss at epoch 55: 2.485435, lr: 0.01000 #> Loss at epoch 56: 2.477212, lr: 0.01000 #> Loss at epoch 57: 2.457061, lr: 0.01000 #> Loss at epoch 58: 2.439397, lr: 0.01000 #> Loss at epoch 59: 2.430008, lr: 0.01000 #> Loss at epoch 60: 2.418852, lr: 0.01000 #> Loss at epoch 61: 2.398282, lr: 0.01000 #> Loss at epoch 62: 2.387675, lr: 0.01000 #> Loss at epoch 63: 2.376007, lr: 0.01000 #> Loss at epoch 64: 2.363876, lr: 0.01000 #> Loss at epoch 65: 2.352631, lr: 0.01000 #> Loss at epoch 66: 2.341351, lr: 0.01000 #> Loss at epoch 67: 2.327733, lr: 0.01000 #> Loss at epoch 68: 2.324057, lr: 0.01000 #> Loss at epoch 69: 2.314050, lr: 0.01000 #> Loss at epoch 70: 2.300553, lr: 0.01000 #> Loss at epoch 71: 2.295034, lr: 0.01000 #> Loss at epoch 72: 2.285905, lr: 0.01000 #> Loss at epoch 73: 2.275905, lr: 0.01000 #> Loss at epoch 74: 2.269326, lr: 0.01000 #> Loss at epoch 75: 2.259049, lr: 0.01000 #> Loss at epoch 76: 2.254114, lr: 0.01000 #> Loss at epoch 77: 2.251495, lr: 0.01000 #> Loss at epoch 78: 2.246542, lr: 0.01000 #> Loss at epoch 79: 2.238564, lr: 0.01000 #> Loss at epoch 80: 2.233981, lr: 0.01000 #> Loss at epoch 81: 2.227862, lr: 0.01000 #> Loss at epoch 82: 2.225135, lr: 0.01000 #> Loss at epoch 83: 2.220459, lr: 0.01000 #> Loss at epoch 84: 2.215439, lr: 0.01000 #> Loss at epoch 85: 2.215550, lr: 0.01000 #> Loss at epoch 86: 2.210361, lr: 0.01000 #> Loss at epoch 87: 2.207266, lr: 0.01000 #> Loss at epoch 88: 2.203069, lr: 0.01000 #> Loss at epoch 89: 2.197910, lr: 0.01000 #> Loss at epoch 90: 2.195693, lr: 0.01000 #> Loss at epoch 91: 2.192172, lr: 0.01000 #> Loss at epoch 92: 2.190574, lr: 0.01000 #> Loss at epoch 93: 2.189275, lr: 0.01000 #> Loss at epoch 94: 2.184715, lr: 0.01000 #> Loss at epoch 95: 2.179309, lr: 0.01000 #> Loss at epoch 96: 2.181983, lr: 0.01000 #> Loss at epoch 97: 2.178058, lr: 0.01000 #> Loss at epoch 98: 2.174677, lr: 0.01000 #> Loss at epoch 99: 2.171290, lr: 0.01000 #> Loss at epoch 100: 2.177768, lr: 0.01000 #>      [,1] [,2] #> [1,]    5    2 #> [2,]    4    2 #> [3,]   10    2 #> [4,]   15    2 #> Starting hyperparameter tuning... #> Fitting final model... #> # A tibble: 10 × 6 #>    steps  test train models hidden        lr #>    <int> <dbl> <dbl> <lgl>  <list>     <dbl> #>  1     1  32.2     0 NA     <dbl [2]> 0.0173 #>  2     2  22.0     0 NA     <dbl [2]> 0.0588 #>  3     3  26.4     0 NA     <dbl [2]> 0.0719 #>  4     4  32.3     0 NA     <dbl [2]> 0.0990 #>  5     5  47.0     0 NA     <dbl [2]> 0.0443 #>  6     6  44.7     0 NA     <dbl [2]> 0.0341 #>  7     7  67.8     0 NA     <dbl [2]> 0.0373 #>  8     8  31.7     0 NA     <dbl [2]> 0.0268 #>  9     9  24.6     0 NA     <dbl [2]> 0.0820 #> 10    10  45.0     0 NA     <dbl [2]> 0.0414   #>            [,1]       [,2]       [,3] #> [1,] 0.32596233 0.04433576 0.07790677 #> [2,] 0.04433576 0.16945159 0.03192519 #> [3,] 0.07790677 0.03192519 0.22975661 # }"},{"path":"/reference/e.html","id":null,"dir":"Reference","previous_headings":"","what":"Embeddings — e","title":"Embeddings — e","text":"Can used create embedding structure categorical variables function interface","code":""},{"path":"/reference/e.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embeddings — e","text":"","code":"e(dim = 1L, weights = NULL, train = TRUE, lambda = 0, alpha = 1)"},{"path":"/reference/e.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embeddings — e","text":"dim integer, embedding dimension weights matrix, use custom embedding matrices train logical, embeddings trained lambda regularization strength embeddings alpha mix L1 L2 regularization","code":""},{"path":"/reference/e.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Embeddings — e","text":"e() structure must used function interface. Although document function signature, first argument e() structure categorical variable codes group data, predictors + e(group, ...) details, see example ","code":""},{"path":"/reference/e.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embeddings — e","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){  # The following example shows that groups with similar responses will cluster in embedding space set.seed(123)  n = 10000 # observations m = 100 # groups / individuals k = 10 # cluster of groups with the same behavior  dat = data.frame(f1 = runif(n),                  f2 = runif(n),                  f3 = runif(n),                  ind = rep(1:m, each = n/m),                  cluster = rep(1:k, each = n/k),                  response = NA)  slopes = matrix(runif(3*k, min = -10,max = 10), nrow = k, ncol = 3)  for(i in 1:k) dat$response[dat$cluster == i] =   as.matrix(dat[dat$cluster == i, 1:3]) %*% slopes[i,] + rnorm(n/k, sd = 0.2)  mod <- dnn(response~f1+f2+f3 + e(ind,dim = 2),            data = dat, epochs = 200L, optimizer = config_optimizer(\"adam\"))  embeddings = coef(mod)[[1]][[1]] # extract embeddings plot(embeddings, col = c(rep(1:k, each = m/k))) # plot clusters in embedding space abline(h = 0, lty = 2) abline(v = 0, lty = 2)  ace = conditionalEffects(mod) # extract conditional effects # now average conditional effects per cluster ind_ace =   sapply(1:m, function(ind) {     tmp = ace[[1]]$result[dat$ind==ind,,]     return(diag(apply(tmp, 2:3, mean)))   })  # to create biplot, multiply beta of each cluster with coordinates coord = ind_ace %*% embeddings/m arrows(x0 = rep(0, 3), x1 = coord[,1], y0 = rep(0,3), y1 =coord[,2])  } #> Error in FUN(X[[i]], ...): Embeddings must be passed as factor/categorical feature. # }"},{"path":"/reference/findReTrmClasses.html","id":null,"dir":"Reference","previous_headings":"","what":"list of specials – taken from enum.R — findReTrmClasses","title":"list of specials – taken from enum.R — findReTrmClasses","text":"list specials – taken enum.R","code":""},{"path":"/reference/findReTrmClasses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"list of specials – taken from enum.R — findReTrmClasses","text":"","code":"findReTrmClasses()"},{"path":"/reference/linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Linear Layer for a CNN Architecture — linear","title":"Create a Linear Layer for a CNN Architecture — linear","text":"function creates linear layer object class citolayer use constructing Convolutional Neural Network (CNN) architecture. resulting layer object can passed create_architecture function define structure network.","code":""},{"path":"/reference/linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Linear Layer for a CNN Architecture — linear","text":"","code":"linear(   n_neurons = NULL,   bias = NULL,   activation = NULL,   normalization = NULL,   dropout = NULL )"},{"path":"/reference/linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Linear Layer for a CNN Architecture — linear","text":"n_neurons (integer) number hidden neurons layer. bias (boolean) TRUE, learnable bias added neurons layer. activation (character) activation function applied layer. Supported activation functions include \"relu\", \"leaky_relu\", \"tanh\", \"elu\", \"rrelu\", \"prelu\", \"softplus\", \"celu\", \"selu\", \"gelu\", \"relu6\", \"sigmoid\", \"softsign\", \"hardtanh\", \"tanhshrink\", \"softshrink\", \"hardshrink\", \"log_sigmoid\". normalization (boolean) TRUE, batch normalization applied layer. dropout (numeric) dropout rate layer. Set 0 disable dropout.","code":""},{"path":"/reference/linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Linear Layer for a CNN Architecture — linear","text":"S3 object class \"linear\" \"citolayer\", representing linear layer CNN architecture.","code":""},{"path":"/reference/linear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Linear Layer for a CNN Architecture — linear","text":"function creates linear layer object, used define linear layer CNN architecture. Parameters specified (thus set NULL) filled default values provided create_architecture function.","code":""},{"path":[]},{"path":"/reference/linear.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a Linear Layer for a CNN Architecture — linear","text":"Armin Schenk","code":""},{"path":"/reference/linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Linear Layer for a CNN Architecture — linear","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # A linear layer where all available parameters are assigned # No value will be overwritten by 'create_architecture()' layer1 <- linear(100, TRUE, \"relu\", FALSE, 0.5)  # A linear layer where only the activation function is assigned # n_neurons, bias, normalization and dropout are filled with the defaults # passed to the 'create_architecture()' function layer2 <- linear(activation=\"selu\") } # }"},{"path":"/reference/maxPool.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"function creates maxPool layer object class citolayer use constructing Convolutional Neural Network (CNN) architecture. resulting layer object can passed create_architecture function define structure network.","code":""},{"path":"/reference/maxPool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"","code":"maxPool(kernel_size = NULL, stride = NULL, padding = NULL, dilation = NULL)"},{"path":"/reference/maxPool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"kernel_size (integer tuple) size kernel layer. Use tuple kernel size varies across dimensions. stride (integer tuple) stride kernel layer. NULL, stride set kernel size. Use tuple stride differs across dimensions. padding (integer tuple) amount zero-padding added input sides. Use tuple padding differs across dimensions. dilation (integer tuple) dilation kernel layer. Use tuple dilation varies across dimensions.","code":""},{"path":"/reference/maxPool.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"S3 object class \"maxPool\" \"citolayer\", representing maximum pooling layer CNN architecture.","code":""},{"path":"/reference/maxPool.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"function creates maxPool layer object, represents maximum pooling layer CNN architecture. Parameters specified (thus set NULL) filled default values provided create_architecture function.","code":""},{"path":[]},{"path":"/reference/maxPool.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"Armin Schenk","code":""},{"path":"/reference/maxPool.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Maximum Pooling Layer for a CNN Architecture — maxPool","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # A maximum pooling layer where all available parameters are assigned # No value will be overwritten by 'create_architecture()' layer1 <- maxPool(3, 1, 0, 1)  # A maximum pooling layer where only the kernel size is assigned # stride, padding and dilation are filled with the defaults # passed to the 'create_architecture()' function layer2 <- maxPool(kernel_size=4) } # }"},{"path":"/reference/mmn.html","id":null,"dir":"Reference","previous_headings":"","what":"Train and evaluate a Multi-Modal Neural Network (MMN) model — mmn","title":"Train and evaluate a Multi-Modal Neural Network (MMN) model — mmn","text":"function trains Multi-Modal Neural Network (MMN) model provided data.","code":""},{"path":"/reference/mmn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train and evaluate a Multi-Modal Neural Network (MMN) model — mmn","text":"","code":"mmn(   formula,   dataList = NULL,   fusion_hidden = c(50L, 50L),   fusion_activation = c(\"relu\", \"leaky_relu\", \"tanh\", \"elu\", \"rrelu\", \"prelu\",     \"softplus\", \"celu\", \"selu\", \"gelu\", \"relu6\", \"sigmoid\", \"softsign\", \"hardtanh\",     \"tanhshrink\", \"softshrink\", \"hardshrink\", \"log_sigmoid\"),   fusion_bias = TRUE,   fusion_dropout = 0,   loss = c(\"mse\", \"mae\", \"softmax\", \"cross-entropy\", \"gaussian\", \"binomial\", \"poisson\"),   optimizer = c(\"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", \"rprop\"),   lr = 0.01,   alpha = 0.5,   lambda = 0,   validation = 0,   batchsize = 32L,   burnin = 10,   shuffle = TRUE,   epochs = 100,   early_stopping = NULL,   lr_scheduler = NULL,   custom_parameters = NULL,   device = c(\"cpu\", \"cuda\", \"mps\"),   plot = TRUE,   verbose = TRUE )"},{"path":"/reference/mmn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train and evaluate a Multi-Modal Neural Network (MMN) model — mmn","text":"formula formula object specifying model structure. See examples information dataList list containing data training model. list contain variables used formula. fusion_hidden numeric vector specifying number units hidden layer fusion network. fusion_activation character vector specifying activation function hidden layer fusion network. Available options : \"relu\", \"leaky_relu\", \"tanh\", \"elu\", \"rrelu\", \"prelu\", \"softplus\", \"celu\", \"selu\", \"gelu\", \"relu6\", \"sigmoid\", \"softsign\", \"hardtanh\", \"tanhshrink\", \"softshrink\", \"hardshrink\", \"log_sigmoid\". fusion_bias logical value vector (length(fusion_hidden) + 1) indicating whether include bias terms layers fusion network. fusion_dropout dropout rate fusion network, numeric value vector (length(fusion_hidden)) 0 1. loss loss function optimized training. Available options : \"mse\", \"mae\", \"softmax\", \"cross-entropy\", \"gaussian\", \"binomial\", \"poisson\". optimizer optimization algorithm used training. Available options : \"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", \"rprop\". lr learning rate optimizer. alpha alpha parameter elastic net regularization. value 0 1. lambda lambda parameter elastic net regularization. positive value. validation proportion training data use validation. value 0 1. batchsize batch size used training. burnin training aborted trainings loss baseline loss burnin epochs shuffle logical indicating whether shuffle training data epoch. epochs number epochs train model. early_stopping provided, training stop validation loss improve specified number epochs. set NULL, early stopping disabled. lr_scheduler Learning rate scheduler created config_lr_scheduler custom_parameters list parameters used custom loss functions. See vignette examples. device device perform computations. Available options : \"cpu\", \"cuda\", \"mps\". plot logical indicating whether plot training validation loss curves. verbose logical indicating whether display verbose output training.","code":""},{"path":"/reference/mmn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train and evaluate a Multi-Modal Neural Network (MMN) model — mmn","text":"object class \"citommn\" containing trained MMN model information.","code":""},{"path":[]},{"path":"/reference/multinomial_log_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial log likelihood — multinomial_log_prob","title":"Multinomial log likelihood — multinomial_log_prob","text":"Multinomial log likelihood","code":""},{"path":"/reference/multinomial_log_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial log likelihood — multinomial_log_prob","text":"","code":"multinomial_log_prob(probs, value)"},{"path":"/reference/multinomial_log_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial log likelihood — multinomial_log_prob","text":"probs probabilities value observed values Multinomial log likelihood","code":""},{"path":"/reference/plot.citoarchitecture.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for citoarchitecture objects — plot.citoarchitecture","title":"Plot method for citoarchitecture objects — plot.citoarchitecture","text":"method provides visual representation network architecture defined object class citoarchitecture, including information layer's configuration. helps understanding structure architecture defined create_architecture.","code":""},{"path":"/reference/plot.citoarchitecture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for citoarchitecture objects — plot.citoarchitecture","text":"","code":"# S3 method for class 'citoarchitecture' plot(x, input_shape, output_shape = NULL, ...)"},{"path":"/reference/plot.citoarchitecture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for citoarchitecture objects — plot.citoarchitecture","text":"x object class citoarchitecture, created create_architecture. input_shape numeric vector specifying dimensions single sample (e.g., c(3, 28, 28) RGB image height width 28 pixels). argument required detailed output. output_shape integer specifying number nodes output layer. NULL, output layer printed. ... Additional arguments (currently used).","code":""},{"path":"/reference/plot.citoarchitecture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for citoarchitecture objects — plot.citoarchitecture","text":"original citoarchitecture object, returned invisibly.","code":""},{"path":"/reference/plot.citoarchitecture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for citoarchitecture objects — plot.citoarchitecture","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  c1 <- conv(n_kernels = 8, kernel_size = 5) c2 <- conv(n_kernels = 16, kernel_size = 3) l <- linear(n_neurons = 100) mP <- maxPool(kernel_size = 2) architecture <- create_architecture(c1, c1, mP, c2, c2, mP, l,                                     default_dropout = list(linear=0.6, conv=0.4),                                     default_normalization = list(linear=TRUE),                                     default_activation = \"selu\")  # See how the finished CNN would look like for specific input and output shapes plot(architecture, c(3,128,128), 10) }  # }"},{"path":"/reference/plot.citocnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a fitted CNN model — plot.citocnn","title":"Plot a fitted CNN model — plot.citocnn","text":"function plots architecture Convolutional Neural Network (CNN) model created using cnn function.","code":""},{"path":"/reference/plot.citocnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a fitted CNN model — plot.citocnn","text":"","code":"# S3 method for class 'citocnn' plot(x, ...)"},{"path":"/reference/plot.citocnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a fitted CNN model — plot.citocnn","text":"x model created cnn. ... Additional arguments (currently used).","code":""},{"path":"/reference/plot.citocnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a fitted CNN model — plot.citocnn","text":"original model object x, returned invisibly.","code":""},{"path":"/reference/plot.citocnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a fitted CNN model — plot.citocnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222)  device <- ifelse(torch::cuda_is_available(), \"cuda\", \"cpu\")  ## Data shapes <- cito:::simulate_shapes(320, 28) X <- shapes$data Y <- shapes$labels  ## Architecture architecture <- create_architecture(conv(5), maxPool(), conv(5), maxPool(), linear(10))  ## Build and train network cnn.fit <- cnn(X, Y, architecture, loss = \"softmax\", epochs = 50, validation = 0.1, lr = 0.05, device=device)  ## Structure of Neural Network plot(cnn.fit) } #> Error in match.arg(tolower(optimizer), choices = c(\"sgd\", \"adam\", \"adadelta\",     \"adagrad\", \"rmsprop\", \"rprop\", \"ignite_adam\")): 'arg' must be of length 1 # }"},{"path":"/reference/plot.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates graph plot which gives an overview of the network architecture. — plot.citodnn","title":"Creates graph plot which gives an overview of the network architecture. — plot.citodnn","text":"Creates graph plot gives overview network architecture.","code":""},{"path":"/reference/plot.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates graph plot which gives an overview of the network architecture. — plot.citodnn","text":"","code":"# S3 method for class 'citodnn' plot(x, node_size = 1, scale_edges = FALSE, ...)  # S3 method for class 'citodnnBootstrap' plot(x, node_size = 1, scale_edges = FALSE, which_model = 1, ...)"},{"path":"/reference/plot.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates graph plot which gives an overview of the network architecture. — plot.citodnn","text":"x model created dnn node_size size node plot scale_edges edge weight gets scaled according weights (layer specific) ... functionality implemented yet which_model model ensemble plotted","code":""},{"path":"/reference/plot.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates graph plot which gives an overview of the network architecture. — plot.citodnn","text":"plot made 'ggraph' + 'igraph' represents neural network","code":""},{"path":"/reference/plot.citodnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates graph plot which gives an overview of the network architecture. — plot.citodnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222) validation_set<- sample(c(1:nrow(datasets::iris)),25)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,])  plot(nn.fit) } #> Loss at epoch 1: 2.496234, lr: 0.01000  #> Loss at epoch 2: 0.275984, lr: 0.01000 #> Loss at epoch 3: 0.299044, lr: 0.01000 #> Loss at epoch 4: 0.222605, lr: 0.01000 #> Loss at epoch 5: 0.287249, lr: 0.01000 #> Loss at epoch 6: 0.250049, lr: 0.01000 #> Loss at epoch 7: 0.359944, lr: 0.01000 #> Loss at epoch 8: 0.206016, lr: 0.01000 #> Loss at epoch 9: 0.163694, lr: 0.01000 #> Loss at epoch 10: 0.140023, lr: 0.01000 #> Loss at epoch 11: 0.141925, lr: 0.01000 #> Loss at epoch 12: 0.151213, lr: 0.01000 #> Loss at epoch 13: 0.149036, lr: 0.01000 #> Loss at epoch 14: 0.398178, lr: 0.01000 #> Loss at epoch 15: 0.183247, lr: 0.01000 #> Loss at epoch 16: 0.356197, lr: 0.01000 #> Loss at epoch 17: 0.132249, lr: 0.01000 #> Loss at epoch 18: 0.187741, lr: 0.01000 #> Loss at epoch 19: 0.184170, lr: 0.01000 #> Loss at epoch 20: 0.272680, lr: 0.01000 #> Loss at epoch 21: 0.172288, lr: 0.01000 #> Loss at epoch 22: 0.147220, lr: 0.01000 #> Loss at epoch 23: 0.130538, lr: 0.01000 #> Loss at epoch 24: 0.126134, lr: 0.01000 #> Loss at epoch 25: 0.129028, lr: 0.01000 #> Loss at epoch 26: 0.150426, lr: 0.01000 #> Loss at epoch 27: 0.158499, lr: 0.01000 #> Loss at epoch 28: 0.157252, lr: 0.01000 #> Loss at epoch 29: 0.158960, lr: 0.01000 #> Loss at epoch 30: 0.216067, lr: 0.01000 #> Loss at epoch 31: 0.149803, lr: 0.01000 #> Loss at epoch 32: 0.173776, lr: 0.01000 #> Loss at epoch 33: 0.176177, lr: 0.01000 #> Loss at epoch 34: 0.116247, lr: 0.01000 #> Loss at epoch 35: 0.131292, lr: 0.01000 #> Loss at epoch 36: 0.128969, lr: 0.01000 #> Loss at epoch 37: 0.176717, lr: 0.01000 #> Loss at epoch 38: 0.120794, lr: 0.01000 #> Loss at epoch 39: 0.164252, lr: 0.01000 #> Loss at epoch 40: 0.164758, lr: 0.01000 #> Loss at epoch 41: 0.167306, lr: 0.01000 #> Loss at epoch 42: 0.148975, lr: 0.01000 #> Loss at epoch 43: 0.165813, lr: 0.01000 #> Loss at epoch 44: 0.115868, lr: 0.01000 #> Loss at epoch 45: 0.119369, lr: 0.01000 #> Loss at epoch 46: 0.134861, lr: 0.01000 #> Loss at epoch 47: 0.131380, lr: 0.01000 #> Loss at epoch 48: 0.117812, lr: 0.01000 #> Loss at epoch 49: 0.182973, lr: 0.01000 #> Loss at epoch 50: 0.171997, lr: 0.01000 #> Loss at epoch 51: 0.106516, lr: 0.01000 #> Loss at epoch 52: 0.118296, lr: 0.01000 #> Loss at epoch 53: 0.179335, lr: 0.01000 #> Loss at epoch 54: 0.116634, lr: 0.01000 #> Loss at epoch 55: 0.121189, lr: 0.01000 #> Loss at epoch 56: 0.175579, lr: 0.01000 #> Loss at epoch 57: 0.224448, lr: 0.01000 #> Loss at epoch 58: 0.135799, lr: 0.01000 #> Loss at epoch 59: 0.128182, lr: 0.01000 #> Loss at epoch 60: 0.124716, lr: 0.01000 #> Loss at epoch 61: 0.114326, lr: 0.01000 #> Loss at epoch 62: 0.133644, lr: 0.01000 #> Loss at epoch 63: 0.154931, lr: 0.01000 #> Loss at epoch 64: 0.120528, lr: 0.01000 #> Loss at epoch 65: 0.142507, lr: 0.01000 #> Loss at epoch 66: 0.140255, lr: 0.01000 #> Loss at epoch 67: 0.146326, lr: 0.01000 #> Loss at epoch 68: 0.177324, lr: 0.01000 #> Loss at epoch 69: 0.163104, lr: 0.01000 #> Loss at epoch 70: 0.210458, lr: 0.01000 #> Loss at epoch 71: 0.133166, lr: 0.01000 #> Loss at epoch 72: 0.119485, lr: 0.01000 #> Loss at epoch 73: 0.181278, lr: 0.01000 #> Loss at epoch 74: 0.113691, lr: 0.01000 #> Loss at epoch 75: 0.137806, lr: 0.01000 #> Loss at epoch 76: 0.125155, lr: 0.01000 #> Loss at epoch 77: 0.190301, lr: 0.01000 #> Loss at epoch 78: 0.104105, lr: 0.01000 #> Loss at epoch 79: 0.184372, lr: 0.01000 #> Loss at epoch 80: 0.197652, lr: 0.01000 #> Loss at epoch 81: 0.305428, lr: 0.01000 #> Loss at epoch 82: 0.171503, lr: 0.01000 #> Loss at epoch 83: 0.113379, lr: 0.01000 #> Loss at epoch 84: 0.117211, lr: 0.01000 #> Loss at epoch 85: 0.110590, lr: 0.01000 #> Loss at epoch 86: 0.122922, lr: 0.01000 #> Loss at epoch 87: 0.204976, lr: 0.01000 #> Loss at epoch 88: 0.167082, lr: 0.01000 #> Loss at epoch 89: 0.145538, lr: 0.01000 #> Loss at epoch 90: 0.142150, lr: 0.01000 #> Loss at epoch 91: 0.131696, lr: 0.01000 #> Loss at epoch 92: 0.129867, lr: 0.01000 #> Loss at epoch 93: 0.145236, lr: 0.01000 #> Loss at epoch 94: 0.141025, lr: 0.01000 #> Loss at epoch 95: 0.111752, lr: 0.01000 #> Loss at epoch 96: 0.185524, lr: 0.01000 #> Loss at epoch 97: 0.231474, lr: 0.01000 #> Loss at epoch 98: 0.196479, lr: 0.01000 #> Loss at epoch 99: 0.151052, lr: 0.01000 #> Loss at epoch 100: 0.151423, lr: 0.01000  # }"},{"path":"/reference/predict.citocnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict with a fitted CNN model — predict.citocnn","title":"Predict with a fitted CNN model — predict.citocnn","text":"function generates predictions Convolutional Neural Network (CNN) model created using cnn function.","code":""},{"path":"/reference/predict.citocnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict with a fitted CNN model — predict.citocnn","text":"","code":"# S3 method for class 'citocnn' predict(   object,   newdata = NULL,   type = c(\"link\", \"response\", \"class\"),   device = NULL,   batchsize = NULL,   ... )"},{"path":"/reference/predict.citocnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict with a fitted CNN model — predict.citocnn","text":"object model created cnn. newdata multidimensional array representing new data predictions made. dimensions newdata match training data, except first dimension represents number samples. NULL, function uses data model trained . type character string specifying type prediction made. Options : \"link\": Scale linear predictor. \"response\": Scale response. \"class\": predicted class labels (classification tasks). device Device used making predictions. Options \"cpu\", \"cuda\", \"mps\". Default \"cpu\". batchsize integer specifying number samples processed time. NULL, function uses batchsize used training model. Default NULL. ... Additional arguments (currently used).","code":""},{"path":"/reference/predict.citocnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict with a fitted CNN model — predict.citocnn","text":"matrix predictions. type \"class\", factor predicted class labels returned.","code":""},{"path":"/reference/predict.citocnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict with a fitted CNN model — predict.citocnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222)  device <- ifelse(torch::cuda_is_available(), \"cuda\", \"cpu\")  ## Data shapes <- cito:::simulate_shapes(320, 28) X <- shapes$data Y <- shapes$labels  ## Architecture architecture <- create_architecture(conv(5), maxPool(), conv(5), maxPool(), linear(10))  ## Build and train network cnn.fit <- cnn(X, Y, architecture, loss = \"softmax\", epochs = 50, validation = 0.1, lr = 0.05, device=device)  ## Get predictions of the validation set valid <- cnn.fit$data$validation predictions <- predict(cnn.fit, newdata = X[valid,,,,drop=FALSE], type=\"class\")  ## Classification accuracy accuracy <- sum(predictions == Y[valid])/length(valid)  } #> Error in match.arg(tolower(optimizer), choices = c(\"sgd\", \"adam\", \"adadelta\",     \"adagrad\", \"rmsprop\", \"rprop\", \"ignite_adam\")): 'arg' must be of length 1 # }"},{"path":"/reference/predict.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict from a fitted dnn model — predict.citodnn","title":"Predict from a fitted dnn model — predict.citodnn","text":"Predict fitted dnn model","code":""},{"path":"/reference/predict.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict from a fitted dnn model — predict.citodnn","text":"","code":"# S3 method for class 'citodnn' predict(   object,   newdata = NULL,   type = c(\"link\", \"response\", \"class\"),   device = c(\"cpu\", \"cuda\", \"mps\"),   batchsize = NULL,   ... )  # S3 method for class 'citodnnBootstrap' predict(   object,   newdata = NULL,   type = c(\"link\", \"response\", \"class\"),   device = c(\"cpu\", \"cuda\", \"mps\"),   batchsize = NULL,   reduce = c(\"mean\", \"median\", \"none\"),   ... )"},{"path":"/reference/predict.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict from a fitted dnn model — predict.citodnn","text":"object model created dnn newdata new data predictions type type predictions. default scale linear predictor, \"response\" scale response, \"class\" means class predictions returned (classification task) device device network trained . batchsize number samples predicted time ... additional arguments reduce predictions bootstrapped model default reduced (mean, optional median none)","code":""},{"path":"/reference/predict.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict from a fitted dnn model — predict.citodnn","text":"prediction matrix","code":""},{"path":"/reference/predict.citodnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict from a fitted dnn model — predict.citodnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222) validation_set<- sample(c(1:nrow(datasets::iris)),25)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,])  # Use model on validation set predictions <- predict(nn.fit, iris[validation_set,]) # Scatterplot plot(iris[validation_set,]$Sepal.Length,predictions) # MAE mean(abs(predictions-iris[validation_set,]$Sepal.Length)) } #> Loss at epoch 1: 10.913945, lr: 0.01000  #> Loss at epoch 2: 0.212412, lr: 0.01000 #> Loss at epoch 3: 0.181393, lr: 0.01000 #> Loss at epoch 4: 0.174366, lr: 0.01000 #> Loss at epoch 5: 0.176865, lr: 0.01000 #> Loss at epoch 6: 0.175349, lr: 0.01000 #> Loss at epoch 7: 0.170944, lr: 0.01000 #> Loss at epoch 8: 0.170821, lr: 0.01000 #> Loss at epoch 9: 0.175792, lr: 0.01000 #> Loss at epoch 10: 0.166616, lr: 0.01000 #> Loss at epoch 11: 0.158596, lr: 0.01000 #> Loss at epoch 12: 0.163973, lr: 0.01000 #> Loss at epoch 13: 0.188188, lr: 0.01000 #> Loss at epoch 14: 0.142548, lr: 0.01000 #> Loss at epoch 15: 0.179802, lr: 0.01000 #> Loss at epoch 16: 0.190694, lr: 0.01000 #> Loss at epoch 17: 0.188766, lr: 0.01000 #> Loss at epoch 18: 0.161489, lr: 0.01000 #> Loss at epoch 19: 0.135624, lr: 0.01000 #> Loss at epoch 20: 0.192862, lr: 0.01000 #> Loss at epoch 21: 0.178981, lr: 0.01000 #> Loss at epoch 22: 0.157601, lr: 0.01000 #> Loss at epoch 23: 0.142329, lr: 0.01000 #> Loss at epoch 24: 0.151263, lr: 0.01000 #> Loss at epoch 25: 0.187743, lr: 0.01000 #> Loss at epoch 26: 0.165388, lr: 0.01000 #> Loss at epoch 27: 0.129267, lr: 0.01000 #> Loss at epoch 28: 0.160585, lr: 0.01000 #> Loss at epoch 29: 0.188379, lr: 0.01000 #> Loss at epoch 30: 0.153558, lr: 0.01000 #> Loss at epoch 31: 0.144072, lr: 0.01000 #> Loss at epoch 32: 0.129944, lr: 0.01000 #> Loss at epoch 33: 0.194182, lr: 0.01000 #> Loss at epoch 34: 0.214907, lr: 0.01000 #> Loss at epoch 35: 0.133484, lr: 0.01000 #> Loss at epoch 36: 0.136095, lr: 0.01000 #> Loss at epoch 37: 0.138463, lr: 0.01000 #> Loss at epoch 38: 0.138378, lr: 0.01000 #> Loss at epoch 39: 0.154714, lr: 0.01000 #> Loss at epoch 40: 0.129576, lr: 0.01000 #> Loss at epoch 41: 0.150117, lr: 0.01000 #> Loss at epoch 42: 0.161391, lr: 0.01000 #> Loss at epoch 43: 0.175937, lr: 0.01000 #> Loss at epoch 44: 0.132407, lr: 0.01000 #> Loss at epoch 45: 0.124281, lr: 0.01000 #> Loss at epoch 46: 0.128900, lr: 0.01000 #> Loss at epoch 47: 0.130559, lr: 0.01000 #> Loss at epoch 48: 0.125338, lr: 0.01000 #> Loss at epoch 49: 0.135080, lr: 0.01000 #> Loss at epoch 50: 0.224758, lr: 0.01000 #> Loss at epoch 51: 0.118671, lr: 0.01000 #> Loss at epoch 52: 0.133125, lr: 0.01000 #> Loss at epoch 53: 0.220347, lr: 0.01000 #> Loss at epoch 54: 0.139228, lr: 0.01000 #> Loss at epoch 55: 0.146905, lr: 0.01000 #> Loss at epoch 56: 0.166265, lr: 0.01000 #> Loss at epoch 57: 0.148147, lr: 0.01000 #> Loss at epoch 58: 0.140983, lr: 0.01000 #> Loss at epoch 59: 0.122876, lr: 0.01000 #> Loss at epoch 60: 0.147520, lr: 0.01000 #> Loss at epoch 61: 0.165574, lr: 0.01000 #> Loss at epoch 62: 0.135080, lr: 0.01000 #> Loss at epoch 63: 0.148231, lr: 0.01000 #> Loss at epoch 64: 0.171466, lr: 0.01000 #> Loss at epoch 65: 0.143968, lr: 0.01000 #> Loss at epoch 66: 0.144999, lr: 0.01000 #> Loss at epoch 67: 0.122125, lr: 0.01000 #> Loss at epoch 68: 0.155123, lr: 0.01000 #> Loss at epoch 69: 0.122421, lr: 0.01000 #> Loss at epoch 70: 0.131400, lr: 0.01000 #> Loss at epoch 71: 0.121768, lr: 0.01000 #> Loss at epoch 72: 0.132778, lr: 0.01000 #> Loss at epoch 73: 0.195100, lr: 0.01000 #> Loss at epoch 74: 0.136567, lr: 0.01000 #> Loss at epoch 75: 0.141775, lr: 0.01000 #> Loss at epoch 76: 0.153628, lr: 0.01000 #> Loss at epoch 77: 0.142830, lr: 0.01000 #> Loss at epoch 78: 0.137246, lr: 0.01000 #> Loss at epoch 79: 0.110762, lr: 0.01000 #> Loss at epoch 80: 0.134318, lr: 0.01000 #> Loss at epoch 81: 0.172165, lr: 0.01000 #> Loss at epoch 82: 0.125350, lr: 0.01000 #> Loss at epoch 83: 0.118069, lr: 0.01000 #> Loss at epoch 84: 0.118394, lr: 0.01000 #> Loss at epoch 85: 0.145122, lr: 0.01000 #> Loss at epoch 86: 0.124948, lr: 0.01000 #> Loss at epoch 87: 0.143738, lr: 0.01000 #> Loss at epoch 88: 0.160448, lr: 0.01000 #> Loss at epoch 89: 0.126943, lr: 0.01000 #> Loss at epoch 90: 0.121993, lr: 0.01000 #> Loss at epoch 91: 0.139184, lr: 0.01000 #> Loss at epoch 92: 0.172383, lr: 0.01000 #> Loss at epoch 93: 0.142582, lr: 0.01000 #> Loss at epoch 94: 0.123578, lr: 0.01000 #> Loss at epoch 95: 0.130031, lr: 0.01000 #> Loss at epoch 96: 0.138533, lr: 0.01000 #> Loss at epoch 97: 0.123130, lr: 0.01000 #> Loss at epoch 98: 0.131821, lr: 0.01000 #> Loss at epoch 99: 0.120103, lr: 0.01000 #> Loss at epoch 100: 0.145702, lr: 0.01000  #> [1] 0.2408615 # }"},{"path":"/reference/predict.citommn.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict from a fitted mmn model — predict.citommn","title":"Predict from a fitted mmn model — predict.citommn","text":"Predict fitted mmn model","code":""},{"path":"/reference/predict.citommn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict from a fitted mmn model — predict.citommn","text":"","code":"# S3 method for class 'citommn' predict(   object,   newdata = NULL,   type = c(\"link\", \"response\", \"class\"),   device = c(\"cpu\", \"cuda\", \"mps\"),   ... )"},{"path":"/reference/predict.citommn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict from a fitted mmn model — predict.citommn","text":"object model created mmn newdata new data predictions type value calculated, either raw response, output link function predicted class (case classification) device device network trained . ... additional arguments","code":""},{"path":"/reference/predict.citommn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict from a fitted mmn model — predict.citommn","text":"prediction matrix","code":""},{"path":"/reference/print.citoarchitecture.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for citoarchitecture objects — print.citoarchitecture","title":"Print method for citoarchitecture objects — print.citoarchitecture","text":"method provides visual representation network architecture defined object class citoarchitecture, including information layer's configuration. helps understanding structure architecture defined create_architecture.","code":""},{"path":"/reference/print.citoarchitecture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for citoarchitecture objects — print.citoarchitecture","text":"","code":"# S3 method for class 'citoarchitecture' print(x, input_shape, output_shape = NULL, ...)"},{"path":"/reference/print.citoarchitecture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for citoarchitecture objects — print.citoarchitecture","text":"x object class citoarchitecture, created create_architecture. input_shape numeric vector specifying dimensions single sample (e.g., c(3, 28, 28) RGB image height width 28 pixels). argument required detailed output. output_shape integer specifying number nodes output layer. NULL, output layer printed. ... Additional arguments (currently used).","code":""},{"path":"/reference/print.citoarchitecture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for citoarchitecture objects — print.citoarchitecture","text":"original citoarchitecture object, returned invisibly.","code":""},{"path":"/reference/print.citoarchitecture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for citoarchitecture objects — print.citoarchitecture","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  c1 <- conv(n_kernels = 8, kernel_size = 5) c2 <- conv(n_kernels = 16, kernel_size = 3) l <- linear(n_neurons = 100) mP <- maxPool(kernel_size = 2) architecture <- create_architecture(c1, c1, mP, c2, c2, mP, l,                                     default_dropout = list(linear=0.6, conv=0.4),                                     default_normalization = list(linear=TRUE),                                     default_activation = \"selu\")  # See how the finished CNN would look like for specific input and output shapes print(architecture, c(3,128,128), 10) } #> ------------------------------------------------------------------------------- #> Convolution|Input: 3x128x128 #>            |Output: 8x124x124 #>            |Kernel: 5x5 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> Convolution|Input: 8x124x124 #>            |Output: 8x120x120 #>            |Kernel: 5x5 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> MaxPool    |Input: 8x120x120 #>            |Output: 8x60x60 #>            |Kernel: 2x2 (stride=2x2, padding=0x0, dilation=1x1) #> ------------------------------------------------------------------------------- #> Convolution|Input: 8x60x60 #>            |Output: 16x58x58 #>            |Kernel: 3x3 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> Convolution|Input: 16x58x58 #>            |Output: 16x56x56 #>            |Kernel: 3x3 (stride=1x1, padding=0x0, dilation=1x1) #>            |Bias: TRUE #>            |Activation: selu #>            |Dropout: rate=0.4 #> ------------------------------------------------------------------------------- #> MaxPool    |Input: 16x56x56 #>            |Output: 16x28x28 #>            |Kernel: 2x2 (stride=2x2, padding=0x0, dilation=1x1) #> ------------------------------------------------------------------------------- #> Linear     |Input: 12544 #>            |Output: 100 #>            |Bias: TRUE #>            |Batch normalization #>            |Activation: selu #>            |Dropout: rate=0.6 #> ------------------------------------------------------------------------------- #> Linear     |Input: 100 #>            |Output: 10 #>            |Bias: TRUE #>            |Activation: Depends on loss #> ------------------------------------------------------------------------------- # }"},{"path":"/reference/print.citocnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a fitted CNN model — print.citocnn","title":"Print a fitted CNN model — print.citocnn","text":"function prints architecture Convolutional Neural Network (CNN) model created using cnn function.","code":""},{"path":"/reference/print.citocnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a fitted CNN model — print.citocnn","text":"","code":"# S3 method for class 'citocnn' print(x, ...)"},{"path":"/reference/print.citocnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a fitted CNN model — print.citocnn","text":"x model created cnn. ... Additional arguments (currently used).","code":""},{"path":"/reference/print.citocnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a fitted CNN model — print.citocnn","text":"original model object x, returned invisibly.","code":""},{"path":"/reference/print.citocnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a fitted CNN model — print.citocnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222)  device <- ifelse(torch::cuda_is_available(), \"cuda\", \"cpu\")  ## Data shapes <- cito:::simulate_shapes(320, 28) X <- shapes$data Y <- shapes$labels  ## Architecture architecture <- create_architecture(conv(5), maxPool(), conv(5), maxPool(), linear(10))  ## Build and train network cnn.fit <- cnn(X, Y, architecture, loss = \"softmax\", epochs = 50, validation = 0.1, lr = 0.05, device=device)  # Structure of Neural Network print(cnn.fit) } #> Error in match.arg(tolower(optimizer), choices = c(\"sgd\", \"adam\", \"adadelta\",     \"adagrad\", \"rmsprop\", \"rprop\", \"ignite_adam\")): 'arg' must be of length 1 # }"},{"path":"/reference/print.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Print class citodnn — print.citodnn","title":"Print class citodnn — print.citodnn","text":"Print class citodnn","code":""},{"path":"/reference/print.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print class citodnn — print.citodnn","text":"","code":"# S3 method for class 'citodnn' print(x, ...)  # S3 method for class 'citodnnBootstrap' print(x, ...)"},{"path":"/reference/print.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print class citodnn — print.citodnn","text":"x model created dnn ... additional arguments","code":""},{"path":"/reference/print.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print class citodnn — print.citodnn","text":"original object x gets returned","code":""},{"path":"/reference/print.citodnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print class citodnn — print.citodnn","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  set.seed(222) validation_set<- sample(c(1:nrow(datasets::iris)),25)  # Build and train  Network nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,])  # Structure of Neural Network print(nn.fit) } #> Loss at epoch 1: 5.278974, lr: 0.01000  #> Loss at epoch 2: 0.158715, lr: 0.01000 #> Loss at epoch 3: 0.269647, lr: 0.01000 #> Loss at epoch 4: 0.779068, lr: 0.01000 #> Loss at epoch 5: 0.289808, lr: 0.01000 #> Loss at epoch 6: 0.222324, lr: 0.01000 #> Loss at epoch 7: 0.151073, lr: 0.01000 #> Loss at epoch 8: 0.117373, lr: 0.01000 #> Loss at epoch 9: 0.238467, lr: 0.01000 #> Loss at epoch 10: 0.202062, lr: 0.01000 #> Loss at epoch 11: 0.224059, lr: 0.01000 #> Loss at epoch 12: 0.206479, lr: 0.01000 #> Loss at epoch 13: 0.189062, lr: 0.01000 #> Loss at epoch 14: 0.185540, lr: 0.01000 #> Loss at epoch 15: 0.243190, lr: 0.01000 #> Loss at epoch 16: 0.186659, lr: 0.01000 #> Loss at epoch 17: 0.196315, lr: 0.01000 #> Loss at epoch 18: 0.247513, lr: 0.01000 #> Loss at epoch 19: 0.151229, lr: 0.01000 #> Loss at epoch 20: 0.174685, lr: 0.01000 #> Loss at epoch 21: 0.169453, lr: 0.01000 #> Loss at epoch 22: 0.340852, lr: 0.01000 #> Loss at epoch 23: 0.145830, lr: 0.01000 #> Loss at epoch 24: 0.152149, lr: 0.01000 #> Loss at epoch 25: 0.158516, lr: 0.01000 #> Loss at epoch 26: 0.266870, lr: 0.01000 #> Loss at epoch 27: 0.150408, lr: 0.01000 #> Loss at epoch 28: 0.205305, lr: 0.01000 #> Loss at epoch 29: 0.116375, lr: 0.01000 #> Loss at epoch 30: 0.187146, lr: 0.01000 #> Loss at epoch 31: 0.186225, lr: 0.01000 #> Loss at epoch 32: 0.126632, lr: 0.01000 #> Loss at epoch 33: 0.202935, lr: 0.01000 #> Loss at epoch 34: 0.204696, lr: 0.01000 #> Loss at epoch 35: 0.176747, lr: 0.01000 #> Loss at epoch 36: 0.154051, lr: 0.01000 #> Loss at epoch 37: 0.180174, lr: 0.01000 #> Loss at epoch 38: 0.146647, lr: 0.01000 #> Loss at epoch 39: 0.150837, lr: 0.01000 #> Loss at epoch 40: 0.125070, lr: 0.01000 #> Loss at epoch 41: 0.270700, lr: 0.01000 #> Loss at epoch 42: 0.317249, lr: 0.01000 #> Loss at epoch 43: 0.118350, lr: 0.01000 #> Loss at epoch 44: 0.135987, lr: 0.01000 #> Loss at epoch 45: 0.199000, lr: 0.01000 #> Loss at epoch 46: 0.133361, lr: 0.01000 #> Loss at epoch 47: 0.152125, lr: 0.01000 #> Loss at epoch 48: 0.178831, lr: 0.01000 #> Loss at epoch 49: 0.170733, lr: 0.01000 #> Loss at epoch 50: 0.161493, lr: 0.01000 #> Loss at epoch 51: 0.132676, lr: 0.01000 #> Loss at epoch 52: 0.225563, lr: 0.01000 #> Loss at epoch 53: 0.152056, lr: 0.01000 #> Loss at epoch 54: 0.137219, lr: 0.01000 #> Loss at epoch 55: 0.114539, lr: 0.01000 #> Loss at epoch 56: 0.188342, lr: 0.01000 #> Loss at epoch 57: 0.176558, lr: 0.01000 #> Loss at epoch 58: 0.152500, lr: 0.01000 #> Loss at epoch 59: 0.201627, lr: 0.01000 #> Loss at epoch 60: 0.144701, lr: 0.01000 #> Loss at epoch 61: 0.140941, lr: 0.01000 #> Loss at epoch 62: 0.123952, lr: 0.01000 #> Loss at epoch 63: 0.177994, lr: 0.01000 #> Loss at epoch 64: 0.104798, lr: 0.01000 #> Loss at epoch 65: 0.157376, lr: 0.01000 #> Loss at epoch 66: 0.145011, lr: 0.01000 #> Loss at epoch 67: 0.176440, lr: 0.01000 #> Loss at epoch 68: 0.160458, lr: 0.01000 #> Loss at epoch 69: 0.146109, lr: 0.01000 #> Loss at epoch 70: 0.162491, lr: 0.01000 #> Loss at epoch 71: 0.117895, lr: 0.01000 #> Loss at epoch 72: 0.138045, lr: 0.01000 #> Loss at epoch 73: 0.122764, lr: 0.01000 #> Loss at epoch 74: 0.163801, lr: 0.01000 #> Loss at epoch 75: 0.177276, lr: 0.01000 #> Loss at epoch 76: 0.105602, lr: 0.01000 #> Loss at epoch 77: 0.134098, lr: 0.01000 #> Loss at epoch 78: 0.139077, lr: 0.01000 #> Loss at epoch 79: 0.133710, lr: 0.01000 #> Loss at epoch 80: 0.169041, lr: 0.01000 #> Loss at epoch 81: 0.112363, lr: 0.01000 #> Loss at epoch 82: 0.167330, lr: 0.01000 #> Loss at epoch 83: 0.136177, lr: 0.01000 #> Loss at epoch 84: 0.124830, lr: 0.01000 #> Loss at epoch 85: 0.134358, lr: 0.01000 #> Loss at epoch 86: 0.201256, lr: 0.01000 #> Loss at epoch 87: 0.259660, lr: 0.01000 #> Loss at epoch 88: 0.114816, lr: 0.01000 #> Loss at epoch 89: 0.137144, lr: 0.01000 #> Loss at epoch 90: 0.213866, lr: 0.01000 #> Loss at epoch 91: 0.138192, lr: 0.01000 #> Loss at epoch 92: 0.120507, lr: 0.01000 #> Loss at epoch 93: 0.133130, lr: 0.01000 #> Loss at epoch 94: 0.145151, lr: 0.01000 #> Loss at epoch 95: 0.152801, lr: 0.01000 #> Loss at epoch 96: 0.117208, lr: 0.01000 #> Loss at epoch 97: 0.181819, lr: 0.01000 #> Loss at epoch 98: 0.196254, lr: 0.01000 #> Loss at epoch 99: 0.114589, lr: 0.01000 #> Loss at epoch 100: 0.115140, lr: 0.01000 #> dnn(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width +  #>     Species, data = datasets::iris[-validation_set, ]) #> An `nn_module` containing 2,901 parameters. #>  #> ── Modules ───────────────────────────────────────────────────────────────────── #> • 0: <nn_linear> #300 parameters #> • 1: <nn_selu> #0 parameters #> • 2: <nn_linear> #2,550 parameters #> • 3: <nn_selu> #0 parameters #> • 4: <nn_linear> #51 parameters # }"},{"path":"/reference/print.citommn.html","id":null,"dir":"Reference","previous_headings":"","what":"Print class citommn — print.citommn","title":"Print class citommn — print.citommn","text":"Print class citommn","code":""},{"path":"/reference/print.citommn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print class citommn — print.citommn","text":"","code":"# S3 method for class 'citommn' print(x, ...)"},{"path":"/reference/print.citommn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print class citommn — print.citommn","text":"x model created mmn ... additional arguments","code":""},{"path":"/reference/print.citommn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print class citommn — print.citommn","text":"original object x","code":""},{"path":"/reference/print.conditionalEffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Print average conditional effects — print.conditionalEffects","title":"Print average conditional effects — print.conditionalEffects","text":"Print average conditional effects","code":""},{"path":"/reference/print.conditionalEffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print average conditional effects — print.conditionalEffects","text":"","code":"# S3 method for class 'conditionalEffects' print(x, ...)  # S3 method for class 'conditionalEffectsBootstrap' print(x, ...)"},{"path":"/reference/print.conditionalEffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print average conditional effects — print.conditionalEffects","text":"x print ACE calculated conditionalEffects ... optional arguments compatibility generic function, function implemented","code":""},{"path":"/reference/print.conditionalEffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print average conditional effects — print.conditionalEffects","text":"Matrix average conditional effects","code":""},{"path":"/reference/print.summary.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for class summary.citodnn — print.summary.citodnn","title":"Print method for class summary.citodnn — print.summary.citodnn","text":"Print method class summary.citodnn","code":""},{"path":"/reference/print.summary.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for class summary.citodnn — print.summary.citodnn","text":"","code":"# S3 method for class 'summary.citodnn' print(x, ...)  # S3 method for class 'summary.citodnnBootstrap' print(x, ...)"},{"path":"/reference/print.summary.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for class summary.citodnn — print.summary.citodnn","text":"x summary object created summary.citodnn ... additional arguments","code":""},{"path":"/reference/print.summary.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for class summary.citodnn — print.summary.citodnn","text":"List Matrices importance, average CE, absolute sum CE, standard deviation CE","code":""},{"path":"/reference/residuals.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Residuals — residuals.citodnn","title":"Extract Model Residuals — residuals.citodnn","text":"Returns residuals training set.","code":""},{"path":"/reference/residuals.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Residuals — residuals.citodnn","text":"","code":"# S3 method for class 'citodnn' residuals(object, ...)"},{"path":"/reference/residuals.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Residuals — residuals.citodnn","text":"object model created dnn ... additional arguments implemented","code":""},{"path":"/reference/residuals.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Residuals — residuals.citodnn","text":"residuals training set","code":""},{"path":"/reference/simulate_shapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Simulation for CNN — simulate_shapes","title":"Data Simulation for CNN — simulate_shapes","text":"generates images rectangles ellipsoids","code":""},{"path":"/reference/simulate_shapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data Simulation for CNN — simulate_shapes","text":"","code":"simulate_shapes(n, size, channels = 1)"},{"path":"/reference/simulate_shapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data Simulation for CNN — simulate_shapes","text":"n number images size size (quadratic) images channels number channels generated data (channel new rectangle/ellipsoid created)","code":""},{"path":"/reference/simulate_shapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data Simulation for CNN — simulate_shapes","text":"array dimension (n, 1, size, size)","code":""},{"path":"/reference/simulate_shapes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data Simulation for CNN — simulate_shapes","text":"function generates simple data demonstrate usage cnn(). generated images centered rectangles ellipsoids random widths heights.","code":""},{"path":"/reference/simulate_shapes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Data Simulation for CNN — simulate_shapes","text":"Armin Schenk","code":""},{"path":"/reference/sumTerms.html","id":null,"dir":"Reference","previous_headings":"","what":"combine a list of formula terms as a sum — sumTerms","title":"combine a list of formula terms as a sum — sumTerms","text":"combine list formula terms sum","code":""},{"path":"/reference/sumTerms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"combine a list of formula terms as a sum — sumTerms","text":"","code":"sumTerms(termList)"},{"path":"/reference/sumTerms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"combine a list of formula terms as a sum — sumTerms","text":"termList list formula terms","code":""},{"path":"/reference/summary.citocnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a fitted CNN model — summary.citocnn","title":"Summarize a fitted CNN model — summary.citocnn","text":"function provides summary Convolutional Neural Network (CNN) model created using cnn function. currently replicates output print.citocnn method.","code":""},{"path":"/reference/summary.citocnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a fitted CNN model — summary.citocnn","text":"","code":"# S3 method for class 'citocnn' summary(object, ...)"},{"path":"/reference/summary.citocnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a fitted CNN model — summary.citocnn","text":"object model created cnn. ... Additional arguments (currently used).","code":""},{"path":"/reference/summary.citocnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a fitted CNN model — summary.citocnn","text":"original model object object, returned invisibly.","code":""},{"path":"/reference/summary.citodnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Neural Network of class citodnn — summary.citodnn","title":"Summarize Neural Network of class citodnn — summary.citodnn","text":"Performs Feature Importance calculation based Permutations","code":""},{"path":"/reference/summary.citodnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Neural Network of class citodnn — summary.citodnn","text":"","code":"# S3 method for class 'citodnn' summary(object, n_permute = NULL, device = NULL, type = \"response\", ...)  # S3 method for class 'citodnnBootstrap' summary(   object,   n_permute = NULL,   device = NULL,   adjust_se = FALSE,   type = \"response\",   ... )"},{"path":"/reference/summary.citodnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Neural Network of class citodnn — summary.citodnn","text":"object model class citodnn created dnn n_permute number permutations performed. Default \\(3 * \\sqrt{n}\\), n euqals number samples training set device calculating variable importance conditional effects type scale average conditional effects calculated (\"response\" \"link\") ... additional arguments adjust_se adjust standard errors importance (standard errors multiplied 1/sqrt(3) )","code":""},{"path":"/reference/summary.citodnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Neural Network of class citodnn — summary.citodnn","text":"summary.citodnn returns object class \"summary.citodnn\", list components","code":""},{"path":"/reference/summary.citodnn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize Neural Network of class citodnn — summary.citodnn","text":"Performs feature importance calculation suggested  Fisher, Rudin, Dominici (2018), mean standard deviation average conditional Effects suggested Pichler & Hartig (2023). Feature importances interpretation similar ANOVA. Main interaction effects absorbed features. Also, feature importances prone collinearity features, .e. two features collinear, importances might overestimated. Average conditional effects (ACE) similar marginal effects approximate linear effects, .e. interpretation similar effects linear regression model. standard deviation ACE informs non-linearity feature effects. Higher values correlate stronger non-linearities. feature n permutation get done original permuted predictive mean squared error (\\(e_{perm}\\) & \\(e_{orig}\\)) get evaluated \\( FI_j= e_{perm}/e_{orig}\\). Based Mean Squared Error.","code":""},{"path":"/reference/summary.citommn.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary citommn — summary.citommn","title":"Summary citommn — summary.citommn","text":"currently print.citommn method.","code":""},{"path":"/reference/summary.citommn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary citommn — summary.citommn","text":"","code":"# S3 method for class 'citommn' summary(object, ...)"},{"path":"/reference/summary.citommn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary citommn — summary.citommn","text":"object model created mmn ... additional arguments","code":""},{"path":"/reference/summary.citommn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary citommn — summary.citommn","text":"original object","code":""},{"path":"/reference/transfer.html","id":null,"dir":"Reference","previous_headings":"","what":"Include a Pretrained Model in a CNN Architecture — transfer","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"function creates transfer layer object class citolayer use constructing Convolutional Neural Network (CNN) architecture. resulting layer object allows use pretrained models available 'torchvision' package within cito.","code":""},{"path":"/reference/transfer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"","code":"transfer(   name = c(\"alexnet\", \"inception_v3\", \"mobilenet_v2\", \"resnet101\", \"resnet152\",     \"resnet18\", \"resnet34\", \"resnet50\", \"resnext101_32x8d\", \"resnext50_32x4d\", \"vgg11\",     \"vgg11_bn\", \"vgg13\", \"vgg13_bn\", \"vgg16\", \"vgg16_bn\", \"vgg19\", \"vgg19_bn\",     \"wide_resnet101_2\", \"wide_resnet50_2\"),   pretrained = TRUE,   freeze = TRUE )"},{"path":"/reference/transfer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"name (character) name pretrained model. Available options include: \"alexnet\", \"inception_v3\", \"mobilenet_v2\", \"resnet101\", \"resnet152\", \"resnet18\", \"resnet34\", \"resnet50\", \"resnext101_32x8d\", \"resnext50_32x4d\", \"vgg11\", \"vgg11_bn\", \"vgg13\", \"vgg13_bn\", \"vgg16\", \"vgg16_bn\", \"vgg19\", \"vgg19_bn\", \"wide_resnet101_2\", \"wide_resnet50_2\". pretrained (boolean) TRUE, model uses pretrained weights. FALSE, random weights initialized. freeze (boolean) TRUE, weights pretrained model (except \"classifier\" part end) updated training. setting applies pretrained = TRUE.","code":""},{"path":"/reference/transfer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"S3 object class \"transfer\" \"citolayer\", representing pretrained model torchvision package CNN architecture.","code":""},{"path":"/reference/transfer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"function creates transfer layer object, represents pretrained model torchvision package linear \"classifier\" part removed. allows pretrained features model utilized enabling customization classifier. using function create_architecture, linear layers can added transfer layer. linear layers define \"classifier\" part network. linear layers provided following transfer layer, default classifier consist single output layer. Additionally, pretrained argument specifies whether use pretrained weights initialize model random weights. freeze set TRUE, weights final linear layers (\"classifier\") updated training, rest pretrained model remains unchanged. Note freeze effect unless pretrained set TRUE.","code":""},{"path":[]},{"path":"/reference/transfer.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"Armin Schenk","code":""},{"path":"/reference/transfer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Include a Pretrained Model in a CNN Architecture — transfer","text":"","code":"# \\donttest{ if(torch::torch_is_installed()){ library(cito)  # Creates a \"transfer\" \"citolayer\" object that later tells the cnn() function that # the alexnet architecture and its pretrained weights should be used, but none # of the weights are frozen alexnet <- transfer(name=\"alexnet\", pretrained=TRUE, freeze=FALSE)  # Creates a \"transfer\" \"citolayer\" object that later tells the cnn() function that # the resnet18 architecture and its pretrained weights should be used. # Also all weights except from the linear layer at the end are frozen (and # therefore not changed during training) resnet18 <- transfer(name=\"resnet18\", pretrained=TRUE, freeze=TRUE) } # }"},{"path":"/reference/tune.html","id":null,"dir":"Reference","previous_headings":"","what":"Tune hyperparameter — tune","title":"Tune hyperparameter — tune","text":"Control hyperparameter tuning","code":""},{"path":"/reference/tune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tune hyperparameter — tune","text":"","code":"tune(   lower = NULL,   upper = NULL,   fixed = NULL,   additional = NULL,   values = NULL )"},{"path":"/reference/tune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tune hyperparameter — tune","text":"lower numeric, numeric vector, character, lower boundaries tuning space upper numeric, numeric vector, character, upper boundaries tuning space fixed character, used multi-dimensional hyperparameters hidden, dimensions fixed additional numeric, additional control parameter sets value fixed argument values custom values hyperparameters sampled, must matrix hidden layers (first column == nodes, second column == number layers)","code":""},{"path":"/news/index.html","id":"cito-11","dir":"Changelog","previous_headings":"","what":"cito 1.1","title":"cito 1.1","text":"CRAN release: 2024-03-18","code":""},{"path":"/news/index.html","id":"new-features-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"cito 1.1","text":"hyperparameter tuning (experimental) burnin parameter multivariate probit model X Y support (alternative interface) negative binomial distribution","code":""},{"path":"/news/index.html","id":"minor-changes-1-1","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"cito 1.1","text":"Improved vignette Improved README","code":""},{"path":"/news/index.html","id":"bug-fixes-1-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"cito 1.1","text":"dropout turned training (evaluation mode) predict type changed small bug activation functions extended support mps devices","code":""},{"path":"/news/index.html","id":"cito-102","dir":"Changelog","previous_headings":"","what":"cito 1.0.2","title":"cito 1.0.2","text":"CRAN release: 2023-10-06","code":""},{"path":"/news/index.html","id":"new-features-1-0-2","dir":"Changelog","previous_headings":"","what":"New features","title":"cito 1.0.2","text":"conditional Effects (approximate linear effects) uncertainties via bootstrapping (can forwarded functions) summary() can return standard errors p-values xAI metrics improved documentation / several new vignettes baseline loss loss = inf/na captured, training aborted user warned mps (M1/M2 gpu) device now supported","code":""},{"path":"/news/index.html","id":"bug-fixes-1-0-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"cito 1.0.2","text":"early stopping (ignored validation loss) weights saved best last epoch gaussian likelihood works now properly reguarlization loss visualized reduce lr plateau works now validation loss","code":""},{"path":"/news/index.html","id":"cito-101","dir":"Changelog","previous_headings":"","what":"cito 1.0.1","title":"cito 1.0.1","text":"CRAN release: 2023-03-13","code":""},{"path":"/news/index.html","id":"new-features-1-0-1","dir":"Changelog","previous_headings":"","what":"New features","title":"cito 1.0.1","text":"predict function can now return directly class custom loss parameter can now also optimized summary function (importances) now support loss = binomial","code":""},{"path":"/news/index.html","id":"minor-changes-1-0-1","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"cito 1.0.1","text":"print summary now clear","code":""},{"path":"/news/index.html","id":"bug-fixes-1-0-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"cito 1.0.1","text":"ALE function providing new data work properly Performance improvements new dataloader ALE/PDP work now correctly softmax PDP ICE return now correct curves Early stopping works now lr reducer plateau didn’t reduce lr Predictions now made cuda model stored cuda","code":""}]
