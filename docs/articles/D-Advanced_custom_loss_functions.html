<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Advanced: Custom loss functions and prediction intervals â€¢ cito</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Advanced: Custom loss functions and prediction intervals">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">cito</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/A-Introduction_to_cito.html">Introduction to cito</a></li>
    <li><a class="dropdown-item" href="../articles/B-Training_neural_networks.html">Training neural networks</a></li>
    <li><a class="dropdown-item" href="../articles/C-Example_Species_distribution_modeling.html">Example: (Multi-) Species distribution models with cito</a></li>
    <li><a class="dropdown-item" href="../articles/D-Advanced_custom_loss_functions.html">Advanced: Custom loss functions and prediction intervals</a></li>
    <li><a class="dropdown-item" href="../articles/E-CNN_and_MMN.html">Convultions neural networks and Multi modal neural networks</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/citoverse/cito/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Advanced: Custom loss functions and prediction intervals</h1>
                        <h4 data-toc-skip class="author">Maximilian
Pichler</h4>
            
            <h4 data-toc-skip class="date">2024-03-05</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/citoverse/cito/blob/HEAD/vignettes/D-Advanced_custom_loss_functions.Rmd" class="external-link"><code>vignettes/D-Advanced_custom_loss_functions.Rmd</code></a></small>
      <div class="d-none name"><code>D-Advanced_custom_loss_functions.Rmd</code></div>
    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      This vignette shows how cito can be used for advanced techniques
      such as custom loss functions.
    </div>
    
<div class="section level2">
<h2 id="custom-loss-functions">Custom loss functions<a class="anchor" aria-label="anchor" href="#custom-loss-functions"></a>
</h2>
<p>We can pass custom loss functions to cito. R variables/values that
are used within the loss function and that should be additionally
optimized must be passed to cito via the custom_parameters argument in
<code>dnn(...custom_parameters = list(name_of_parameter=...))</code></p>
<p>Examples:</p>
<ul>
<li>(Complex) likelihood functions</li>
<li>Advanced: Quantile regression</li>
</ul>
<p>Requirements: - Complex calculations have to be written in torch -
All functions/calls must have derivatives.</p>
<div class="section level3">
<h3 id="example-1-custom-likelihoodloss-functions">Example 1: Custom (likelihood/loss) functions<a class="anchor" aria-label="anchor" href="#example-1-custom-likelihoodloss-functions"></a>
</h3>
<p>Gaussian likelihood (already implemented, but still a nice example).
Custom parameters must be passed as a list to the custom_parameters
function. The names must match the names of the parameters in the custom
loss function. The values of the named custom parameters will be the
initial values. Cito will automatically convert them to torch
tensors:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://citoverse.github.io/cito/" class="external-link">cito</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs" class="external-link">torch</a></span><span class="op">)</span></span>
<span><span class="va">gaussian_ll</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">pred</span>, <span class="va">true</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">loss</span> <span class="op">=</span> <span class="op">-</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/distr_normal.html" class="external-link">distr_normal</a></span><span class="op">(</span><span class="va">pred</span>, scale <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_exp.html" class="external-link">torch_exp</a></span><span class="op">(</span><span class="va">scale_par</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="va">true</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">loss</span><span class="op">$</span><span class="fu">mean</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Simulate some data</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">=</span> <span class="fl">2</span><span class="op">*</span><span class="va">X</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">200</span>, sd <span class="op">=</span> <span class="fl">0.4</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>, Y <span class="op">=</span> <span class="va">Y</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="fu"><a href="../reference/dnn.html">dnn</a></span><span class="op">(</span><span class="va">Y</span><span class="op">~</span><span class="va">X</span>, data <span class="op">=</span> <span class="va">df</span>,</span>
<span>        loss <span class="op">=</span> <span class="va">gaussian_ll</span>, <span class="co"># custom function</span></span>
<span>        custom_parameters <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>scale_par <span class="op">=</span> <span class="fl">0.0</span><span class="op">)</span> <span class="co"># custom parameter that should be addtionally optimized</span></span>
<span>        <span class="op">)</span></span>
<span><span class="co">#&gt; Loss at epoch 1: 1.334335, lr: 0.01000</span></span></code></pre></div>
<p><img src="D%2FD-unnamed-chunk-2-1.png" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">#&gt; Loss at epoch 2: 1.154231, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 3: 1.068738, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 4: 1.016910, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 5: 0.976305, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 6: 0.937856, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 7: 0.899509, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 8: 0.863034, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 9: 0.824331, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 10: 0.786820, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 11: 0.749023, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 12: 0.716187, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 13: 0.684993, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 14: 0.651024, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 15: 0.630259, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 16: 0.602878, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 17: 0.594161, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 18: 0.585590, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 19: 0.572606, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 20: 0.596161, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 21: 0.560749, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 22: 0.569604, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 23: 0.557299, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 24: 0.562676, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 25: 0.566415, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 26: 0.545704, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 27: 0.563066, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 28: 0.579306, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 29: 0.548550, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 30: 0.566733, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 31: 0.602605, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 32: 0.566520, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 33: 0.555276, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 34: 0.573158, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 35: 0.553411, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 36: 0.562307, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 37: 0.553605, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 38: 0.561382, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 39: 0.542558, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 40: 0.555270, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 41: 0.569742, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 42: 0.559802, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 43: 0.561651, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 44: 0.550025, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 45: 0.551257, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 46: 0.553354, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 47: 0.548418, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 48: 0.572100, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 49: 0.566985, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 50: 0.563628, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 51: 0.565352, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 52: 0.557491, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 53: 0.553377, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 54: 0.543934, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 55: 0.591781, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 56: 0.551933, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 57: 0.556685, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 58: 0.557246, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 59: 0.550845, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 60: 0.568086, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 61: 0.547975, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 62: 0.553804, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 63: 0.550696, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 64: 0.553359, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 65: 0.555588, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 66: 0.556177, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 67: 0.548261, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 68: 0.575579, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 69: 0.555330, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 70: 0.567671, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 71: 0.550055, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 72: 0.542451, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 73: 0.563940, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 74: 0.550842, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 75: 0.562200, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 76: 0.557705, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 77: 0.557986, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 78: 0.556814, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 79: 0.560184, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 80: 0.548673, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 81: 0.591368, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 82: 0.556005, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 83: 0.544128, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 84: 0.585111, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 85: 0.565595, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 86: 0.555380, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 87: 0.553692, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 88: 0.554190, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 89: 0.550925, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 90: 0.546147, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 91: 0.550892, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 92: 0.560193, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 93: 0.570056, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 94: 0.553779, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 95: 0.558661, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 96: 0.546044, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 97: 0.549163, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 98: 0.550264, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 99: 0.549252, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 100: 0.562601, lr: 0.01000</span></span></code></pre>
<p>The optimized parameters are saved in the parameter field:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">m</span><span class="op">$</span><span class="va">parameter</span><span class="op">$</span><span class="va">scale_par</span><span class="op">)</span> <span class="co"># true scale parameter: 0.4!</span></span>
<span><span class="co">#&gt; [1] 0.4217262</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-2-quantile-regression">Example 2: Quantile regression<a class="anchor" aria-label="anchor" href="#example-2-quantile-regression"></a>
</h3>
<p>The bootstrapping approach provides confidence intervals, but not
prediction intervals. We could use likelihoods, such as the Gaussian
likelihood, to fit a constant prediction interval. However, we often use
loss functions, such as the mean squared error in ML/DL, which donâ€™t
have an intrinsic parametrization for prediction intervals. We can
approximate prediction intervals with quantile regression, which has the
advantage of providing non-constant prediction intervals (for example
for heteroscedasticity):</p>
<p>Simulate data:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sim_in</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span> <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">S</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fl">1.</span>, <span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">S</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">]</span><span class="op">=</span><span class="va">S</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">1</span><span class="op">]</span><span class="op">=</span><span class="fl">0.0</span></span>
<span>  <span class="va">X</span> <span class="op">=</span> <span class="fu">mvtnorm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mvtnorm/man/Mvnorm.html" class="external-link">rmvnorm</a></span><span class="op">(</span><span class="va">n</span>, sigma <span class="op">=</span> <span class="va">S</span><span class="op">)</span></span>
<span>  <span class="va">X1</span> <span class="op">=</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">C</span> <span class="op">=</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span></span>
<span>  <span class="va">X2</span> <span class="op">=</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span></span>
<span>  <span class="va">Y</span> <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="va">X1</span> <span class="op">+</span> <span class="fl">0.1</span><span class="op">*</span><span class="va">X2</span> <span class="op">+</span> <span class="fl">0.0</span><span class="op">*</span><span class="va">C</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, sd <span class="op">=</span> <span class="fl">0.3</span><span class="op">+</span><span class="fl">2</span><span class="op">*</span><span class="fl">1.8</span><span class="op">^</span><span class="op">(</span><span class="va">X1</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Y <span class="op">=</span> <span class="va">Y</span>, X1 <span class="op">=</span> <span class="va">X1</span>, X2 <span class="op">=</span> <span class="va">X2</span>, C <span class="op">=</span> <span class="va">C</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">data</span> <span class="op">=</span> <span class="fu">sim_in</span><span class="op">(</span><span class="fl">500L</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">X1</span>, <span class="va">data</span><span class="op">$</span><span class="va">Y</span><span class="op">)</span></span></code></pre></div>
<p><img src="D%2FD-unnamed-chunk-4-1.png" style="display: block; margin: auto;"></p>
<p>The variance increases with higher feature values</p>
<p>Quantile Regression:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs" class="external-link">torch</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">q1</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="va">q2</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">q3</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span><span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="va">loss_func</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">pred</span>, <span class="va">true</span>,<span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">l1</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_max.html" class="external-link">torch_max</a></span><span class="op">(</span><span class="va">q1</span><span class="op">*</span><span class="op">(</span><span class="va">true</span><span class="op">[</span>,<span class="fl">1</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">-</span><span class="va">pred</span><span class="op">[</span>,<span class="fl">1</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span>, other <span class="op">=</span> <span class="op">(</span><span class="fl">1.0</span><span class="op">-</span><span class="va">q1</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">pred</span><span class="op">[</span>,<span class="fl">1</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">-</span><span class="va">true</span><span class="op">[</span>,<span class="fl">1</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">l2</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_max.html" class="external-link">torch_max</a></span><span class="op">(</span><span class="va">q2</span><span class="op">*</span><span class="op">(</span><span class="va">true</span><span class="op">[</span>,<span class="fl">2</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">-</span><span class="va">pred</span><span class="op">[</span>,<span class="fl">2</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span>, other <span class="op">=</span> <span class="op">(</span><span class="fl">1.0</span><span class="op">-</span><span class="va">q2</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">pred</span><span class="op">[</span>,<span class="fl">2</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">-</span><span class="va">true</span><span class="op">[</span>,<span class="fl">2</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">l3</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_max.html" class="external-link">torch_max</a></span><span class="op">(</span><span class="va">q3</span><span class="op">*</span><span class="op">(</span><span class="va">true</span><span class="op">[</span>,<span class="fl">3</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">-</span><span class="va">pred</span><span class="op">[</span>,<span class="fl">3</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span>, other <span class="op">=</span> <span class="op">(</span><span class="fl">1.0</span><span class="op">-</span><span class="va">q3</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">pred</span><span class="op">[</span>,<span class="fl">3</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">-</span><span class="va">true</span><span class="op">[</span>,<span class="fl">3</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">l1</span><span class="op">+</span><span class="va">l2</span><span class="op">+</span><span class="va">l3</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="fu"><a href="../reference/dnn.html">dnn</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">Y</span>, <span class="va">Y</span>, <span class="va">Y</span><span class="op">)</span><span class="op">~</span><span class="va">.</span>, data <span class="op">=</span> <span class="va">data</span>,</span>
<span>        lr <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>        loss <span class="op">=</span> <span class="va">loss_func</span>,</span>
<span>        lambda <span class="op">=</span> <span class="fl">0.000</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>        epochs <span class="op">=</span> <span class="fl">70L</span>, hidden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">30L</span>, <span class="fl">30L</span><span class="op">)</span>,</span>
<span>        activation <span class="op">=</span> <span class="st">"selu"</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span>, plot <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Loss at epoch 1: 5.470749, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 2: 5.268569, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 3: 5.076637, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 4: 4.884690, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 5: 4.684872, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 6: 4.477314, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 7: 4.274307, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 8: 4.078366, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 9: 3.909358, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 10: 3.758730, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 11: 3.627732, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 12: 3.520284, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 13: 3.424504, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 14: 3.341247, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 15: 3.270656, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 16: 3.210762, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 17: 3.154351, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 18: 3.105250, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 19: 3.063805, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 20: 3.032800, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 21: 3.005759, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 22: 2.983023, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 23: 2.964745, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 24: 2.950813, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 25: 2.935929, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 26: 2.922020, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 27: 2.911182, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 28: 2.903018, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 29: 2.894961, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 30: 2.888757, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 31: 2.882994, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 32: 2.878412, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 33: 2.874529, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 34: 2.871417, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 35: 2.868292, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 36: 2.867184, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 37: 2.863862, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 38: 2.861748, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 39: 2.859973, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 40: 2.858448, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 41: 2.856646, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 42: 2.854968, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 43: 2.854192, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 44: 2.852455, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 45: 2.851032, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 46: 2.850336, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 47: 2.849624, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 48: 2.848325, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 49: 2.846308, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 50: 2.845728, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 51: 2.844210, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 52: 2.844008, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 53: 2.842485, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 54: 2.841521, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 55: 2.841301, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 56: 2.839583, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 57: 2.839782, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 58: 2.837819, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 59: 2.837510, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 60: 2.836291, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 61: 2.835764, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 62: 2.835144, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 63: 2.834413, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 64: 2.834573, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 65: 2.832787, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 66: 2.831882, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 67: 2.832079, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 68: 2.831004, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 69: 2.829836, lr: 0.01000</span></span>
<span><span class="co">#&gt; Loss at epoch 70: 2.829776, lr: 0.01000</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">X1</span>, <span class="va">data</span><span class="op">$</span><span class="va">Y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/smooth.spline.html" class="external-link">smooth.spline</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">X1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>, spar <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/smooth.spline.html" class="external-link">smooth.spline</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">X1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span>, spar <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/smooth.spline.html" class="external-link">smooth.spline</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">X1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, spar <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<p><img src="D%2FD-unnamed-chunk-5-1.png" style="display: block; margin: auto;"></p>
</div>
<div class="section level3">
<h3 id="example-3-using-cito-for-optimization-active-learning">Example 3: Using cito for optimization / active learning<a class="anchor" aria-label="anchor" href="#example-3-using-cito-for-optimization-active-learning"></a>
</h3>
<p>Neural networks can be used in an unconventional way to optimize
arbitrary functions (which is sometimes called active learning, it is
related to reinforcement learning) - the only prerequisite is that the
analytic derivative of the function using torch must be available. We
provide the function to be optimized as a series of Torch operations.
First, our model will predict the parameters (based on noise, the inputs
donâ€™t matter) which are passed to the custom loss function and then we
will then use the model function (which we optimize) to compute the loss
and return it to the optimizer. In that way we overfit to the noisy
inputs and the DNN will learn to predict the optimal set of parameters -
independent of the input.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">=</span> <span class="fl">2</span><span class="op">*</span><span class="va">X</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">200</span>, sd <span class="op">=</span> <span class="fl">0.4</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">X</span>, Y <span class="op">=</span> <span class="va">Y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Function we want to optimize (linear model)</span></span>
<span><span class="va">Xt</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">Yt</span> <span class="op">=</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_tensor.html" class="external-link">torch_tensor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">Y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_lm</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">pred</span> <span class="op">=</span> <span class="va">Xt</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">par</span><span class="op">[</span>,<span class="fl">1</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">loss</span> <span class="op">=</span> <span class="op">-</span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/distr_normal.html" class="external-link">distr_normal</a></span><span class="op">(</span><span class="va">pred</span>, scale <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_exp.html" class="external-link">torch_exp</a></span><span class="op">(</span><span class="va">par</span><span class="op">[</span>,<span class="fl">2</span>,drop<span class="op">=</span><span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="va">Yt</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">loss</span><span class="op">$</span><span class="fu">mean</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">custom_loss</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">pred</span>, <span class="va">true</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">pred</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">1</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_zeros.html" class="external-link">torch_zeros</a></span><span class="op">(</span><span class="fl">1L</span><span class="op">)</span><span class="op">)</span> <span class="co"># disable loss calculation</span></span>
<span>  <span class="va">loss</span> <span class="op">=</span> <span class="fu">model_lm</span><span class="op">(</span><span class="va">pred</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">loss</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># X and Y values don't matter, number of columns in Y has to match the number of parameters we want to optimize</span></span>
<span><span class="va">noise</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">300</span><span class="op">*</span><span class="fl">5</span><span class="op">)</span>, <span class="fl">300</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">noise_y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">300</span><span class="op">*</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">300</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>y1 <span class="op">=</span> <span class="va">noise_y</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>, y2 <span class="op">=</span> <span class="va">noise_y</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, <span class="va">noise</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="fu"><a href="../reference/dnn.html">dnn</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">y1</span>, <span class="va">y2</span><span class="op">)</span><span class="op">~</span><span class="va">.</span>, data <span class="op">=</span> <span class="va">df</span>, loss <span class="op">=</span> <span class="va">custom_loss</span>, batchsize <span class="op">=</span> <span class="fl">1L</span>, epochs <span class="op">=</span> <span class="fl">20L</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p><img src="D%2FD-unnamed-chunk-6-1.png" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Effect:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2.035041</span></span>
<span><span class="co"># SD</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.4103649</span></span></code></pre></div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Christian AmesÃ¶der, Maximilian Pichler.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
